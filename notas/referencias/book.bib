@article{shao,
author = { Jun   Shao },
title = {Linear Model Selection by Cross-validation},
journal = {Journal of the American Statistical Association},
volume = {88},
number = {422},
pages = {486-494},
year  = {1993},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1993.10476299},
URL = {
        https://www.tandfonline.com/doi/abs/10.1080/01621459.1993.10476299
},
eprint = {
        https://www.tandfonline.com/doi/pdf/10.1080/01621459.1993.10476299
}
}
@book{kuhn2022tidy,
  title={Tidy Modeling with R},
  author={Kuhn, M. and Silge, J.},
  isbn={9781492096443},
  url={https://books.google.com.mx/books?id=9cJ6EAAAQBAJ},
  year={2022},
  publisher={O'Reilly Media}
}
@book{kuhn,
  title={Applied Predictive Modeling},
  author={Kuhn, M. and Johnson, K.},
  isbn={9781461468493},
  series={SpringerLink : B{\"u}cher},
  url={https://books.google.com.mx/books?id=xYRDAAAAQBAJ},
  year={2013},
  publisher={Springer New York}
}
@Book{ESL,
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  biburl = {https://www.bibsonomy.org/bibtex/2f58afc5c9793fcc8ad8389824e57984c/sb3000},
  publisher = {Springer New York Inc.},
  series = {Springer Series in Statistics},
  url = {http://web.stanford.edu/~hastie/ElemStatLearn/},
  title = {The Elements of Statistical Learning},
  year = 2017
}
@misc{Ngcoursera,
author = {Andrew Ng},
title = {Machine Learning},
howpublished = "\url{https://www.coursera.org/learn/machine-learning}",
year = {2017},
note = "Accessed 08/08/17",
}
@Book{ISL,
 author = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
 title = {An Introduction to Statistical Learning: With Applications in R},
 year = {2014},
 isbn = {1461471370, 9781461471370},
 url ={http://www-bcf.usc.edu/~gareth/ISL/},
 publisher = {Springer Publishing Company, Incorporated},
}
@Book{xie2015,
  title = {Dynamic Documents with {R} and knitr},
  author = {Yihui Xie},
  publisher = {Chapman and Hall/CRC},
  address = {Boca Raton, Florida},
  year = {2015},
  edition = {2nd},
  note = {ISBN 978-1498716963},
  url = {http://yihui.name/knitr/},
}
@article{breiman2001,
author = "Breiman, Leo",
doi = "10.1214/ss/1009213726",
fjournal = "Statistical Science",
journal = "Statist. Sci.",
month = "08",
number = "3",
pages = "199--231",
publisher = "The Institute of Mathematical Statistics",
title = "Statistical Modeling: The Two Cultures (with comments and a
 rejoinder by the author)",
url = "http://dx.doi.org/10.1214/ss/1009213726",
volume = "16",
year = "2001"
}



@article{Srivastava:2014:DSW:2627435.2670313,
 author = {Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
 title = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2014},
 volume = {15},
 number = {1},
 month = jan,
 year = {2014},
 issn = {1532-4435},
 pages = {1929--1958},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=2627435.2670313},
 acmid = {2670313},
 publisher = {JMLR.org},
 keywords = {deep learning, model combination, neural networks, regularization},
}

@article{DBLP:journals/corr/abs-1206-5533,
  author    = {Yoshua Bengio},
  title     = {Practical recommendations for gradient-based training of deep architectures},
  journal   = {CoRR},
  volume    = {abs/1206.5533},
  year      = {2012},
  url       = {http://arxiv.org/abs/1206.5533},
  timestamp = {Wed, 07 Jun 2017 14:43:16 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/abs-1206-5533},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}
@book{Bishop,
 author = {Bishop, Christopher M.},
 title = {Pattern Recognition and Machine Learning (Information Science and Statistics)},
 year = {2006},
 isbn = {0387310738},
 publisher = {Springer-Verlag New York, Inc.},
 address = {Secaucus, NJ, USA},
}
@book{GelmanHill,
  address = {New York},
  author = {Gelman, Andrew and Hill, Jennifer},
  publisher = {Cambridge University Press},
  title = {Data analysis using regression and multilevel/hierarchical models},
  volume = {Analytical methods for social research},
  year = 2007
}
@inproceedings{xgboost,
author = {Chen, Tianqi and Guestrin, Carlos},
year = {2016},
month = {08},
pages = {785-794},
title = {XGBoost: A Scalable Tree Boosting System},
doi = {10.1145/2939672.2939785}
}

@article{donoho50,
author = {David Donoho},
title = {50 Years of Data Science},
journal = {Journal of Computational and Graphical Statistics},
volume = {26},
number = {4},
pages = {745-766},
year  = {2017},
publisher = {Taylor & Francis},
doi = {10.1080/10618600.2017.1384734},
URL = {https://doi.org/10.1080/10618600.2017.1384734},
eprint = {https://doi.org/10.1080/10618600.2017.1384734}
}
@article {KingCausal,
	title = {Misunderstandings Among Experimentalists and Observationalists about Causal Inference},
	journal = {Journal of the Royal Statistical Society, Series A},
	volume = {171, part 2},
	year = {2008},
	pages = {481{\textendash}502},
	abstract = {We attempt to clarify, and suggest how to avoid, several serious misunderstandings about and fallacies of causal inference in experimental and observational research. These issues concern some of the most basic advantages and disadvantages of each basic research design. Problems include improper use of hypothesis tests for covariate balance between the treated and control groups, and the consequences of using randomization, blocking before randomization, and matching after treatment assignment to achieve covariate balance. Applied researchers in a wide range of scientific disciplines seem to fall prey to one or more of these fallacies, and as a result make suboptimal design or analysis choices. To clarify these points, we derive a new four-part decomposition of the key estimation errors in making causal inferences. We then show how this decomposition can help scholars from different experimental and observational research traditions better understand each other{\textquoteright}s inferential problems and attempted solutions.},
	author = {Kosuke Imai and Gary King and Elizabeth Stuart}
}
@book{chambers83,
  title={Graphical Methods for Data Analysis},
  author={Chambers, J.M. and Cleveland, W.S. and Kleiner, B. and Tukey, P.A.},
  isbn={9780534980528},
  lccn={83003660},
  series={Chapman \& Hall statistics series},
  url={https://books.google.com.mx/books?id=I-tQAAAAMAAJ},
  year={1983},
  publisher={Wadsworth International Group}
}
@misc{gentle21,
      title={A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification},
      author={Anastasios N. Angelopoulos and Stephen Bates},
      year={2021},
      eprint={2107.07511},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@Book{goodfellow2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}
