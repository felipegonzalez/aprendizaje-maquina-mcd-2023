[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizaje Máquina",
    "section": "",
    "text": "Temario y referencias\nTodas las notas y material del curso estarán en este repositorio.\n\nIntroducción al aprendizaje máquina\nMétodos locales y estructurados. Ingeniería de variables de entrada.\nPrincipios de Regularización\nProblemas de clasificación, métricas y evaluación\nMétodos de remuestreo y validación cruzada\nRedes neuronales\nÁrboles, bosques aleatorios y boosting\nDiagnóstico y mejora en problemas de aprendizaje supervisado\nReducción de dimensionalidad: Embeddings, descomposición en valores singulares, componentes principales\nAnálisis de conglomerados\n\n\nEvaluación\n\nTareas semanales (20%) para discutir en clase, compartidas en el repositorio y en nuestro espacio de trabajo de Posit Cloud.\nExamen parcial (40% práctico), con una componente oral.\nUn examen final (40% práctico), con una componente oral.\n\n\n\nMaterial\nCada semestre las notas cambian, en algunas partes considerablemente. Las de este semestre están en este repositorio, incluyendo ejemplos, ejercicios y tareas.\n\n\nReferencias principales\n\nAn Introduction to Statistical Learning, James et al. (2014)\nDeep Learning, Goodfellow, Bengio, y Courville (2016)\nTidy Modeling with R, Kuhn y Silge (2022)\n\n\n\nOtras referencias\n\nPattern Recognition and Machine Learning, Bishop (2006)\nThe Elements of Statistical Learning, Hastie, Tibshirani, y Friedman (2017)\nPredicción conforme\n\n\n\nSoftware\nPara hacer las tareas y exámenes pueden usar cualquier lenguaje o flujo de trabajo que les convenga (R o Python, por ejemplo) - el único requisito esté basado en código y no point-and-click. En lo posible utilizamos librerías especializadas que se pueden utilizar desde varias plataformas (keras, por ejemplo).\n\n\n\n\nBishop, Christopher M. 2006. Pattern Recognition and Machine Learning (Information Science and Statistics). Secaucus, NJ, USA: Springer-Verlag New York, Inc.\n\n\nGoodfellow, Ian, Yoshua Bengio, y Aaron Courville. 2016. Deep Learning. MIT Press.\n\n\nHastie, Trevor, Robert Tibshirani, y Jerome Friedman. 2017. The Elements of Statistical Learning. Springer Series en Statistics. Springer New York Inc. http://web.stanford.edu/~hastie/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, y Robert Tibshirani. 2014. An Introduction to Statistical Learning: With Applications in R. Springer Publishing Company, Incorporated. http://www-bcf.usc.edu/~gareth/ISL/.\n\n\nKuhn, M., y J. Silge. 2022. Tidy Modeling with R. O’Reilly Media. https://books.google.com.mx/books?id=9cJ6EAAAQBAJ."
  },
  {
    "objectID": "01-introduccion.html#qué-es-aprendizaje-de-máquina-machine-learning",
    "href": "01-introduccion.html#qué-es-aprendizaje-de-máquina-machine-learning",
    "title": "1  Introducción",
    "section": "1.1 ¿Qué es aprendizaje de máquina (machine learning)?",
    "text": "1.1 ¿Qué es aprendizaje de máquina (machine learning)?\nMétodos computacionales para aprender de datos con el fin de producir reglas para mejorar el desempeño en alguna tarea o toma de decisión.\nEn este curso nos enfocamos en las tareas de aprendizaje supervisado (predecir o estimar una variable respuesta a partir de datos de entrada) y aprendizaje no supervisado (describir estructuras interesantes en datos, donde no necesariamente hay una respuesta que predecir). Existe también aprendizaje por refuerzo, en donde buscamos aprender a tomar decisiones en un entorno en donde la decisión afecta directa e inmediatamente al entorno.\n\nEjemplos de tareas de aprendizaje:\n\nPredecir si un cliente de tarjeta de crédito va a caer en impago en los próximos tres meses.\nReconocer palabras escritas a mano (OCR).\nDetectar llamados de ballenas en grabaciones de boyas.\nEstimar el ingreso mensual de un hogar a partir de las características de la vivienda, posesiones y equipamiento y localización geográfica.\nDividir a los clientes de Netflix según sus gustos.\nRecomendar artículos a clientes de un programa de lealtad o servicio online.\n\nLas razones usuales para intentar resolver estos problemas computacionalmente son diversas:\n\nQuisiéramos obtener una respuesta barata, rápida, automatizada, y con suficiente precisión. Por ejemplo, reconocer caracteres en una placa de coche de una fotografía se puede hacer por personas, pero eso es lento y costoso. Igual oír cada segundo de grabación de las boyas para saber si hay ballenas o no. Hacer mediciones directas del ingreso de un hogar requiere mucho tiempo y esfuerzo.\nQuisiéramos superar el desempeño actual de los expertos o de reglas simples utilizando datos: por ejemplo, en la decisión de dar o no un préstamo a un solicitante, puede ser posible tomar mejores decisiones con algoritmos que con evaluaciones personales o con reglas simples que toman en cuenta el ingreso mensual, por ejemplo.\nAl resolver estos problemas computacionalmente tenemos oportunidad de aprender más del problema que nos interesa: estas soluciones forman parte de un ciclo de análisis de datos donde podemos aprender de una forma más concentrada cuáles son características y patrones importantes de nuestros datos.\n\nEs posible aproximarse a todos estos problemas usando reglas (por ejemplo, si los pixeles del centro de la imagen están vacíos, entonces es un cero, si el crédito total es mayor al 50% del ingreso anual, declinar el préstamo, etc). Las razones para no tomar un enfoque de reglas construidas “a mano”:\n\nCuando conjuntos de reglas creadas a mano se desempeñan mal (por ejemplo, para otorgar créditos, reconocer caracteres, etc.)\nReglas creadas a mano pueden ser difíciles de mantener (por ejemplo, un corrector ortográfico), pues para problemas interesantes muchas veces se requieren grandes cantidades de reglas. Por ejemplo: ¿qué búsquedas www se enfocan en dar direcciones como resultados? ¿cómo filtrar comentarios no aceptables en foros?"
  },
  {
    "objectID": "01-introduccion.html#ejemplo-reglas-y-aprendizaje",
    "href": "01-introduccion.html#ejemplo-reglas-y-aprendizaje",
    "title": "1  Introducción",
    "section": "1.2 Ejemplo: reglas y aprendizaje",
    "text": "1.2 Ejemplo: reglas y aprendizaje\nLectura de un medidor mediante imágenes. Supongamos que en una infraestructura donde hay medidores análogos (de agua, electricidad, gas, etc.) que no se comunican. ¿Podríamos pensar en utilizar fotos tomadas automáticamente para medir el consumo?\nPor ejemplo, consideramos el siguiente problema (tomado de aquí, ver código y datos):\n\nlibrary(imager)\nlibrary(tidyverse)\nlibrary(gt)\nset.seed(437)\npath_img &lt;- \"../datos/medidor/\"\npath_full_imgs &lt;- list.files(path = path_img, full.names = TRUE)\nmedidor &lt;- load.image(sample(path_full_imgs, 1))\npar(mar = c(1, 1, 1, 1))\nplot(medidor, axes = FALSE)\n\n\n\n\nNótese que las imágenes y videos son matrices o arreglos de valores de pixeles, por ejemplo estas son las dimensiones para una imagen:\n\ndim(medidor)\n\n[1] 142 142   1   3\n\n\nEn este caso, la imagen es de 193 x 193 pixeles y tiene tres canales, o tres matrices de 193 x 193 donde la entrada de cada matriz es la intensidad del canal correspondiente. Buscámos hacer cálculos con estas matrices para extraer la información que queremos. En este caso, construiremos estos cálculos a mano.\nPrimero filtramos (extraemos canal rojo y azul, restamos, difuminamos y aplicamos un umbral):\n\nmedidor_rojo &lt;- medidor |&gt;  R() \nmedidor_azul &lt;- medidor |&gt; B()\nmedidor_1 &lt;- (medidor_rojo - medidor_azul) |&gt; isoblur(5)\naguja &lt;-  medidor_1 |&gt;  imager::threshold(\"90%\", approx = FALSE)\n\n\n\n\n\n\nLogramos extraer la aguja, aunque hay algo de ruido adicional. Una estrategia es extraer la componente conexa más grande (que debería corresponder a la aguja), y luego calcular su orientación. Una manera fácil es encontrar una recta que vaya del centro de la imagen hasta el punto más alejado del centro (aunque quizá puedes pensar maneras más robustas de hacer esto):\n\ncalcular_punta &lt;- function(pixset){\n  centro &lt;- floor(dim(pixset)[1:2] / 2)\n  # segmentar en componentes conexas\n  componentes &lt;- split_connected(pixset)\n  # calcular la más grande\n  num_pixeles &lt;- map_dbl(componentes, sum)\n  ind_maxima &lt;- which.max(num_pixeles)\n  pixset_tbl &lt;- as_tibble(componentes[[ind_maxima]]) |&gt; \n    mutate(dist = (x - centro[1])^2 + (y - centro[2])^2) |&gt; \n    top_n(1, dist)  |&gt; \n    mutate(x_1 = x - centro[1], y_1 = y - centro[2])\n  pixset_tbl[1, ] \n}\n\nY ahora podemos aplicar el proceso de arriba a todas la imágenes:\n\npath_imgs &lt;- list.files(path = path_img)\n\npath_full_imgs &lt;- list.files(path = path_img, full.names = TRUE)\n# en este caso los datos están etiquetados\ny_imagenes &lt;- path_imgs |&gt; str_sub(1, 3) |&gt; as.numeric()\n# procesar algunas imagenes\nset.seed(82)\nindice_imgs &lt;- sample(1:length(path_full_imgs), 500)\nangulos &lt;- path_full_imgs[indice_imgs] |&gt; \n    map( ~ load.image(.x)) |&gt;  \n    map(~ R(.x) - B(.x)) |&gt; \n    map( ~ isoblur(.x, 5)) |&gt; \n    map( ~ imager::threshold(.x, \"90%\")) |&gt; \n    map( ~ calcular_punta(.x)) |&gt; \n  bind_rows()\n\n\nangulos_tbl &lt;- angulos |&gt; \n  mutate(y_medidor = y_imagenes[indice_imgs])\nggplot(angulos_tbl, \n    aes(x = 180 * atan2(y_1, x_1) / pi + 90, y = y_medidor)) +\n  geom_point() + xlab(\"Ángulo\")\n\n\n\n\nEl desempeño no es muy malo pero tiene algunas fallas grandes. Quizá refinando nuestro pipeline de procesamiento podemos mejorarlo.\n\nPor el contrario, en el enfoque de aprendizaje, comenzamos con un conjunto de datos etiquetado (por una persona, por un método costoso, etc.), y utilizamos alguna estructura general para aprender a producir la respuesta a partir de las imágenes. Por ejemplo, en este caso podríamos una red convolucional sobre los valores de los pixeles de la imagen:\n\nlibrary(keras)\n# usamos los tres canales de la imagen\nimagenes &lt;- map(path_full_imgs, ~ image_load(.x, target_size = c(64, 64)))\nimgs_array &lt;-  imagenes |&gt;  map(~ image_to_array(.x)) \nimgs_array &lt;- map(imgs_array, ~ array_reshape(.x, c(1, 64, 64, 3)))\nx &lt;- abind::abind(imgs_array, along = 1)\nset.seed(25311)\nindices_entrena &lt;- sample(1:dim(x)[1], size = 4200)\n# generar lotes de datos de las imágenes originales\ngenerador_1 &lt;- image_data_generator(\n  rescale = 1/255,\n  rotation_range = 5,\n  zoom_range = 0.05,\n  horizontal_flip = FALSE,\n  vertical_flip = FALSE,\n  fill_mode = \"nearest\"\n)\ngenerador_entrena &lt;- flow_images_from_data(\n  x = x[indices_entrena,,,],\n  y = y_imagenes[indices_entrena] / 10,\n  generator = generador_1,\n  shuffle = TRUE,\n  batch_size = 64\n)\n\n\nmodelo_aguja &lt;- keras_model_sequential() |&gt;\n  layer_conv_2d(input_shape = c(64, 64, 3), \n    filters = 32, kernel_size = c(5, 5)) |&gt; \n  layer_max_pooling_2d(pool_size = c(2, 2)) |&gt;\n  layer_conv_2d(filters = 32, kernel_size = c(5, 5)) |&gt; \n  layer_max_pooling_2d(pool_size = c(2, 2)) |&gt; \n  layer_conv_2d(filters = 16, kernel_size = c(3, 3)) |&gt; \n  layer_max_pooling_2d(pool_size = c(2, 2)) |&gt; \n  layer_flatten() |&gt; \n  layer_dropout(0.2) |&gt; \n  layer_dense(units = 100, activation = \"sigmoid\") |&gt;\n  layer_dropout(0.2) |&gt; \n  layer_dense(units = 100, activation = \"sigmoid\") |&gt;\n  layer_dropout(0.2) |&gt; \n  layer_dense(units = 1, activation = 'linear')\n\nAjustamos el modelo:\n\nmodelo_aguja |&gt; compile(\n  loss = \"mse\",\n  optimizer = optimizer_adam(learning_rate = 0.0005),\n  metrics = c('mae')\n)                                                                                                        \n# Entrenar\nmodelo_aguja |&gt; fit(\n  generador_entrena,\n  epochs = 200,\n  verbose = TRUE, \n  validation_data = list(x = x[-indices_entrena,,,], \n                         y = y_imagenes[-c(indices_entrena)] / 10)\n)\nsave_model_hdf5(modelo_aguja, \"cache/modelo-aguja.h5\")\n\n\nmodelo &lt;- load_model_hdf5(\"cache/modelo-aguja.h5\")\nmodelo\n\nModel: \"sequential_2\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n conv2d_8 (Conv2D)                  (None, 60, 60, 32)              2432        \n max_pooling2d_8 (MaxPooling2D)     (None, 30, 30, 32)              0           \n conv2d_7 (Conv2D)                  (None, 26, 26, 32)              25632       \n max_pooling2d_7 (MaxPooling2D)     (None, 13, 13, 32)              0           \n conv2d_6 (Conv2D)                  (None, 11, 11, 16)              4624        \n max_pooling2d_6 (MaxPooling2D)     (None, 5, 5, 16)                0           \n flatten_2 (Flatten)                (None, 400)                     0           \n dropout_8 (Dropout)                (None, 400)                     0           \n dense_8 (Dense)                    (None, 100)                     40100       \n dropout_7 (Dropout)                (None, 100)                     0           \n dense_7 (Dense)                    (None, 100)                     10100       \n dropout_6 (Dropout)                (None, 100)                     0           \n dense_6 (Dense)                    (None, 1)                       101         \n================================================================================\nTotal params: 82,989\nTrainable params: 82,989\nNon-trainable params: 0\n________________________________________________________________________________\n\n\nY observamos que obtenemos predicciones prometedoras:\n\npreds &lt;- predict(modelo, x[-indices_entrena,,,])\npreds_tbl &lt;- tibble(y = y_imagenes[-c(indices_entrena)] / 10, preds = preds)\nggplot(preds_tbl, aes(x = preds, y = y)) +\n  geom_jitter(alpha = 0.5) +\n  geom_abline(colour = 'red')\n\n\n\n\nDe forma que podemos resolver este problema con algoritmos generales, sin tener que aplicar métodos sofisticados de procesamiento de imágenes. El enfoque de aprendizaje es particularmente efectivo cuando hay cantidades grandes de datos poco ruidosos, y aunque en este ejemplo los dos enfoques dan resultados razonables, en procesamiento de imágenes es cada vez más común usar redes neuronales grandes para resolver este tipo de problemas."
  },
  {
    "objectID": "01-introduccion.html#medicioncostosa",
    "href": "01-introduccion.html#medicioncostosa",
    "title": "1  Introducción",
    "section": "1.3 Ejemplo: mediciones costosas",
    "text": "1.3 Ejemplo: mediciones costosas\nEn algunos casos, el estándar de la medición que nos interesa es uno que es costoso de cumplir: a veces se dice que etiquetar los datos es costoso. Un ejemplo es producir las estimaciones de ingreso trimestral de un hogar que se recolecta en la ENIGH (ver aquí). En este caso particular, se utiliza esta encuesta como datos etiquetados para poder estimar el ingreso de otros hogares que no están en la muestra del ENIGH, pero para los que se conocen características de las vivienda, características de los integrantes, y otras medidas que son más fácilmente recolectadas en encuestas de opinión.\nVeremos otro ejemplo: estimar el valor de mercado de las casas en venta de una región. Es posible que tengamos un inventario de casas con varias de sus características registradas, pero producir estimaciones correctas de su valor de mercado puede requerir de inspecciones costosas de expertos, o tomar aproximaciones imprecisas de esta cantidad (por ejemplo, cuál es el precio ofertado).\nUtilizaremos datos de casas que se vendieron en Ames, Iowa en cierto periodo. En este caso, conocemos el valor a la que se vendió una casa. Buscamos producir una estimación para otras casas para las cuales conocemos características como su localización, superficie en metros cuadrados, año de construcción, espacio de estacionamiento, y así sucesivamente. Estas medidas son más fáciles de recolectar, y quisiéramos producir una estimación de su precio de venta en términos de estas medidas.\nEn este ejemplo intentaremos una forma simple de predecir.\n\nlibrary(tidymodels)\nlibrary(patchwork)\nsource(\"../R/casas_traducir_geo.R\")\nset.seed(68821)\n# dividir muestra\ncasas_split &lt;- initial_split(casas, prop = 0.75)\n# obtener muestra de entrenamiento\ncasas_entrena &lt;- training(casas_split)\n# graficar\ng_1 &lt;- ggplot(casas_entrena, aes(x = precio_miles)) +\n  geom_histogram()\ng_2 &lt;- ggplot(casas_entrena, aes(x = area_hab_m2, \n                          y = precio_miles, \n                          colour = condicion_venta)) +\n  geom_point() \ng_1 + g_2\n\n\n\n\nLa variable de condición de venta no podemos utilizarla para predecir, pues sólo la conocemos una vez que la venta se hace. Podemos ver en lugar de eso solamente las de condición normal. Consideramos además del área habitable, por ejemplo, la calidad general de terminados:\n\nggplot(casas_entrena |&gt;  \n       filter(condicion_venta == \"Normal\") |&gt;  \n       mutate(calidad_grupo = \n        cut(calidad_gral, breaks = c(0, 5, 7, 8, 10))), \n  aes(x = area_hab_m2, \n      y = precio_miles,\n      colour = calidad_grupo)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE, formula = \"y ~ x\")\n\n\n\n\nPrecio vs área y calidad\n\n\n\n\nVemos que estas dos variables que hemos usado explican buena parte de la variación de los precios de las casas. Podemos examinar otras variables como la existencia y tamaño del garage:\n\nggplot(casas_entrena |&gt;  filter(condicion_venta == \"Normal\"),\n       aes(x = area_hab_m2, y = precio_miles, colour = area_garage_m2)) +\n  geom_point(alpha = 0.5) + facet_wrap(~ (area_garage_m2 == 0))\n\n\n\n\nY quizá podríamos proponer una fórmula simple de la forma:\n\\[Precio = a_{calidad} + b_{calidad}\\textrm{Area} + c \\textrm{AreaGarage} + d\\textrm{TieneGarage}\\]\ndonde los valores de \\(a_{calidad}, b_{calidad}, c, d\\) podríamos estimarlos de los datos. La pendiente de Area dependende de la calificación de la calidad de los terminados.\nNuestro proceso comenzaría entonces construir los datos para usar en el modelo:\n\nreceta_casas &lt;- \n  recipe(precio_miles ~ area_hab_m2 + calidad_gral + \n           area_garage_m2, \n         data = casas_entrena) |&gt;  \n  step_cut(calidad_gral, breaks = c(3, 5, 6, 7, 8)) |&gt;  \n  step_normalize(starts_with(\"area\")) |&gt; \n  step_mutate(tiene_garage = ifelse(area_garage_m2 &gt; 0, 1, 0)) |&gt; \n  step_dummy(calidad_gral) |&gt; \n  step_interact(terms = ~ area_hab_m2:starts_with(\"calidad_gral\")) \n\nDefinimos el tipo de modelo que queremos ajustar, creamos un flujo y ajustamos\n\n# modelo\ncasas_modelo &lt;- linear_reg() |&gt; \n  set_engine(\"lm\")\n# flujo\nflujo_casas &lt;- workflow() |&gt; \n  add_recipe(receta_casas) |&gt; \n  add_model(casas_modelo)\n# ajustar flujo\najuste &lt;- fit(flujo_casas, casas_entrena)\najuste\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: linear_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_cut()\n• step_normalize()\n• step_mutate()\n• step_dummy()\n• step_interact()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:\nstats::lm(formula = ..y ~ ., data = data)\n\nCoefficients:\n                       (Intercept)                         area_hab_m2  \n                           111.124                              22.505  \n                    area_garage_m2                        tiene_garage  \n                            12.014                               3.230  \n               calidad_gral_X.3.5.                 calidad_gral_X.5.6.  \n                            30.104                              54.623  \n               calidad_gral_X.6.7.                 calidad_gral_X.7.8.  \n                            79.565                             119.639  \n              calidad_gral_X.8.10.   area_hab_m2_x_calidad_gral_X.3.5.  \n                           217.099                              -7.942  \n area_hab_m2_x_calidad_gral_X.5.6.   area_hab_m2_x_calidad_gral_X.6.7.  \n                             2.839                              14.141  \n area_hab_m2_x_calidad_gral_X.7.8.  area_hab_m2_x_calidad_gral_X.8.10.  \n                            14.221                              -1.421  \n\n\nY ahora podemos hacer predicciones para nuevos datos no observados en el entrenamiento:\n\nset.seed(8)\ncasas_prueba &lt;- testing(casas_split) \nejemplos &lt;- casas_prueba|&gt; sample_n(5)\npredict(ajuste, ejemplos) |&gt; \n  bind_cols(ejemplos |&gt; select(precio_miles, area_hab_m2)) |&gt; \n  arrange(desc(precio_miles)) |&gt; gt() |&gt; \n  fmt_number(columns = everything(), decimals = 1)\n\n\n\n\n\n  \n    \n    \n      .pred\n      precio_miles\n      area_hab_m2\n    \n  \n  \n    242.3\n275.0\n152.9\n    177.3\n181.0\n155.6\n    169.3\n175.5\n132.1\n    123.1\n133.0\n117.8\n    115.6\n128.5\n90.2\n  \n  \n  \n\n\n\n\nY finalmente podemos evaluar nuestro modelo. En este casos mostramos diversas métricas como ejemplo:\n\nmetricas &lt;- metric_set(mape, mae, rmse)\nmetricas(casas_prueba |&gt; bind_cols(predict(ajuste, casas_prueba)), \n     truth = precio_miles, estimate = .pred) |&gt; gt() |&gt; \n  fmt_number(columns = where(is_double), decimals = 1)\n\n\n\n\n\n  \n    \n    \n      .metric\n      .estimator\n      .estimate\n    \n  \n  \n    mape\nstandard\n14.1\n    mae\nstandard\n23.4\n    rmse\nstandard\n33.3\n  \n  \n  \n\n\n\n\n\ncasas_prueba_f &lt;- filter(casas_prueba,\n  condicion_venta %in% c(\"Normal\", \"Partial\", \"Abnorml\"))\nggplot(casas_prueba_f |&gt;\n       bind_cols(predict(ajuste, casas_prueba_f)),\n       aes(x = .pred, y = precio_miles)) +\n  geom_point() +\n  geom_abline(colour = \"red\") + facet_wrap(~ condicion_venta)\n\n\n\n\nEste modelo tiene algunos defectos y todavía tiene error considerablemente grande. La mejora sin embargo podemos cuantificarla con un modelo base o benchmark. En este caso utilizamos el siguiente modelo simple, cuya predicción es el promedio de entrenamiento:\n\n# nearest neighbors es grande, así que la predicción\n# es el promedio de precio en entrenamiento\ncasas_promedio &lt;- nearest_neighbor(\n    neighbors = 1000, weight_func = \"rectangular\") |&gt;\n  set_mode(\"regression\") |&gt; \n  set_engine(\"kknn\")\nworkflow_base &lt;- workflow() |&gt; \n  add_recipe(receta_casas) |&gt; \n  add_model(casas_promedio)\najuste_base &lt;- fit(workflow_base, casas_entrena)\nmetricas(casas_prueba |&gt; bind_cols(predict(ajuste_base, casas_prueba)), \n     truth = precio_miles, estimate = .pred)|&gt; gt() |&gt; \n  fmt_number(columns = where(is_double), decimals = 1)\n\n\n\n\n\n  \n    \n    \n      .metric\n      .estimator\n      .estimate\n    \n  \n  \n    mape\nstandard\n33.4\n    mae\nstandard\n54.8\n    rmse\nstandard\n77.2"
  },
  {
    "objectID": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "href": "01-introduccion.html#aprendizaje-supervisado-y-no-supervisado",
    "title": "1  Introducción",
    "section": "1.4 Aprendizaje supervisado y no supervisado",
    "text": "1.4 Aprendizaje supervisado y no supervisado\nLas tareas de aprendizaje se dividen en dos grandes partes: aprendizaje supervisado y aprendizaje no supervisado.\nEn Aprendizaje supervisado buscamos construir un modelo o algoritmo para predecir o estimar un target o una respuesta a partir de ciertas variables de entrada.\nPredecir y estimar, en este contexto, se refieren a cosas similares. Generalmente se usa predecir cuando se trata de variables que no son observables ahora, sino en el futuro, y estimar cuando nos interesan variables actuales que no podemos observar ahora por costos o por la naturaleza del fenómeno.\nPor ejemplo, para identificar a los clientes con alto riesgo de impago de tarjeta de crédito, utilizamos datos históricos de clientes que han pagado y no han pagado. Con estos datos entrenamos un algoritmo para detectar anticipadamente los clientes con alto riesgo de impago.\nUsualmente dividimos los problemas de aprendizaje supervisado en dos tipos, dependiendo de la variables salida:\n\nProblemas de regresión: cuando la salida es una variable numérica. El ejemplo de estimación de ingreso es un problema de regresión\nProblemas de clasificación: cuando la salida es una variable categórica. El ejemplo de detección de dígitos escritos a manos es un problema de clasificación.\n\nEn contraste, en Aprendizaje no supervisado no hay target o variable respuesta. Buscamos modelar y entender las relaciones entre variables y entre observaciones, o patrones importantes o interesantes en los datos.\nLos problemas supervisados tienen un objetivo claro: hacer las mejores predicciones posibles bajo ciertas restricciones. Los problemas no supervisados tienden a tener objetivos más vagos, y por lo mismo pueden ser más difíciles."
  },
  {
    "objectID": "02-principios-supervisado.html#población-y-pérdida",
    "href": "02-principios-supervisado.html#población-y-pérdida",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.1 Población y pérdida",
    "text": "2.1 Población y pérdida\nSupongamos que tenemos una población grande de observaciones potenciales de la forma\n\\[(x_1, x_2, \\ldots, x_p, y) \\]\nY para esa población nos interesa predecir una variable respuesta \\(y\\) numérica en términos de variables de entrada disponibles \\(x = (x_1,x_2,\\ldots, x_p)\\):\n\\[(x_1, x_2, \\ldots, x_p) \\to y\\]\nEl proceso que produce la salida \\(y\\) a partir de las entradas es típicamente muy complejo y dificíl de describir de forma mecanística (por ejemplo, el ingreso dadas características de los hogares).\n\nEjemplo\nPara ilustrar esta discusión teórica, consideraremos datos simulados. La población está dada por el siguiente proceso generador de datos:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(patchwork)\nlibrary(gt)\ngenera_datos &lt;- function(n = 500, tipo = NULL){\n  dat_tbl &lt;- tibble(nse = runif(n, 0, 100)) |&gt;\n    mutate(estudio_años = floor(rnorm(n, 1.5 * sqrt(nse), 1))) |&gt;\n    mutate(estudio_años = pmax(0, pmin(17, estudio_años))) |&gt; \n    mutate(habilidad = rnorm(n, 100 + 0.1 * nse, 1)) |&gt; \n    mutate(z = 100 + (habilidad/100) * ( 20 * nse + 5 * (estudio_años))) |&gt; \n    mutate(ingreso = pmax(0, 0.2*(z + rnorm(n, 0, 150))))\n  obs_tbl &lt;- dat_tbl |&gt; \n    mutate(tipo = tipo, id = 1:n)\n  obs_tbl |&gt; select(id, tipo, x = estudio_años, y = ingreso)\n}\n\nTenemos una sola entrada y una respuesta numérica, y una muestra se ve como sigue:\n\nset.seed(1234)\ndatos_tbl &lt;- genera_datos(n = 500, tipo = \"entrena\")\nggplot(datos_tbl, aes(x = x, y = y)) + geom_jitter(width = 0.3) +\n  xlab(\"Años de estudio\") + ylab(\"Ingreso anual (miles)\")\n\n\n\n\n\nBuscamos construir una función \\(f\\) tal que si observamos cualquier \\(x = (x_1, x_2, \\ldots, x_p) \\to y\\), entonces nuestra predicción es\n\\[\\hat{y} = f(x_1, x_2, \\ldots, x_p) = f(x).\\] Con esta regla o algoritmo \\(f\\) queremos predecir con buena precisión el valor de \\(y\\). Esta \\(f\\), como explicamos antes, puede ser producida de muy distintas maneras (experiencia, reglas a mano, datos, etc.)\nNuestra primera tarea es definir qué quiere decir predecir con buena precisión.\nPara hacer esto tenemos que introducir una medida del error, que llamamos en general función de pérdida.\n\n\n\n\n\n\nFunción de pérdida y error de predicción\n\n\n\nSi el verdadero valor observado es \\(y\\) y nuestra predicción es \\(f(x)\\), denotamos la pérdida asociada a esta observación como \\[L(y, f(x))\\] Para medir el desempeño general de la regla \\(f\\), consideramos su valor esperado, el error de predicción, que es el promedio sobre toda la población:\n\\[Err(f) = E[L(y, f(x))]\\]\nEste es el error que obtendríamos promediando las pérdidas sobre toda la población de interés.\n\n\nObservación: Para fijar ideas, podríamos usar por ejemplo la pérdida absoluta \\(L(y, f(x)) = |y - f(x)|\\) o la pérdida cuadrática \\(L(y, f(x)) = (y - f(x))^2\\).\nAl menos en teoría, podemos encontrar una \\(f\\) que minimiza esta pérdida:\n\n\n\n\n\n\nPredictor óptimo\n\n\n\nPara una población dada, el predictor óptimo (teórico) es\n\\[f^* = \\underset{f}{\\mathrm{argmin}} E[L(y, f(x))].\\]\nEs decir: el mínimo error posible que podemos obtener es \\(Err(f^*)\\). Para cualquier otro predictor \\(f\\) tenemos que \\(Err(f) \\geq Err(f^*).\\)\n\n\nPor ejemplo si usamos la pérdida cuadrática \\(L(y, f(x)) = (y - f(x))^2\\), entonces puede mostrarse que\n\\[f^*(x) = E(y | x)\\] de forma que \\(f^*\\) es la media condicional de la \\(y\\) dado que sabemos que las entradas son \\(x\\). Si usáramos la pérdida absoluta \\(L(y, f(x)) = |y - f(x)|\\) entonces \\[f^*(x) = \\textrm{mediana}(y|x).\\] Distintas funciones de pérdida dan distintas soluciones teóricas. Por ejemplo, si existen valores atípicos en \\(y\\) producidos por errores de registro o medición, usar la pérdida absoluta puede dar mejores resultados que la cuadrática, que tiende a dar mayor peso a errores grandes.\nObservaciones:\n\nPodemos ver nuestra tarea entonces como una de ajuste de curvas: queremos aproximar tan bien como sea posible la función \\(f^*(x)\\).\nNo es simple decidir qué función de pérdida debería utilizarse para un problema dado de predicción.\nGeneralmente es una combinación de costos/beneficios del problema que tratamos, conveniencia computacional, y cómo se comportan los errores de nuestros predictores bajo distintas pérdidas. Sin embargo, al principio del proceso de construcción de modelos es mejor escoger una métrica simple que capture a grandes rasgos el comportamiento que esperamos (pérdida cuadrática, absoluta o logarítmica por ejemplo).\nMuchas veces es mejor considerar el problema de selección de la pérdida desde dos ángulos: el primero es computacional y de propiedades de la predicción, y el segundo tiene que ver con costos y beneficios asociados al problema que queremos resolver. Para el primero, alguna de las pérdidas estándar (como las que vimos arriba, cuadrática y absoluta, ologarítmica) son usualmente suficiente. En el segundo enfoque, el análisis es generalmente involucra más aspectos particulares del problema y generalmente tiene que hacerse de manera ad-hoc.\n\n\n\nEjemplo\nSupongamos que nos interesa minimizar la pérdida cuadrática. Si tomamos una muestra muy grande (para este problema), podemos aproximar la predicción óptima directamente. Abajo graficamos nuestra muestra chica de datos junto con una buena aproximación del predictor óptimo:\n\npoblacion_tbl &lt;- genera_datos(n = 50000, tipo = \"poblacion\")\n# calcular óptimo\npreds_graf_tbl &lt;- poblacion_tbl |&gt; \n  group_by(x) |&gt; # condicionar a x\n  summarise(.pred = mean(y)) |&gt; # media en cada grupo\n  mutate(predictor = \"_óptimo\")\n# graficar con una muestra grande\nggplot(datos_tbl, aes(x = x)) +\n  geom_jitter(aes(y = y), colour = \"red\") + \n  geom_line(data = preds_graf_tbl, aes(y = .pred, colour = predictor), \n    linewidth = 1.1) +\n  xlab(\"Años de estudio\") + ylab(\"Ingreso anual (miles)\")"
  },
  {
    "objectID": "02-principios-supervisado.html#estimando-el-desempeño-y-datos-de-prueba",
    "href": "02-principios-supervisado.html#estimando-el-desempeño-y-datos-de-prueba",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.2 Estimando el desempeño y datos de prueba",
    "text": "2.2 Estimando el desempeño y datos de prueba\nPara obtener una estimación de la pérdida para una función \\(f\\) que usamos para hacer predicciones, podemos tomar una muestra de datos del proceso generador:\n\\[{\\mathcal T} = \\{(\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}), (\\mathbf{x}^{(2)}, \\mathbf{y}^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, \\mathbf{y}^{(m)})\\},\\]\nCompararíamos entonces las respuestas observadas \\(\\mathbf{y^{(i)}}\\) con las predicciones \\(f(\\mathbf{x^{(i)}})\\). Ahora resumimos evaluando el error promedio sobre los datos de prueba. El error de prueba de \\(f\\) es\n\\[ \\widehat{Err}(f) = \\frac{1}{m} \\sum_{i=1}^m L(\\mathbf{y}^{(i)} , f(\\mathbf{x}^{(i)}))\\] Por ejemplo, si usamos la pérdida cuadrática,\n\\[ \\widehat{Err}(f) = \\frac{1}{m} \\sum_{i=1}^m (\\mathbf{y}^{(i)} - f(\\mathbf{x}^{(i)}))^2\\] Si \\(m\\) es grande, entonces tenemos por la ley de los grandes números que \\[Err(f) \\approx \\widehat{Err} (f)\\] Podemos también estimar el error de estimación de \\(\\widehat{Err}(f)\\) con técnicas estándar, por ejemplo bootstrap o aproximación normal.\nObervación: nótese que en estos cálculos no es necesario hacer ningún supuesto acerca de \\(f\\), que en este argumento está fija y no utiliza la muestra de prueba.\n\nEjemplo: óptimo\nSupongamos que \\(f\\) es el predictor óptimo que obtuvimos arriba (pero esto aplica para cualquier otra función \\(f\\) que usemos para hacer predicciones). Tomamos una muestra de prueba, y evaluamos usando la raíz de la pérdida cuadrática media:\n\nprueba_tbl &lt;- genera_datos(n = 2000, tipo = \"prueba\")\neval_tbl &lt;- prueba_tbl |&gt;  \n  left_join(preds_graf_tbl, by = \"x\") \nresumen_tbl &lt;- eval_tbl |&gt;  \n  group_by(predictor, tipo) |&gt; \n  rmse(truth = y, estimate = .pred) \nfmt_resumen &lt;- function(resumen_tbl){\n  resumen_tbl |&gt; \n    select(-.estimator) |&gt; \n    pivot_wider(names_from = tipo, values_from = .estimate) |&gt; \n    gt() |&gt; \n    fmt_number(where(is_double), decimals = 0)\n}\nfmt_resumen(resumen_tbl)\n\n\n\n\n\n  \n    \n    \n      predictor\n      .metric\n      prueba\n    \n  \n  \n    _óptimo\nrmse\n49\n  \n  \n  \n\n\n\n\nEste es nuestro error de prueba. Como la muestra de prueba no es muy grande, podríamos usar un método estándar para estimar su precisión, por ejemplo con bootstrap.\n\n\nEjemplo: regla\nAhora probemos con otro predictor, por ejemplo, supongamos que estamos usando la regla de “cada año de escolaridad aumenta ingresos potenciales en 20 unidades”, un predictor construido con reglas manuales que es\n\nf_regla &lt;- function(x){\n  20 * x\n}\n\nAbajo lo graficamos en comparación con el modelo óptimo:\n\naños_x &lt;- tibble(x = seq(0, 17, by = 0.5))\npreds_regla_tbl &lt;- años_x |&gt; \n  mutate(.pred = f_regla(x), predictor = \"regla\")\npreds_graf_tbl &lt;- bind_rows(preds_regla_tbl, preds_graf_tbl)\nggplot(datos_tbl, aes(x = x)) +\n  geom_point(aes(y = y), colour = \"red\", alpha = 0.2) +\n  geom_line(data = preds_graf_tbl, aes(y = .pred, colour = predictor), size = 1.1) \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\neval_tbl &lt;- prueba_tbl |&gt;  \n  left_join(preds_graf_tbl, by = \"x\") \n\nWarning in left_join(prueba_tbl, preds_graf_tbl, by = \"x\"): Detected an unexpected many-to-many relationship between `x` and `y`.\nℹ Row 1 of `x` matches multiple rows in `y`.\nℹ Row 21 of `y` matches multiple rows in `x`.\nℹ If a many-to-many relationship is expected, set `relationship =\n  \"many-to-many\"` to silence this warning.\n\nresumen_tbl &lt;- eval_tbl |&gt;  \n  group_by(predictor, tipo) |&gt; \n  rmse(truth = y, estimate = .pred) \nfmt_resumen(resumen_tbl)\n\n\n\n\n\n  \n    \n    \n      predictor\n      .metric\n      prueba\n    \n  \n  \n    _óptimo\nrmse\n49\n    regla\nrmse\n91\n  \n  \n  \n\n\n\n\nObserva que el error es considerablemente mayor que el error que obtuvimos con el predictor óptimo del ejemplo anterior. Quisiéramos buscar algoritmos que tengan mejor desempeño aprendiendo de datos anteriores."
  },
  {
    "objectID": "02-principios-supervisado.html#aprendizaje",
    "href": "02-principios-supervisado.html#aprendizaje",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.3 Aprendizaje supervisado",
    "text": "2.3 Aprendizaje supervisado\nEn aprendizaje supervisado, buscamos construir la función \\(f\\) de manera automática usando datos. Supongamos entonces que tenemos un conjunto de datos etiquetados (sabemos la \\(y\\) correspondiente a cada \\(x\\)):\n\\[{\\mathcal L}=\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \\ldots, (x^{(N)}, y^{(N)}) \\}\\]\nque llamamos conjunto de entrenamiento.\nUn algoritmo de aprendizaje (aprender de los datos automáticamente) es una regla que asigna a cada conjunto de entrenamiento \\({\\mathcal L}\\) una función \\(\\hat{f}\\):\n\\[{\\mathcal L} \\to \\hat{f} = f_{\\mathcal L} \\]\nUna vez que construimos la función \\(\\hat{f}\\), podemos hacer predicciones.\nEl desempeño del predictor particular \\(\\hat{f}\\) se mide igual que antes: observamos otra muestra \\({\\mathcal T}\\), que llamamos muestra de prueba,\n\\[{\\mathcal T} = \\{(\\mathbf{x}^{(1)}, \\mathbf{y}^{(1)}), (\\mathbf{x}^{(2)}, \\mathbf{y}^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, \\mathbf{y}^{(m)})\\},\\]\ny calculamos el error de prueba. Si suponemos que \\(m\\) es suficientemente grande:\n\\[ \\widehat{Err}(\\hat{f}) = \\frac{1}{m} \\sum_{i=1}^m L(\\mathbf{y}^{(i)} , \\hat{f}(\\mathbf{x}^{(i)})) \\]\nes una buena aproximación del error de predicción \\(Err(\\hat{f})\\).\nAdicionalmente, definimos otra cantidad de menor interés, el error de entrenamiento, como\n\\[\\overline{err} = \\frac{1}{N}\\sum_{i=1}^N L(y^{(i)} , \\hat{f}(x^{(i)})).\\] que es una medida de qué tan bien se ajusta a \\(\\hat{f}\\) a los datos con los que se entrenó \\(\\hat{f}\\). Usualmente esta cantidad no es apropiada para medir el desempeño de un predictor, pues el algoritmo \\(\\hat{f}\\) incluye las “respuestas” \\(y_i\\) en su construcción, de forma que tiende a ser una estimación optimista del error de predicción.\n\nEjemplo: vecinos más cercanos\nConsideremos usar un método de \\(k\\)-vecinos más cercanos para resolver este problema. Este método es simple: si queremos hacer una predicción en las entradas \\(x\\), buscamos los puntos de entrenamiento con entradas \\(x^{(i)}\\) más cercanas a \\(x\\), que denotamos como \\(N_k(x)\\). Tomamos las \\(y\\) correspondientes a estas \\(x\\) y las usamos para hacer nuestra predicción:\n\\[f_2(x) = \\frac{1}{k}\\sum_{x^{(i)} \\in N_k(x)} y^{(i)}\\]\nPrimero obtendremos una muestra de entrenamiento:\n\nset.seed(12)\nentrena_tbl &lt;- genera_datos(n = 20, tipo = \"entrena\")\n\nEn nuestro ejemplo, en lugar de usar un número fijo de vecinos, utilizaremos 10% de los datos más cercanos al punto donde queremos predecir:\n\n# modelo\nmodelo_kvecinos &lt;- nearest_neighbor(\n    neighbors = nrow(entrena_tbl) * 0.1, \n    weight_func = \"gaussian\") |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"kknn\")\n# preprocesamiento\nreceta &lt;- recipe(y ~ x, data = entrena_tbl |&gt; select(x, y))\n# flujo\nflujo &lt;- workflow() |&gt; \n  add_recipe(receta) |&gt; \n  add_model(modelo_kvecinos)\n# Ajustamos flujo\nflujo_ajustado_vecinos &lt;- fit(flujo, entrena_tbl)\n\nHacemos predicciones y calculamos el error:\n\neval_tbl &lt;- bind_rows(prueba_tbl, entrena_tbl) \nresumen_vmc_tbl &lt;- \n  predict(flujo_ajustado_vecinos, eval_tbl) |&gt; \n  mutate(predictor = \"vecinos\") |&gt; \n  bind_cols(eval_tbl) |&gt; \n  group_by(predictor, tipo) |&gt; \n  rmse(truth = y, estimate = .pred) \nfmt_resumen(resumen_vmc_tbl)\n\n\n\n\n\n  \n    \n    \n      predictor\n      .metric\n      entrena\n      prueba\n    \n  \n  \n    vecinos\nrmse\n36\n65\n  \n  \n  \n\n\n\n\nEl error de prueba, que es el que nos interesa hacer chico, es considerablemente grande. Si graficamos podemos ver el problema:\n\npreds_vmc &lt;- predict(flujo_ajustado_vecinos, años_x) |&gt; \n  bind_cols(años_x) |&gt; mutate(predictor = \"vecinos\")\npreds_graf_tbl &lt;- bind_rows(preds_vmc, preds_graf_tbl |&gt; \n  filter(predictor == \"_óptimo\"))\ng_1 &lt;- ggplot(entrena_tbl, aes(x = x)) +\n  geom_line(data = preds_graf_tbl |&gt; filter(predictor != \"regla\"), \n            aes(y = .pred, colour = predictor), size = 1.1) +\n  geom_point(aes(y = y), colour = \"red\") +\n  labs(subtitle = \"Óptimo vs ajustado\")\ng_1\n\n\n\n\nDonde vemos que este método intenta interpolar los datos, capturando ruido y produciendo variaciones que lo alejan del modelo óptimo. Esto lo notamos en lo siguiente:\n\nHay una brecha grande entre el error de entrenamiento y el error predictivo.\nEsta estimación de vecinos más cercanos es muy dependiente de la muestra de entrenamiento que obtengamos, pues intenta casi interpolar los datos. Esto sugiere alta variabilidad de las predicciones dependiendo de la muestra particular de entrenamiento que utilizamos.\nDecimos que este predictor está sobreajustado.\n\n\n\nEjemplo: regresión lineal\nAhora intentaremos con un modelo lineal. En este caso, utilizamos un predictor de la forma\n\\[f(x) = \\beta_0 + \\beta_1x\\] Usamos la muestra de entrenamiento para encontrar la \\(\\beta_0\\) y \\(\\beta_1\\) que minimizar el error sobre los datos disponibles de entrenamiento, lo cual es un problema de optimización relativamente fácil. Usamos entonces \\[\\hat{f}(x) =\\hat{\\beta}_0 + \\hat{\\beta}_1 x\\] para hacer nuestras predicciones.\n\nmodelo_lineal &lt;- linear_reg() |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"lm\")\nflujo_lineal &lt;- workflow() |&gt; \n  add_recipe(receta) |&gt; \n  add_model(modelo_lineal)\n# Ajustamos\nflujo_ajustado_lineal &lt;- fit(flujo_lineal, entrena_tbl)\n\nHacemos predicciones y calculamos el error:\n\neval_tbl &lt;- bind_rows(prueba_tbl, entrena_tbl) \nresumen_lineal_tbl &lt;- \n  predict(flujo_ajustado_lineal, eval_tbl) |&gt; \n  mutate(predictor = \"lineal\") |&gt; \n  bind_cols(eval_tbl) |&gt; \n  group_by(predictor, tipo) |&gt; \n  rmse(truth = y, estimate = .pred) \nfmt_resumen(bind_rows(resumen_vmc_tbl, resumen_lineal_tbl))\n\n\n\n\n\n  \n    \n    \n      predictor\n      .metric\n      entrena\n      prueba\n    \n  \n  \n    vecinos\nrmse\n36\n65\n    lineal\nrmse\n49\n56\n  \n  \n  \n\n\n\n\nY el desempeño de este método es mejor que vecinos más cercanos (ver columna de prueba).\n\npreds_1 &lt;- predict(flujo_ajustado_lineal, tibble(x = 0:17)) |&gt; \n  bind_cols(tibble(x = 0:17, predictor = \"lineal\"))\npreds_graf_tbl &lt;- bind_rows(preds_1, preds_graf_tbl)\ng_1 &lt;- ggplot(datos_tbl, aes(x = x)) +\n  geom_point(aes(y = y), colour = \"red\", alpha = 0.1) +\n  geom_line(data = preds_graf_tbl |&gt; filter(predictor %in% c(\"_óptimo\", \"lineal\")), \n            aes(y = .pred, colour = predictor), size = 1.1) +\n  labs(subtitle = \"Óptimo vs ajustado\")\ng_1\n\n\n\n\nEn este caso:\n\nNo hay brecha tan grande entre el error de entrenamiento y el error predictivo\nObservamos patrones claros de desajuste: el predictor lineal no captura el patrón curvo que presentan los datos: en la parte media de las \\(x\\) tiende a producir predicciones demasiado altas y lo contario ocurre en los extremos\nDecimos que esté modelo presenta subajuste."
  },
  {
    "objectID": "02-principios-supervisado.html#entendiendo-el-error-de-predicción",
    "href": "02-principios-supervisado.html#entendiendo-el-error-de-predicción",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.4 Entendiendo el error de predicción",
    "text": "2.4 Entendiendo el error de predicción\nEstos dos ejemplos de predictores tienen mal desempeño (comparado con el óptimo por distintas razones. Para entender qué pasa, consideramos los residuales de cada ajuste, para un caso de prueba:\n\\[\\mathbf{y} - \\hat{f_{\\mathcal{L}}}(\\mathbf{x})\\] Esta cantidad puede tener un valor positivo o negativo grande, lo que indica errores grandes. Sea \\(f^*\\) el predictor óptimo que explicamos arriba. Entonces, en primer lugar:\n\\[\\mathbf{y} - \\hat{f_{\\mathcal{L}}}(\\mathbf{x}) = \\underbrace{(f^* (\\mathbf{x}) - \\hat{f_{\\mathcal{L}}}(\\mathbf{x}))}_\\text{reducible} + \\underbrace{(\\mathbf{y}- f^*(\\mathbf{x}))}_\\text{irreducible}.\\] donde vemos que si las dos cantidades de la derecha están cercanas a cero, entonces el residual es cercano a cero (la predicción es precisa):\n\nError irreducible: no depende de nuestro algoritmo, sino de la información que tenemos en \\(x\\) para predecir \\(y\\). Si queremos hacer esté error más chico, necesitamos incluir otras variables \\(x\\) relevantes para predecir \\(y\\).\nError reducible: qué tan lejos nuestro método está del óptimo. Podemos mejorar este error seleccionando nuestra muestra de entrenamiento y método de predicción \\(\\hat{f}\\) de manera adecuada.\n\nEn nuestros dos ejemplos anteriores, el error reducible era considerablemente grande (como podemos verificar comparando con el predictor óptimo, que sólo sufre de error irreducible). Pero la razón por la que ese error reducible es grande es diferente en cada caso.\nPara explicar la diferencia, podemos considerar \\(f_{lim},\\) el predictor que obtendríamos con nuestro método si ajustáramos nuestro método con la población completa, de manera que \\(\\hat{f_{\\mathcal{L}}}\\to f_{\\lim}\\) cuando el tamaño de la muestra de entrenamiento \\({\\mathcal{L}}\\) se hace muy grande.\nPodemos refinar nuestra descomposición y escribir:\n\\[\\mathbf{y} - \\hat{f_{\\mathcal{L}}}(\\mathbf{x}) = \\underbrace{f^* (\\mathbf{x}) - f_{\\lim}(\\mathbf{x})}_\\text{sesgo-especificacion} +\n  \\underbrace{f_{\\lim}(\\mathbf{x}) - \\hat{f_{\\mathcal{L}}}(\\mathbf{x})}_\\text{error-estimacion} +\n  \\underbrace{y - f^*(\\mathbf{x})}_\\text{irreducible}.\\]\nEl error reducible ahora se descompone en dos partes:\n\nEl sesgo de especificacion: que se debe a la incapacidad de nuestro modelo de capturar la forma del predictor óptimo, incluso conociendo toda la población. Este término no depende de la muestra de entrenamiento: depende de la capacidad de nuestro método para aprender en condiciones ideales.\nEl error de estimación: este error resulta de que tenemos información limitada de la población, y nuestro ajuste se aleja de lo que obtendríamos con información completa. Esta parte del error varía dependiendo de la muestra particular de entrenamiento que utilizamos.\n\nEn nuestros dos ejemplos, intuímos que vecinos más cercanos sufre más de error de estimación y regresión lineal de sesgo de especificación, lo cual verificamos más adelante.\nPodemos refinar aún más nuestra descomposición considerando qué pasa con distintas muestras del mismo tamaño para entender mejor el error de estimación. Si consideramos el valor esperado de nuestra predicción a lo largo de las posibles muestras \\(\\mathcal L\\) que podemos extraer, descomponemos el segundo término como:\n\\[\\hat{f_{\\mathcal{L}}}(\\mathbf{x}) - f_{\\lim}(\\mathbf{x})  = \\hat{f_{\\mathcal{L}}}(\\mathbf{x}) -  E(\\hat{f_{\\mathcal{L}}}(\\mathbf{x})) + E(\\hat{f_{\\mathcal{L}}}(\\mathbf{x})) - f_{\\lim}(\\mathbf{x}) \\] donde el valor esperado es sobre todas las muestras de entrenamiento de un tamaño fijo \\(n\\) que podríamos obtener. El primer término puede llamarse variabilidad, mientras que el segundo es el sesgo que obtenemos al usar una muestra \\(n\\) finita (para algunos métodos, el segundo término puede ser igual a cero). Desde este punto de vista, podemos hacer también la descomposición:\n\\[\\mathbf{y} - \\hat{f_{\\mathcal{L}}}(\\mathbf{x}) = \\underbrace{f^* (\\mathbf{x}) - f_{lim}(\\mathbf{x})}_\\text{sesgo-especificacion}  + \\underbrace{f_{lim}(\\mathbf{x}) - E(\\hat{f_{\\mathcal{L}}}(\\mathbf{x}))}_\\text{sesgo-estimacion} +   \\underbrace{E(\\hat{f_{\\mathcal{L}}}(\\mathbf{x})) - \\hat{f_{\\mathcal{L}}}(\\mathbf{x})}_\\text{variabilidad} + \\underbrace{ \\mathbf{y} - f^*(\\mathbf{x})}_\\text{irreducible}.\\]\nTenemos entonces cuatro términos:\n\nEl sesgo de especificación mide la capacidad del modelo de utilizar datos de muestras cada vez más grandes. No depende de una muestra particular ni su tamaño.\nEl sesgo de estimación mide en promedio qué tan lejos está la estimación del ideal con datos completos, y depende de la naturaleza de la muestra de entrenamiento, incluyendo su tamaño.\nLa variabilidad es el único término que depende de la muestra particular que usamos. También depende del tamaño de muestra que utilizamos.\n\nLos dos primeros términos usualmente se agrupan en un sólo término de sesgo, y obtenemos la siguiente definición usual:\n\n\n\n\n\n\nDescomposición sesgo-varianza\n\n\n\nEl error total (la diferencia entre observado y nuestra predicción) se descompone como:\n\\[\\mathbf{y} - \\hat{f_{\\mathcal{L}}}(\\mathbf{x}) = \\underbrace{f^* (\\mathbf{x}) - E(\\hat{f_{\\mathcal{L}}}(\\mathbf{x}))}_\\text{sesgo} +   \\underbrace{E(\\hat{f_{\\mathcal{L}}}(\\mathbf{x})) - \\hat{f_{\\mathcal{L}}}(\\mathbf{x})}_\\text{variabilidad} + \\underbrace{y - f^*(\\mathbf{x})}_\\text{irreducible}.\\]\n\n\nQue explica qué sucede con distintas posibles muestras de entrenamiento de tamaño fijo. El sesgo en este caso significa en promedio qué tan lejos nuestro predictor está del óptimo, y la variabilidad qué tanto puede variar nuestra predicción con respecto al promedio."
  },
  {
    "objectID": "02-principios-supervisado.html#ejemplo-fuentes-de-error",
    "href": "02-principios-supervisado.html#ejemplo-fuentes-de-error",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.5 Ejemplo: fuentes de error",
    "text": "2.5 Ejemplo: fuentes de error\nVamos a ver qué sucede con nuestros dos métodos si utilizamos una muestra grande:\n\nmuestra_grande_tbl &lt;- sample_n(poblacion_tbl, 10000) |&gt; \n  mutate(tipo = \"entrena\")\nmodelo_kvecinos &lt;- nearest_neighbor(\n    neighbors = nrow(muestra_grande_tbl) * 0.10, \n    weight_func = \"gaussian\") |&gt; \n  set_mode(\"regression\") |&gt; \n  set_engine(\"kknn\")\n# Ajustamos (no es necesario usar la población completa para este ejemplo)\nflujo_vecinos &lt;- workflow() |&gt; \n  add_recipe(receta) |&gt; \n  add_model(modelo_kvecinos)\nflujo_ajustado_vecinos_limite &lt;- fit(flujo_vecinos, muestra_grande_tbl)\nflujo_ajustado_lineal_limite &lt;- fit(flujo_lineal, muestra_grande_tbl)\n\neval_tbl &lt;- bind_rows(prueba_tbl, muestra_grande_tbl)\nresumen_vecinos_lim_tbl &lt;- \n  predict(flujo_ajustado_vecinos_limite, eval_tbl) |&gt; \n  mutate(predictor = \"vecinos_limite\") |&gt; \n  bind_cols(eval_tbl) |&gt; \n  group_by(predictor, tipo) |&gt; \n  rmse(truth = y, estimate = .pred) \nresumen_lineal_lim_tbl &lt;- \n  predict(flujo_ajustado_lineal_limite, eval_tbl) |&gt; \n  mutate(predictor = \"lineal_limite\") |&gt; \n  bind_cols(eval_tbl) |&gt; \n  group_by(predictor, tipo) |&gt; \n  rmse(truth = y, estimate = .pred) \nfmt_resumen(bind_rows(resumen_vmc_tbl, \n  resumen_lineal_tbl, \n  resumen_vecinos_lim_tbl, \n  resumen_lineal_lim_tbl) |&gt; arrange(predictor))\n\n\n\n\n\n  \n    \n    \n      predictor\n      .metric\n      entrena\n      prueba\n    \n  \n  \n    lineal\nrmse\n49\n56\n    lineal_limite\nrmse\n54\n54\n    vecinos\nrmse\n36\n65\n    vecinos_limite\nrmse\n49\n49\n  \n  \n  \n\n\n\n\n¿Qué patrones ves en esta tabla? Podemos también graficar para entender mejor qué está pasando:\n\npreds_1 &lt;- predict(flujo_ajustado_vecinos_limite, tibble(x = 0:17)) |&gt; \n  bind_cols(tibble(x = 0:17, predictor = \"vecinos_limite\"))\npreds_2 &lt;- predict(flujo_ajustado_lineal_limite, tibble(x = 0:17)) |&gt; \n  bind_cols(tibble(x = 0:17, predictor = \"lineal_limite\"))\npreds_graf_tbl &lt;- bind_rows(preds_1, preds_2, preds_graf_tbl) |&gt; \n  mutate(predictor = factor(predictor))\ng_1 &lt;- ggplot(datos_tbl, aes(x = x)) +\n  geom_line(data = preds_graf_tbl |&gt; \n            filter(str_detect(predictor, \"vecinos|_óptimo\")), \n            aes(y = .pred, colour = predictor), size = 1.1) +\n  labs(subtitle = \"Vecinos\") \ng_2 &lt;- ggplot(datos_tbl, aes(x = x)) +\n  geom_line(data = preds_graf_tbl |&gt; \n            filter(str_detect(predictor, \"lineal|_óptimo\")), \n            aes(y = .pred, colour = predictor), size = 1.1) +\n  labs(subtitle = \"Lineal\") \ng_1 + g_2 + plot_layout(guides = 'collect')\n\n\n\n\nEsto patrón sugiere que:\n\nNuestro método de vecinos más cercanos tiene errores bajos por sesgo, pero tiene error considerable por sobreajuste o variabilidad.\nNuestro método lineal no tiene mucha variabilidad (el estimado con una muestra grande es casi igual al de la muestra de entrenamiento), sino más bien por sesgo.\nEl error por sesgo se reduce usando métodos más flexibles o menos restringidos que puedan capturar patrones claros en los datos.\nPara reducir la variabilidad podemos usar métodos más simples o restringidos que no capturen tanto ruido.\nEl balance de complejidad correcto depende del tamaño de muestra de entrenamiento.\nEl error irreducible se puede reducir incorporando información adicional relevante a las entradas.\n\n\n\n\n\n\n\nComplejidad y error de predicción\n\n\n\nPara un tamaño de muestra de entrenamiento fijo,\n\nMétodos de predicción más flexibles o complejos tienden a sufrir más de error por variabilidad, pues dependen fuertemente de la muestra utilizada.\nMétodos de predicción más rígidos o simples tienden a sufrir más error por sesgo, pues dependen menos de la muestra utilizada."
  },
  {
    "objectID": "02-principios-supervisado.html#agregando-más-información-y-error-irreducible",
    "href": "02-principios-supervisado.html#agregando-más-información-y-error-irreducible",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.6 Agregando más información y error irreducible",
    "text": "2.6 Agregando más información y error irreducible\nPodemos ver qué sucede cuando tenemos disponibles más variables relevantes. En este caso, probaremos con dos entradas:\n\ngenera_datos_2 &lt;- function(n = 500, tipo = NULL){\n  dat_tbl &lt;- tibble(nse = runif(n, 0, 100)) |&gt;\n    mutate(estudio_años = floor(rnorm(n, 1.5 * sqrt(nse), 1))) |&gt;\n    mutate(estudio_años = pmax(0, pmin(17, estudio_años))) |&gt; \n    mutate(habilidad = rnorm(n, 100 + 0.1 * nse, 1)) |&gt; \n    mutate(z = 100 + (habilidad/100) * ( 20 * nse + 5 * (estudio_años))) |&gt; \n    mutate(ingreso = pmax(0, 0.2*(z + rnorm(n, 0, 150))))\n  obs_tbl &lt;- dat_tbl |&gt; \n    mutate(tipo = tipo, id = 1:n)\n  obs_tbl |&gt; select(id, tipo, x_1 = estudio_años, x_2 = nse,  y = ingreso)\n}\n\n\nentrena_tbl &lt;- genera_datos_2(20, tipo = \"entrena\")\nprueba_tbl &lt;- genera_datos_2(500, tipo = \"prueba\")\nreceta_2 &lt;- recipe(y ~ x_1 + x_2, data = entrena_tbl)\nflujo_lineal &lt;- workflow() |&gt; \n  add_recipe(receta_2) |&gt; \n  add_model(modelo_lineal)\n# Ajustamos\nflujo_ajustado_lineal &lt;- fit(flujo_lineal, entrena_tbl)\npredict(flujo_ajustado_lineal, bind_rows(entrena_tbl, prueba_tbl)) |&gt; \n  bind_cols(bind_rows(entrena_tbl, prueba_tbl)) |&gt;\n  group_by(tipo) |&gt; \n  rmse(truth = y, estimate = .pred) |&gt; gt() |&gt; \n  fmt_number(.estimate, decimals = 1)\n\n\n\n\n\n  \n    \n    \n      tipo\n      .metric\n      .estimator\n      .estimate\n    \n  \n  \n    entrena\nrmse\nstandard\n27.1\n    prueba\nrmse\nstandard\n31.5\n  \n  \n  \n\n\n\n\nY vemos cómo inmediatamente redujimos el error de predicción: en este caso, aunque la variabilidad aumentó un poco (tenemos más parámetros que estimar vs el modelo con una sola variable), la reducción en el sesgo y en el error irreducible es tan grande que el desempeño es muy superior. Examina el caso de vecinos más cercanos."
  },
  {
    "objectID": "02-principios-supervisado.html#acerca-de-la-estimación-del-error-de-predicción",
    "href": "02-principios-supervisado.html#acerca-de-la-estimación-del-error-de-predicción",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.7 Acerca de la estimación del error de predicción",
    "text": "2.7 Acerca de la estimación del error de predicción\nCuando usamos una muestra de prueba limitada, podemos evaluar la precisión de nuestra estimación del error de predicción usando por ejemplo el bootstrap. En nuestro ejemplo anterior podríamos hacer los siguiente:\n\nlibrary(infer)\npreds &lt;- predict(flujo_ajustado_lineal, bind_rows(prueba_tbl)) |&gt; \n  bind_cols(prueba_tbl) \npreds |&gt; \n  generate(reps = 1000, type = \"bootstrap\", variables = id) |&gt; \n  group_by(replicate, tipo) |&gt; \n  rmse(truth = y, estimate = .pred) |&gt; \n  select(replicate, tipo, stat = .estimate) |&gt;\n  get_ci(level = 0.90) |&gt; \n  gt() |&gt; fmt_number(where(is_double), decimals = 1)\n\nWarning: The `variables` argument is only relevant for the \"permute\" generation\ntype and will be ignored.\n\n\n\n\n\n\n  \n    \n    \n      lower_ci\n      upper_ci\n    \n  \n  \n    29.9\n33.0"
  },
  {
    "objectID": "02-principios-supervisado.html#resumen",
    "href": "02-principios-supervisado.html#resumen",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.8 Resumen",
    "text": "2.8 Resumen\n\n\n\n\n\n\nTarea fundamental del análisis supervisado\n\n\n\n\nUsando datos de entrenamiento \\({\\mathcal L}\\), construimos una funcion \\(\\hat{f}\\) para predecir. Estas funciones se ajustan usualmente intentando estimar directamente el predictor óptimo \\(f^*(x)\\) (si lo conocemos teóricamente), o indirectamente intentando minimizar la pérdida sobre el conjunto de entrenamiento.\nSi observamos nuevos valores \\(\\mathbf{x}\\), nuestra predicción es \\(\\hat{y} = \\hat{f}(\\mathbf{x})\\).\nBuscamos que cuando observemos nuevos casos para predecir, nuestro error de predicción sea bajo en promedio (\\(Err\\) sea bajo).\nUsualmente estimamos \\(Err\\) mediante una muestra de prueba o validación \\({\\mathcal T}\\).\nNos interesan métodos de construir \\(\\hat{f}\\) que produzcan errores de predicción bajos.\n\n\n\n\nNótese que el error de entrenamiento se calcula sobre la muestra \\({\\mathcal L}\\) que se usó para construir \\(\\hat{f}\\), mientras que el error de predicción se estima usando una muestra independiente \\({\\mathcal T}\\).\n\\(\\hat{Err}\\) es una estimación razonable de el error de predicción \\(Err\\) (por ejemplo, \\(\\hat{Err} \\to Err\\) cuando el tamaño de la muestra de prueba crece), pero \\(\\overline{err}\\) típicamente es una estimación mala del error de predicción.\nNótese también que aunque generalmente podemos ajustar reduciendo el error de entrenamiento, lo que queremos es reducir el error de prueba: es decir, el error fuera de la muestra de entrenamiento.\n\n\n\n\n\n\n\nReduciendo el error de predicción\n\n\n\nPara reducir el error de predicción, podemos:\n\nIncluir variables relevantes que reduzcan el error irreducible\nReducir variabilidad usando métodos más estables o menos complejos\nReducir sesgo usando métodos más flexibles\nUsar métodos con la estructura adecuada para el problema\n\nGeneralmente 2 y 3 están en contraposición, a lo que muchas veces se le llama equilibrio de varianza y sesgo. Los puntos 1 y 4 generalmente mejoran los resultados reduciendo tanto sesgo como variabilidad."
  },
  {
    "objectID": "02-principios-supervisado.html#resolver-problemas-con-aprendizaje-automático",
    "href": "02-principios-supervisado.html#resolver-problemas-con-aprendizaje-automático",
    "title": "2  Principios de aprendizaje supervisado",
    "section": "2.9 Resolver problemas con aprendizaje automático",
    "text": "2.9 Resolver problemas con aprendizaje automático\nEn este curso nos concentraremos en la construcción, evaluación y mejora de modelos predictivos. Para que estas ideas funcionen en problemas reales, hay más aspectos a considerar que no discutiremos con tanto detalle, pues en general están muy ligados al problema particular de predicción que nos interesa (y muchas veces son considerablemente más difíciles de la teoría y los algoritmos):\n\nPara entender exactamente cuál es el problema que queremos resolver se requiere trabajo analítico considerable, y también trabajo en entender aspectos del área o negocio donde nos interesa usar aprendizaje máquina. Muchas veces es fácil resolver un problema muy preciso, que tenemos a la mano, pero que más adelante nos damos cuenta de que no es útil.\nEstos dos puntos incluyen indentificar las métricas que queremos monitorear y mejorar, lo cual no siempre es claro. Optimizar métricas incorrectas es poco útil en el mejor de los casos, y en los peores pueden causar daños. Evitar esto requiere monitoreo constante de varios aspectos del funcionamiento de nuestros modelos y sus consecuencias.\n¿Cómo poner en producción modelos y mantenerlos? Un flujo apropiado de trabajo, que comienza con pipelines de preproceso y heurísticas simples, para después utilizar modelos de aprendizaje automático, seguido de monitoreo y entrenamiento continuo son cruciales para tener éxito con este enfoque."
  },
  {
    "objectID": "03-metodos-locales.html#controlando-complejidad",
    "href": "03-metodos-locales.html#controlando-complejidad",
    "title": "3  Métodos locales no estructurados",
    "section": "3.1 Controlando complejidad",
    "text": "3.1 Controlando complejidad\nPrimero examinamos cómo controlamos el nivel de complejidad para un método local como \\(k\\) vecinos más cercanos. La idea es que:\n\nMás complejidad: Si tomamos \\(k\\) demasiado chica, cada estimación usa pocos datos y puede ser ruidosa (incurrimos en variabilidad). Sin embargo, el predictor resultante puede ajustarse a patrones locales y globales.\nMenos complejidad: Si tomamos \\(k\\) demasiado grande, cada estimación usa potencialmente datos no relevantes muy lejanos a donde queremos predecir (incurrimos en sesgo), sin embargo cada estimación es más estable pues utiliza más datos.\n\nComenzamos con un ejemplo simple en dimensión baja:\n\nEjemplo\n\nlibrary(tidyverse)\nlibrary(gt)\nauto &lt;- read_csv(\"../datos/auto.csv\")\n# seleccionar variables y poner en sistema métrico\ndatos &lt;- auto |&gt; \n  select(name, weight, year, mpg, displacement) |&gt; \n  mutate(\n    peso_kg = weight * 0.45359237,\n    rendimiento_kpl = mpg * (1.609344 / 3.78541178), \n    año = year\n  )\n\nVamos a separa en muestra de entrenamiento y de prueba estos datos. Podemos hacerlo como sigue (75% para entrenamiento aproximadamente en este caso, así obtenemos alrededor de 100 casos para prueba):\n\nlibrary(tidymodels)\nset.seed(121)\ndatos_split &lt;- initial_split(datos, prop = 0.75)\ndatos_entrena &lt;- training(datos_split)\ndatos_prueba &lt;- testing(datos_split)\nnrow(datos_entrena)\n\n[1] 294\n\nnrow(datos_prueba)\n\n[1] 98\n\n\nVamos a usar año y peso de los coches para predecir su rendimiento:\n\nggplot(datos_entrena, \n  aes(x = peso_kg, y = rendimiento_kpl, colour = año)) +\n  geom_point()\n\n\n\n\nProbaremos con varios valores para \\(k\\), el número de vecinos más cercanos. La función de predicción ajustada es entonces:\n\n# nótese que normalizamos entradas - esto también es importante\n# hacer cuando hacemos vecinos más cercanos, pues en otro caso\n# las variables con escalas más grandes dominan el cálculo\nvmc_1 &lt;- nearest_neighbor(neighbors = tune(), weight_func = \"gaussian\") |&gt;  \n  set_engine(\"kknn\") |&gt;  \n  set_mode(\"regression\")\nreceta_vmc &lt;- recipe(\n  rendimiento_kpl ~ peso_kg + año, datos_entrena) |&gt; \n  step_normalize(all_predictors()) \nflujo_vecinos &lt;- workflow() |&gt;  \n  add_recipe(receta_vmc) |&gt; \n  add_model(vmc_1)\n# definir parámetros que nos interesa explorar\nvecinos_params &lt;- parameters(neighbors(range = c(1, 100)))\n# definir cuáles valores de los parámetros exploramos\nvecinos_grid &lt;- grid_regular(vecinos_params, levels = 100)\nmis_metricas &lt;- metric_set(rmse)\n\nEn la siguiente gráfica mostramos cómo cambia el error de los las predicciones sobre la muestra de prueba separada de la de entrenamiento. En este caso le llamaremos muestra de validación porque más adelante veremos que puede ser conveniente dividir en entrenamiento-validación-prueba en lugar de usar sólo 2 particiones:\n\nr_split &lt;- manual_rset(list(datos_split), \"validación\")\nvecinos_eval_tbl &lt;- tune_grid(flujo_vecinos,\n                            resamples = r_split,\n                            grid = vecinos_grid,\n                            metrics = mis_metricas) \nvecinos_ajustes_tbl &lt;- vecinos_eval_tbl |&gt;\n  unnest(cols = c(.metrics)) |&gt; \n  select(id, neighbors, .metric, .estimate)\nggplot(vecinos_ajustes_tbl, aes(x = neighbors, y = .estimate)) +\n  geom_line() + geom_point() +\n  ylab(\"Error de validación\") + xlab(\"Vecinos\")\n\n\n\n\nDonde obtenemos más o menos lo que esperaríamos: modelos con muy pocos vecinos o demasiados vecinos se desempeñan relativamente mal.\nSeleccionaremos el mejor modelo según el error estimado de predicción y visualizamos primero nuestras predicciones y los datos de entrenamiento de la siguiente forma:\n\nmejor_rmse &lt;- select_best(vecinos_eval_tbl, metric = \"rmse\")\najuste_1 &lt;- finalize_workflow(flujo_vecinos, mejor_rmse) |&gt; \n  fit(datos_entrena)\ndat_graf &lt;- tibble(peso_kg = seq(900, 2200, by = 10)) |&gt; \n  crossing(tibble(año = c(70, 75, 80)))\ndat_graf &lt;- dat_graf |&gt; \n  mutate(pred_1 = predict(ajuste_1, dat_graf) |&gt; pull(.pred))\nggplot(datos_entrena, aes(x = peso_kg, group = año, colour = año)) +\n  geom_point(aes(y = rendimiento_kpl), alpha = 0.6) + \n  geom_line(data = dat_graf, aes(y = pred_1),  linewidth = 1.2)\n\n\n\n\nEl método parece funcionar razonablemente bien para este problema simple. Sin embargo, si el espacio de entradas no es de dimensión baja, entonces podemos encontrarnos con dificultades."
  },
  {
    "objectID": "03-metodos-locales.html#la-maldición-de-la-dimensionalidad",
    "href": "03-metodos-locales.html#la-maldición-de-la-dimensionalidad",
    "title": "3  Métodos locales no estructurados",
    "section": "3.2 La maldición de la dimensionalidad",
    "text": "3.2 La maldición de la dimensionalidad\nEl método de k-vecinos más cercanos funciona mejor cuando\n\nNo es necesario hacer \\(k\\) demasiado grande, de forma que terminemos tomando valores lejanos que inducen sesgo.\nNo es necesario hacer \\(k\\) demasiado chica, de forma que nuestras predicciones sean inestables.\n\n\n\n\n\n\n\nMaldición de la dimensionalidad\n\n\n\nEn dimensión alta, para la mayoría de las \\(\\mathbf{x}\\) donde queremos hacer predicciones típicamente no existen vecinos cercanos, aún para conjuntos de entrenamiento muy grandes.\n\n\nEsto implica que para tamaños típicos \\(n\\) de muestra de entrenamiento:\n\nSi tomamos \\(k\\) chica, el sesgo por especificación es chico (muestras muy grandes), pero el sesgo de estimación puede ser grande pues estamos de todas formas obligados a buscar vecinos lejos de donde queremos predecir. La variabilidad también es alta pues usamos pocos datos para cada predicción.\nSi tomamos \\(k\\) más grande, el sesgo por especificación tiende ser más grande (pues promediamos sobre regiones relativamente grandes). Perdemos la supuesta ventaja del método local, aún cuando quizá reduzcamos el sesgo de estimación.\nPara que una \\(k\\) chica tenga sesgo de estimación bajo, el tamaño \\(n\\) de la muestra de entrenamiento tiene que ser gigantesca.\n\n\nEjemplo\nConsideremos que la salida Y es determinística \\(Y = e^{-8\\sum_{j=1}^p x_j^2}\\). Vamos a usar 1-vecino más cercano para hacer predicciones, con una muestra de entrenamiento de 1000 casos. Generamos $x^{i}’s uniformes en \\([ 1,1]\\), para \\(p = 2\\), y calculamos la respuesta \\(Y\\) para cada caso:\n\nfun_exp &lt;- function(x) exp(-8 * sum(x ^ 2))\nx &lt;- map(1:1000, ~ runif(2, -1, 1))\ndat &lt;- tibble(x = x) |&gt; \n        mutate(y = map_dbl(x, fun_exp))\nggplot(dat |&gt; mutate(x_1 = map_dbl(x, 1), x_2 = map_dbl(x, 2)), \n       aes(x = x_1, y = x_2, colour = y)) + geom_point()\n\n\n\n\nLa mejor predicción en \\(x_0 = (0,0)\\) es \\(f((0,0)) = 1\\). El vecino más cercano al origen es\n\ndat &lt;- dat |&gt; mutate(dist_origen = map_dbl(x, ~ sqrt(sum(.x^2)))) |&gt; \n  arrange(dist_origen)\nmas_cercano &lt;- dat[1, ]\nmas_cercano\n\n# A tibble: 1 × 3\n  x             y dist_origen\n  &lt;list&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1 &lt;dbl [2]&gt; 0.995      0.0261\n\nmas_cercano$x[[1]]\n\n[1] -0.025090354  0.007277334\n\n\nNuestra predicción es entonces \\(\\hat{f}(0)=\\) 0.994555, que es bastante cercano al valor verdadero (1).\nAhora intentamos hacer lo mismo para dimensión \\(p=8\\).\n\nx &lt;- map(1:1000, ~ runif(8, -1, 1))\ndat &lt;- tibble(x = x) |&gt; \n       mutate(y = map_dbl(x, fun_exp))\ndat &lt;- dat |&gt; mutate(dist_origen = map_dbl(x, ~ sqrt(sum(.x^2)))) |&gt; \n  arrange(dist_origen)\nmas_cercano &lt;- dat[1, ]\nmas_cercano\n\n# A tibble: 1 × 3\n  x             y dist_origen\n  &lt;list&gt;    &lt;dbl&gt;       &lt;dbl&gt;\n1 &lt;dbl [8]&gt; 0.104       0.532\n\nmas_cercano$x[[1]]\n\n[1]  0.30027994  0.36774993 -0.06613864 -0.03673154  0.12260975  0.16718980\n[7] -0.01866598 -0.09308947\n\n\nY el resultado es un desastre. Nuestra predicción es\n\nmas_cercano$y\n\n[1] 0.1038249\n\n\nNecesitariamos una muestra de alrededor de un millón de casos para obtener resultados no tan malos (haz pruebas).\n¿Qué es lo que está pasando? La razón es que en dimensiones altas, los puntos de la muestra de entrenamiento están muy lejos unos de otros, y están cerca de la frontera, incluso para tamaños de muestra relativamente grandes como n = 1000. Cuando la dimensión crece, la situación empeora exponencialmente."
  },
  {
    "objectID": "03-metodos-locales.html#regresión-lineal-en-dimensión-alta",
    "href": "03-metodos-locales.html#regresión-lineal-en-dimensión-alta",
    "title": "3  Métodos locales no estructurados",
    "section": "3.3 Regresión lineal en dimensión alta",
    "text": "3.3 Regresión lineal en dimensión alta\nAhora intentamos algo similar con una función que es razonable aproximar con una función lineal:\n\nfun_cuad &lt;- function(x)  0.5 * (1 + x[1])^2\n\nY queremos predecir para \\(x=(0,0,\\ldots,0)\\), cuyo valor exacto es\n\nfun_cuad(0)\n\n[1] 0.5\n\n\nLos datos se generan de la siguiente forma:\n\nsimular_datos &lt;- function(p = 40){\n    x &lt;- map(1:1000,  ~ runif(p, -1, 1))\n    dat &lt;- tibble(x = x) |&gt; mutate(y = map_dbl(x, fun_cuad)) \n    dat\n}\n\nPor ejemplo para dimensión baja \\(p=1\\) (nótese que una aproximación lineal es razonable):\n\nejemplo &lt;- simular_datos(p = 1) |&gt; mutate(x = unlist(x))\nggplot(ejemplo, aes(x = x, y = y)) + geom_point() +\n    geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nAhora repetimos el proceso en dimensión \\(p=40\\): simulamos las entradas, y aplicamos un vecino más cercano\n\nvmc_1 &lt;- function(dat){\n    dat &lt;- dat |&gt; \n        mutate(dist_origen = map_dbl(x, ~ sqrt(sum(.x^2)))) |&gt; \n        arrange(dist_origen)\n        mas_cercano &lt;- dat[1, ]\n        mas_cercano$y\n}\nset.seed(834)\ndat &lt;- simular_datos(p = 40)\nvmc_1(dat)\n\n[1] 1.206478\n\n\nEste no es un resultado muy bueno. Sin embargo, regresión se desempeña considerablemente mejor:\n\nregresion_pred &lt;- function(dat){\n    p &lt;- length(dat$x[[1]])\n    dat_reg &lt;- cbind(\n        y = dat$y, \n        x = matrix(unlist(dat$x), ncol = p, byrow=T)) |&gt; \n        as.data.frame()\n    mod_lineal &lt;- lm(y ~ ., dat = dat_reg)\n    origen &lt;- data.frame(matrix(rep(0, p), 1, p))\n    names(origen) &lt;- names(dat_reg)[2:(p+1)]\n    predict(mod_lineal, newdata = origen)\n}\nregresion_pred(dat)\n\n        1 \n0.6677861 \n\n\nLa razón de este mejor desempeño de regresión es que en este caso, el modelo lineal explota la estructura aproximadamente lineal del problema (¿cuál estructura lineal? haz algunas gráficas). Nota: corre este ejemplo varias veces con semilla diferente.\nSolución: vamos a hacer varias simulaciones, para ver qué modelo se desempeña mejor.\n\nsims &lt;- map(1:200, function(i){\n    dat &lt;- simular_datos(p = 40)\n    vmc_y &lt;- vmc_1(dat)\n    reg_y &lt;- regresion_pred(dat)\n    tibble(rep = i, \n           error = c(abs(vmc_y - 0.5), abs(reg_y - 0.5)), \n            tipo = c(\"vmc\", \"regresion\"))\n}) |&gt; bind_rows()\nggplot(sims, aes(x = tipo, y = error)) + geom_boxplot() \n\n\n\n\nAsí que típicamente el error de vecinos más cercanos es más alto que el de regresión. El error esperado es para vmc es más de doble que el de regresión:\n\nsims |&gt; group_by(tipo) |&gt; \n  summarise(media_error = mean(error)) |&gt; \n  gt()\n\n\n\n\n\n  \n    \n    \n      tipo\n      media_error\n    \n  \n  \n    regresion\n0.1662124\n    vmc\n0.3542532\n  \n  \n  \n\n\n\n\nLo que sucede más específicamente es que en regresión lineal utilizamos todos los datos para hacer nuestra estimación en cada predicción. Si la estructura del problema es aproximadamente lineal, entonces regresión lineal explota la estructura para hacer pooling de toda la información para construir predicción con sesgo y varianza bajas. En contraste, vecinos más cercanos sufre de varianza alta.\n\n\n\n\n\n\nMétodos locales sin estructura\n\n\n\nLos métodos locales muchas veces no funcionan bien en dimensión alta. La razón es que:\n\nEl sesgo es alto, pues promediamos puntos muy lejanos al lugar donde queremos predecir (aunque tomemos pocos vecinos cercanos).\nEn el caso de que encontremos unos pocos puntos cercanos, la varianza también puede ser alta porque promediamos relativamente pocos vecinos.\n\nMétodos con más estructura global, apropiada para el problema, logran explotar información de puntos que no están tan cerca del lugar donde queremos predecir.\n\n\nMuchas veces el éxito en la predicción depende de establecer esas estructuras apropiadas ya sea mediante:\n\nEstructura en nuestros modelos (por ejemplo, efectos lineales cuando variables tienen efectos aproximadamente lineales, árboles cuando hay algunas interacciones, redes convolucionales para procesamiento de imágenes y señales, dependencia del contexto en modelos de lenguaje, etc.)\nReducción de dimensionalidad apropiada (por ejemplo, embeddings basados en otros modelos, o técnicas como componentes principales/descompocisión en valores singulares, etc.)."
  },
  {
    "objectID": "04-lineales-ingenieria.html#aprendizaje-de-coeficientes-ajuste",
    "href": "04-lineales-ingenieria.html#aprendizaje-de-coeficientes-ajuste",
    "title": "4  Métodos lineales e ingenería de entradas",
    "section": "4.1 Aprendizaje de coeficientes (ajuste)",
    "text": "4.1 Aprendizaje de coeficientes (ajuste)\nEn el ejemplo anterior, los coeficientes fueron calculados (o estimados) usando experiencia, reglas, argumentos teóricos, o quizá otras fuentes de datos (como estudios o encuestas, conteos, etc.)\nAhora quisiéramos construir un algoritmo para aprender estos coeficientes del modelo \\[f_\\beta (x) = \\beta_0 + \\beta_1 x_1 + \\cdots \\beta_p x_p\\] a partir de una muestra de entrenamiento de datos históricos de tiendas que hemos abierto antes: \\[{\\mathcal L}=\\{ (x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}), \\ldots, (x^{(N)}, y^{(N)}) \\}\\] El criterio de ajuste (algoritmo de aprendizaje) más usual para regresión lineal es el de mínimos cuadrados.\nConstruimos las predicciones (ajustados) para la muestra de entrenamiento: \\[ f_\\beta (x^{(i)}) = \\beta_0 + \\beta_1 x_1^{(i)}+ \\cdots + \\beta_p x_p^{(i)}\\]\nY consideramos las diferencias de los ajustados con los valores observados:\n\\[e^{(i)} = y^{(i)} - f_\\beta (x^{(i)})\\]\nLa idea entonces es minimizar la suma de los residuales al cuadrado, para intentar que la función ajustada pase lo más cercana a los puntos de entrenamiento que sea posible. La función de pérdida que utilizamos más frecuentemente es la pérdida cuadrática, dada por:\n\\[L(\\beta) = \\frac{1}{N}\\sum_{i=1}^N (y^{(i)} - f_\\beta(x^{(i)}))^2\\]\n\n\n\n\n\n\nMínimos cuadrados para regresión lineal\n\n\n\nBuscamos encontrar: \\[\\hat{\\beta} = \\mathrm{arg\\,min}_{\\beta} L(\\beta) = \\mathrm{arg\\,min}_{\\beta}\\frac{1}{N}\\sum_{i=1}^N (y^{(i)} - f_\\beta(x^{(i)}))^2\\] donde \\[f_\\beta (x^{(i)}) = \\beta_0 + \\beta_1 x_1^{(i)}+ \\cdots + \\beta_p x_p^{(i)}\\]\n\n\nHay varias maneras de resolver este problema: puede hacerse analíticamente con álgebra lineal, o con algún método numérico como descenso máximo (que puede escalarse fácilmente). Típicamente la función objetivo es convexa, y la solución es única, excepto en casos degenerados que podremos evitar más adelante usando regularización.\nObservación: Como discutimos al final de la sección anterior, minimizar directamente el error de entrenamiento para encontrar los coeficientes puede resultar en en un modelo sobreajustado/con varianza alta/ruidoso. Hay cuatro grandes estrategias para mitigar este problema: restringir o estructurar la familia de funciones, penalizar la función objetivo, perturbar la muestra de entrenamiento, o cambiar el proceso de minimización perturbando la función objetivo en cada paso o deteniendo el proceso antes de llegar a un mínimo sobreajustado. El método mas común es cambiar la función objetivo, que discutiremos más adelante en la sección de regularización."
  },
  {
    "objectID": "04-lineales-ingenieria.html#ingeniería-de-entradas",
    "href": "04-lineales-ingenieria.html#ingeniería-de-entradas",
    "title": "4  Métodos lineales e ingenería de entradas",
    "section": "4.2 Ingeniería de entradas",
    "text": "4.2 Ingeniería de entradas\nAlgunas veces, encontrar la estructura apropiada puede requerir más trabajo que simplemente escoger una familia de modelos. Por ejemplo, en el caso de precios de casa, vimos que podríamos mejorar el ajuste haciendo que el coeficiente de área habitable dependiera de la calidad de los terminados @ref(medicioncostosa).\nUsualmente tendremos que hacer varias transformaciones para obtener buen desempeño de un modelo lineal. En la siguientes secciones mostramos algunas de las más usuales."
  },
  {
    "objectID": "04-lineales-ingenieria.html#variables-categóricas",
    "href": "04-lineales-ingenieria.html#variables-categóricas",
    "title": "4  Métodos lineales e ingenería de entradas",
    "section": "4.3 Variables categóricas",
    "text": "4.3 Variables categóricas\nEn primer lugar, podemos incluir variables categóricas creando variables numéricas 0-1 para cada categoría. Por ejemplo para la variable calidad sótano:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gt)\nsource(\"../R/casas_traducir_geo.R\")\nset.seed(83)\ncasas_split &lt;- initial_split(casas, prop = 0.75)\ncasas_entrena &lt;- training(casas_split)\ncasas_entrena |&gt; count(calidad_sotano)\n\n# A tibble: 5 × 2\n  calidad_sotano     n\n  &lt;chr&gt;          &lt;int&gt;\n1 Ex                89\n2 Fa                23\n3 Gd               457\n4 TA               500\n5 &lt;NA&gt;              26\n\n\nEl mejor nivel es Ex (excelente), luego sigue Gd (bueno), luego Fa (razonable) y finalmente TA (típico)). Hay otro nivel Po (Malo) que no aparece en estos datos.\nEn primer lugar, podemos codificar los valores faltantes, que en este caso indican casas sin sótano:\n\nreceta_na &lt;- recipe(~ calidad_sotano, casas_entrena) |&gt; \n  step_unknown(calidad_sotano, new_level = \"no_sótano\") |&gt; \n  step_relevel(calidad_sotano, ref_level = \"TA\")\ncasas_preproc &lt;- prep(receta_na) |&gt; juice()\ncasas_preproc |&gt; count(calidad_sotano)\n\n# A tibble: 5 × 2\n  calidad_sotano     n\n  &lt;fct&gt;          &lt;int&gt;\n1 TA               500\n2 Ex                89\n3 Fa                23\n4 Gd               457\n5 no_sótano         26\n\n\nAhora convertimos a codificación dummy:\n\nset.seed(7)\nreceta_dummy &lt;- \n  recipe( ~ calidad_sotano, casas_entrena) |&gt; \n  step_unknown(calidad_sotano, new_level = \"no_sótano\") |&gt; \n  step_relevel(calidad_sotano, ref_level = \"TA\") |&gt; \n  step_dummy(calidad_sotano, keep_original_cols = TRUE)\n# preparar receta\nreceta_dummy_prep &lt;- prep(receta_dummy) \n# extrae los datos de entrenamiento preprocesados\nreceta_dummy_prep |&gt; juice() |&gt; \n  sample_n(10) |&gt; gt() |&gt; \n  tab_options(table.font.size = 10)\n\n\n\n\n\n  \n    \n    \n      calidad_sotano\n      calidad_sotano_Ex\n      calidad_sotano_Fa\n      calidad_sotano_Gd\n      calidad_sotano_no_sótano\n    \n  \n  \n    TA\n0\n0\n0\n0\n    Gd\n0\n0\n1\n0\n    Ex\n1\n0\n0\n0\n    Ex\n1\n0\n0\n0\n    TA\n0\n0\n0\n0\n    TA\n0\n0\n0\n0\n    TA\n0\n0\n0\n0\n    TA\n0\n0\n0\n0\n    TA\n0\n0\n0\n0\n    TA\n0\n0\n0\n0\n  \n  \n  \n\n\n\n\nNótese que no hay columna para el nivel TA, que tomamos como referencia. Incluir esta columna sería redundante, pues tenemos una constante en el predictor. En general, cuando una variable categórica tiene \\(k\\) niveles, esta codificación produce \\(k-1\\) columnas binarias.\nVeamos qué pasa cuando preprocesamos datos de prueba (para después poder hacer predicciones):\n\nprueba_casas &lt;- testing(casas_split)\n# supongamos que un nuevo nivel aparece\nprueba_casas$calidad_sotano[1] &lt;- \"no visto antes\"\ndatos &lt;- bake(receta_dummy_prep, prueba_casas)\n\nWarning: There are new levels in a factor: no visto antes\nNew levels will be coerced to `NA` by `step_unknown()`.\nConsider using `step_novel()` before `step_unknown()`.\n\n\nWarning: There are new levels in a factor: NA\n\n\nEn este caso, podemos hacer nuestro flujo más robusto incluyendo un nuevo nivel en los factores donde pondremos casos no vistos. Modificamos nuestra receta:\n\nreceta_dummy &lt;- \n  recipe( ~ calidad_sotano, casas_entrena) |&gt; \n  step_novel(calidad_sotano, new_level = \"nuevo\") |&gt; \n  step_unknown(calidad_sotano, new_level = \"no_sótano\") |&gt; \n  step_relevel(calidad_sotano, ref_level = \"TA\") |&gt; \n  step_dummy(calidad_sotano, keep_original_cols = TRUE)\n# preparar receta\nreceta_dummy_prep &lt;- prep(receta_dummy) \n\n\nprueba_casas &lt;- testing(casas_split)\n# supongamos que un nuevo nivel aparece\nprueba_casas$calidad_sotano[1] &lt;- \"no visto antes\"\ndatos &lt;- bake(receta_dummy_prep, prueba_casas)\ndatos |&gt; head() |&gt; gt() |&gt; tab_options(table.font.size = 10)\n\n\n\n\n\n  \n    \n    \n      calidad_sotano\n      calidad_sotano_Ex\n      calidad_sotano_Fa\n      calidad_sotano_Gd\n      calidad_sotano_nuevo\n      calidad_sotano_no_sótano\n    \n  \n  \n    nuevo\n0\n0\n0\n1\n0\n    Ex\n1\n0\n0\n0\n0\n    TA\n0\n0\n0\n0\n0\n    Gd\n0\n0\n1\n0\n0\n    TA\n0\n0\n0\n0\n0\n    TA\n0\n0\n0\n0\n0\n  \n  \n  \n\n\n\n\nY podemos ignorar el nuevo nivel al hacer predicciones (que equivale a ponerlo en la categoría de referencia, que en este caso es TA), o podemos lidiar de manera ad-hoc con este nivel.\nOtro problema con el que podemos encontrarnos es variables categóricas que son muy ralas. Por ejemplo, una variable que tiene muchas categorías y algunas de ellas tienen muy pocos datos, además de que es probable que observemos nuevas categorías en el futuro. Por ejemplo, para la variable de zona:\n\ncasas_entrena |&gt; count(nombre_zona) |&gt; \n  arrange(desc(n)) |&gt; gt() |&gt; tab_options(table.font.size = 10)\n\n\n\n\n\n  \n    \n    \n      nombre_zona\n      n\n    \n  \n  \n    NAmes\n163\n    CollgCr\n113\n    OldTown\n80\n    Edwards\n74\n    Somerst\n65\n    Gilbert\n61\n    Sawyer\n59\n    NridgHt\n58\n    NWAmes\n57\n    BrkSide\n45\n    SawyerW\n42\n    Crawfor\n39\n    Mitchel\n36\n    IDOTRR\n31\n    NoRidge\n30\n    Timber\n26\n    ClearCr\n22\n    StoneBr\n20\n    SWISU\n18\n    Blmngtn\n14\n    BrDale\n14\n    MeadowV\n12\n    NPkVill\n8\n    Veenker\n7\n    Blueste\n1\n  \n  \n  \n\n\n\n\nEn este caso, tenemos muchas categorías, algunas con muy pocos datos, y es posible que observemos nuevos datos. Una técnica es agrupar los datos de baja cardinalidad en un nuevo nivel (incluyendo categorías no observadas en entrenamiento):\n\nreceta_vecindario_1 &lt;- \n  recipe( ~ nombre_zona, casas_entrena) |&gt;\n  step_other(nombre_zona, threshold = 0.01, other = \"otras\") \nreceta_vecindario &lt;- receta_vecindario_1 |&gt; \n  step_dummy(nombre_zona)\n# preparar receta\nreceta_vecindario_prep &lt;- prep(receta_vecindario_1)\nset.seed(8231)\nreceta_vecindario_prep |&gt; juice() |&gt; \n  count(nombre_zona) |&gt; arrange(desc(n)) |&gt; gt()\n\n\n\n\n\n  \n    \n    \n      nombre_zona\n      n\n    \n  \n  \n    NAmes\n163\n    CollgCr\n113\n    OldTown\n80\n    Edwards\n74\n    Somerst\n65\n    Gilbert\n61\n    Sawyer\n59\n    NridgHt\n58\n    NWAmes\n57\n    BrkSide\n45\n    SawyerW\n42\n    Crawfor\n39\n    Mitchel\n36\n    IDOTRR\n31\n    NoRidge\n30\n    Timber\n26\n    ClearCr\n22\n    StoneBr\n20\n    SWISU\n18\n    otras\n16\n    Blmngtn\n14\n    BrDale\n14\n    MeadowV\n12\n  \n  \n  \n\n\n\n\nEn este caso, las zonas de baja frecuencia fueron agrupadas en la categoría “otras”. Si observamos un nuevo nivel al momento de predicción:\n\nprueba_casas &lt;- testing(casas_split)\n# supongamos que un nuevo nivel aparece\nprueba_casas$nombre_zona[1] &lt;- \"Xochimilco\"\ndatos &lt;- bake(prep(receta_vecindario), prueba_casas)\ndatos |&gt; head() |&gt;  gt() |&gt; tab_options(table.font.size = 10)\n\n\n\n\n\n  \n    \n    \n      nombre_zona_BrDale\n      nombre_zona_BrkSide\n      nombre_zona_ClearCr\n      nombre_zona_CollgCr\n      nombre_zona_Crawfor\n      nombre_zona_Edwards\n      nombre_zona_Gilbert\n      nombre_zona_IDOTRR\n      nombre_zona_MeadowV\n      nombre_zona_Mitchel\n      nombre_zona_NAmes\n      nombre_zona_NoRidge\n      nombre_zona_NridgHt\n      nombre_zona_NWAmes\n      nombre_zona_OldTown\n      nombre_zona_Sawyer\n      nombre_zona_SawyerW\n      nombre_zona_Somerst\n      nombre_zona_StoneBr\n      nombre_zona_SWISU\n      nombre_zona_Timber\n      nombre_zona_otras\n    \n  \n  \n    0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n    0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n    0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n    0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n    0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n    0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n  \n  \n  \n\n\n\n\nEl proceso general es (ver por ejemplo esta lista):\n\n\n\n\n\n\nVariables categóricas\n\n\n\n\nEstablecemos los niveles que puede tener cada variable, incluyendo la posibilidad de categorías nuevas al momento de predecir, y categorías para valores no disponibles (NAs) (es posible también imputar con algún método en caso necesario).\nReorganizamos factores dependiendo del problema. Por ejemplo, incluir categorías de baja frecuencia en una categoría separada, o manipulaciones ad-hoc dependiendo del problema.\nSustituimos variables categóricas con \\(K\\) niveles en \\(K-1\\) columnas indicadoras de los niveles (estableciendo) alguna categoría como referencia. Esto no es estrictamente necesario en otros métodos, o si utilizamos regularización (ver sección siguiente)."
  },
  {
    "objectID": "04-lineales-ingenieria.html#interacciones",
    "href": "04-lineales-ingenieria.html#interacciones",
    "title": "4  Métodos lineales e ingenería de entradas",
    "section": "4.4 Interacciones",
    "text": "4.4 Interacciones\nOtra manera de expandir nuestro modelo es la utilización de interacciones, que muchas veces son clave para tener éxito con modelos lineales. Vimos ejemplos de interacciones en el ejemplo de las casas (@ref(medicioncostosa)) y en el primer ejemplo de ventas de tiendas que dependían del tráfico.\n\nEjemplo\nSi \\(x_1\\) es el área en metros cuadrados de una casa, y \\(x_2\\) una calificación numérica de su calidad, podemos considerar el modelo sin interacciones:\n\\[\\beta_0 + \\beta_1x_1 + \\beta_2 x_2\\]\nPero no tiene mucho sentido que el efecto marginal de \\(x_1\\) sea constante para cualquier nivel de calidad, y tampoco que la calidad de terminados agregue una cantidad fija al precio de la casa sin tomar en cuenta su tamaño. Podemos remediar esto creando una nueva variable que es le producto de \\(x_1\\) y \\(x_2\\):\n\\[x_3 = x_1 x_2\\]\ny agregando, nuestro predictor para precio es\n\\[ \\beta_0 +  \\beta_1x_1 + \\beta_2 x_2 + \\beta_3 x_1x_2\\]\nAhora notemos que para \\(x_2\\) fija, el modelo es\n\\[(\\beta_0 + \\beta_2x_2) + (\\beta_1 + \\beta_3x_2)x_1 = \\gamma_0 + \\gamma_1x_1\\] De modo que es lineal en \\(x_1\\). La diferencia es que cuando cambia \\(x_2\\), la recta que ajustamos es diferente.\n\nbeta &lt;- c(0, 50, 100, 20)\ncombs_tbl &lt;- crossing(x_1 = seq(2, 20, by = 1), x_2 = seq(0, 10, by = 2)) |&gt; \n  mutate(x_3 = x_1 * x_2) |&gt; \n  mutate(pred = beta[1] + beta[2]*x_1 + beta[3]*x_2 + beta[4]*x_3)\nggplot(combs_tbl, aes(x = x_1, y = pred, group = x_2, colour = x_2)) +\n  geom_line()\n\n\n\n\nY vemos que cuando la calidad es baja, el precio por metro cuadrado es más bajo que cuando la calidad es alta. Otra manera de pensar esto es que la inclusión de la interacción produce curvas marginales que rotan dependiendo del valor de otras variables.\nPregunta. ¿puedes pensar en otros casos donde las interacciones deben jugar un papel importante?\n\n\n\n\n\n\nInteracciones\n\n\n\n\nTransformamos las variables categóricas a dummies. Transformamos las variables numéricas si es necesario (normalizar, aplicar transformación no lineal, etc.)\nIncluimos interacciones de la siguiente forma:\n\n\nPara la interaccion de dos variables numéricas \\(x_1\\) y \\(x_2\\) agregamos el producto \\(x_3 = x_1x_2\\).\nPara interacción de una variable categórica \\(g\\) con una numérica \\(x\\) podemos hacer el mismo procedimiento multiplicando la variable categórica por cada una de las variable dummy que creamos a partir de \\(g\\). Esto en efecto produce una pendiente para \\(x\\) dependiendo del valor que toma \\(g\\)."
  },
  {
    "objectID": "04-lineales-ingenieria.html#ejemplo-precios-de-casas",
    "href": "04-lineales-ingenieria.html#ejemplo-precios-de-casas",
    "title": "4  Métodos lineales e ingenería de entradas",
    "section": "4.5 Ejemplo: precios de casas",
    "text": "4.5 Ejemplo: precios de casas\nEn el ejemplo de precios de casas, por ejemplo, es claro que el efecto en ventas del tamaño de las áreas (habitable, garage, etc.) depende de la calidad de los terminados, como vimos en la introducción. En la siguiente receta de preprocesamiento:\n\nCortamos calidad general en 5 grupos: este paso no es necesario y puede dañar el desempeño, pero es consistente con el análisis que hicimos anteriormente.\nLidiamos con niveles nuevos y los ponemos en una categoría “nuevo” (para que nuestro modelo no falle al momento de predicción)\nPonemos los faltantes de calidad sotano y garage en una categoría nueva (no tienen sótano y/o garage)\nAgrupamos las zonas con pocas observaciones en una categoría de “Otros”\nQuitamos los NA’s de área garage y área sotano, que deben ser igual a 0 cuando no existen estas características.\nCreamos variables dummy de todas las variables categóricas\nIncluimos interacciones de distintas áreas con las dummy correspondientes, incluyendo zona con área habitable\nFinalmente, eliminamos para el ajuste aquellas variables que tengan varianza cercana a cero (500 /1 quiere decir que elimina cualquier variable cuyo conteo del valor más común entre el conteo de la siguiente es mayor a 500).\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gt)\nsource(\"../R/casas_traducir_geo.R\")\nset.seed(83)\ncasas_split &lt;- initial_split(casas, prop = 0.75)\ncasas_entrena &lt;- training(casas_split)\nreceta_casas &lt;- recipe(precio_miles ~ \n           nombre_zona + \n           area_hab_m2 + area_garage_m2 + area_sotano_m2 + \n           area_lote_m2 + \n           año_construccion + \n           calidad_gral + calidad_garage + calidad_sotano + \n           num_coches  + \n           aire_acondicionado + condicion_venta, \n           data = casas_entrena) |&gt; \n  step_filter(condicion_venta == \"Normal\") |&gt; \n  step_select(-condicion_venta, skip = TRUE) |&gt; \n  step_cut(calidad_gral, breaks = c(3, 5, 7, 8), \n           include_outside_range = TRUE) |&gt;\n  step_novel(nombre_zona, calidad_sotano, calidad_garage) |&gt; \n  step_unknown(calidad_sotano, calidad_garage) |&gt; \n  step_other(nombre_zona, threshold = 0.02, other = \"otras\") |&gt; \n  step_mutate(area_sotano_m2 = ifelse(is.na(area_sotano_m2), 0, area_sotano_m2)) |&gt; \n  step_mutate(area_garage_m2 = ifelse(is.na(area_garage_m2), 0, area_garage_m2)) |&gt; \n  step_dummy(nombre_zona, calidad_gral, calidad_garage, calidad_sotano, aire_acondicionado) |&gt; \n  step_interact(terms = ~ area_hab_m2:starts_with(\"calidad_gral\")) |&gt; \n  step_interact(terms = ~ area_hab_m2:starts_with(\"nombre_zona\")) |&gt; \n  step_interact(terms = ~ area_garage_m2:starts_with(\"calidad_garage\")) |&gt; \n  step_interact(terms = ~ area_sotano_m2: starts_with(\"calidad_sotano\")) |&gt; \n  step_nzv(all_predictors(), freq_cut = 500 / 1, unique_cut = 1)\n\nEntrenamos la receta y vemos cuántos casos y columnas tenemos:\n\nreceta_casas_prep &lt;- prep(receta_casas, verbose = TRUE)\n\noper 1 step filter [training] \noper 2 step select [training] \noper 3 step cut [training] \noper 4 step novel [training] \noper 5 step unknown [training] \noper 6 step other [training] \noper 7 step mutate [training] \noper 8 step mutate [training] \noper 9 step dummy [training] \noper 10 step interact [training] \noper 11 step interact [training] \noper 12 step interact [training] \noper 13 step interact [training] \noper 14 step nzv [training] \nThe retained training set is ~ 0.46 Mb  in memory.\n\ndatos_tbl &lt;- juice(receta_casas_prep)\ndim(datos_tbl)\n\n[1] 907  62\n\n\n\ndatos_tbl |&gt;\n  mutate(across(where(is.numeric), \\(x) round(x, 2))) |&gt;\n  head() |&gt; \n  gt()\n\n\n\n\n\n  \n    \n    \n      area_hab_m2\n      area_garage_m2\n      area_sotano_m2\n      area_lote_m2\n      año_construccion\n      num_coches\n      precio_miles\n      nombre_zona_CollgCr\n      nombre_zona_Crawfor\n      nombre_zona_Edwards\n      nombre_zona_Gilbert\n      nombre_zona_IDOTRR\n      nombre_zona_Mitchel\n      nombre_zona_NAmes\n      nombre_zona_NoRidge\n      nombre_zona_NridgHt\n      nombre_zona_NWAmes\n      nombre_zona_OldTown\n      nombre_zona_Sawyer\n      nombre_zona_SawyerW\n      nombre_zona_Somerst\n      nombre_zona_Timber\n      nombre_zona_otras\n      calidad_gral_X.3.5.\n      calidad_gral_X.5.7.\n      calidad_gral_X.7.8.\n      calidad_gral_X.8.max.\n      calidad_garage_Fa\n      calidad_garage_Gd\n      calidad_garage_TA\n      calidad_garage_unknown\n      calidad_sotano_Fa\n      calidad_sotano_Gd\n      calidad_sotano_TA\n      calidad_sotano_unknown\n      aire_acondicionado_Y\n      area_hab_m2_x_calidad_gral_X.3.5.\n      area_hab_m2_x_calidad_gral_X.5.7.\n      area_hab_m2_x_calidad_gral_X.7.8.\n      area_hab_m2_x_calidad_gral_X.8.max.\n      area_hab_m2_x_nombre_zona_CollgCr\n      area_hab_m2_x_nombre_zona_Crawfor\n      area_hab_m2_x_nombre_zona_Edwards\n      area_hab_m2_x_nombre_zona_Gilbert\n      area_hab_m2_x_nombre_zona_IDOTRR\n      area_hab_m2_x_nombre_zona_Mitchel\n      area_hab_m2_x_nombre_zona_NAmes\n      area_hab_m2_x_nombre_zona_NoRidge\n      area_hab_m2_x_nombre_zona_NridgHt\n      area_hab_m2_x_nombre_zona_NWAmes\n      area_hab_m2_x_nombre_zona_OldTown\n      area_hab_m2_x_nombre_zona_Sawyer\n      area_hab_m2_x_nombre_zona_SawyerW\n      area_hab_m2_x_nombre_zona_Somerst\n      area_hab_m2_x_nombre_zona_Timber\n      area_hab_m2_x_nombre_zona_otras\n      area_garage_m2_x_calidad_garage_Fa\n      area_garage_m2_x_calidad_garage_Gd\n      area_garage_m2_x_calidad_garage_TA\n      area_sotano_m2_x_calidad_sotano_Fa\n      area_sotano_m2_x_calidad_sotano_Gd\n      area_sotano_m2_x_calidad_sotano_TA\n    \n  \n  \n    137.22\n20.07\n79.99\n584.55\n1928\n1\n145.0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n0.00\n137.22\n0.00\n0\n0.00\n0\n0\n0.00\n0\n0\n0.00\n0\n0\n0\n0\n0\n0\n0\n0\n137.22\n0\n0\n20.07\n0\n0.00\n79.99\n    179.86\n46.82\n130.62\n1039.96\n2000\n2\n230.5\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1\n0.00\n0.00\n179.86\n0\n0.00\n0\n0\n179.86\n0\n0\n0.00\n0\n0\n0\n0\n0\n0\n0\n0\n0.00\n0\n0\n46.82\n0\n130.62\n0.00\n    81.94\n27.31\n0.00\n774.72\n1959\n1\n106.5\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n1\n1\n81.94\n0.00\n0.00\n0\n0.00\n0\n0\n0.00\n0\n0\n81.94\n0\n0\n0\n0\n0\n0\n0\n0\n0.00\n0\n0\n27.31\n0\n0.00\n0.00\n    153.01\n20.07\n74.88\n637.13\n1915\n1\n128.0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n1\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n0\n0.00\n153.01\n0.00\n0\n0.00\n0\n0\n0.00\n0\n0\n0.00\n0\n0\n0\n0\n0\n0\n0\n0\n153.01\n0\n0\n20.07\n0\n74.88\n0.00\n    101.45\n26.57\n50.73\n205.97\n1970\n1\n88.0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n0\n0\n0\n0\n0\n1\n0\n0\n0\n1\n0\n1\n101.45\n0.00\n0.00\n0\n0.00\n0\n0\n0.00\n0\n0\n0.00\n0\n0\n0\n0\n0\n0\n0\n0\n101.45\n0\n0\n26.57\n0\n0.00\n50.73\n    71.35\n36.79\n71.35\n668.90\n1972\n1\n133.9\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0\n0\n1\n71.35\n0.00\n0.00\n0\n71.35\n0\n0\n0.00\n0\n0\n0.00\n0\n0\n0\n0\n0\n0\n0\n0\n0.00\n0\n0\n36.79\n0\n71.35\n0.00\n  \n  \n  \n\n\n\n\nFinalmente, usamos un modelo lineal con las 62 entradas que acabamos de crear:\n\nflujo_casas &lt;- workflow() |&gt; \n  add_recipe(receta_casas) |&gt; \n  add_model(linear_reg() |&gt; set_engine(\"lm\"))\najuste &lt;- fit(flujo_casas, casas_entrena)\n\nAunque no es de interés particular para nosotros por el momento, examinamos los coeficientes (que no son tan simples de interpretar como discutiremos más adelante):\n\najuste |&gt; broom::tidy() |&gt; \n  mutate(across(where(is.numeric), \\(x) round(x, 2))) |&gt; \n  select(term, estimate) |&gt; \n  gt()\n\n\n\n\n\n  \n    \n    \n      term\n      estimate\n    \n  \n  \n    (Intercept)\n-858.68\n    area_hab_m2\n0.80\n    area_garage_m2\n1.02\n    area_sotano_m2\n0.88\n    area_lote_m2\n0.01\n    año_construccion\n0.39\n    num_coches\n2.11\n    nombre_zona_CollgCr\n16.70\n    nombre_zona_Crawfor\n37.11\n    nombre_zona_Edwards\n28.82\n    nombre_zona_Gilbert\n31.31\n    nombre_zona_IDOTRR\n11.81\n    nombre_zona_Mitchel\n32.01\n    nombre_zona_NAmes\n28.74\n    nombre_zona_NoRidge\n22.00\n    nombre_zona_NridgHt\n-6.51\n    nombre_zona_NWAmes\n17.67\n    nombre_zona_OldTown\n25.28\n    nombre_zona_Sawyer\n37.91\n    nombre_zona_SawyerW\n-11.95\n    nombre_zona_Somerst\n-8.99\n    nombre_zona_Timber\n3.23\n    nombre_zona_otras\n-14.27\n    calidad_gral_X.3.5.\n35.54\n    calidad_gral_X.5.7.\n13.76\n    calidad_gral_X.7.8.\n16.99\n    calidad_gral_X.8.max.\n-67.26\n    calidad_garage_Fa\n15.54\n    calidad_garage_Gd\n39.04\n    calidad_garage_TA\n18.71\n    calidad_garage_unknown\n20.61\n    calidad_sotano_Fa\n72.92\n    calidad_sotano_Gd\n54.95\n    calidad_sotano_TA\n60.56\n    calidad_sotano_unknown\n59.88\n    aire_acondicionado_Y\n15.17\n    area_hab_m2_x_calidad_gral_X.3.5.\n-0.25\n    area_hab_m2_x_calidad_gral_X.5.7.\n0.05\n    area_hab_m2_x_calidad_gral_X.7.8.\n0.19\n    area_hab_m2_x_calidad_gral_X.8.max.\n0.81\n    area_hab_m2_x_nombre_zona_CollgCr\n-0.25\n    area_hab_m2_x_nombre_zona_Crawfor\n-0.14\n    area_hab_m2_x_nombre_zona_Edwards\n-0.39\n    area_hab_m2_x_nombre_zona_Gilbert\n-0.33\n    area_hab_m2_x_nombre_zona_IDOTRR\n-0.21\n    area_hab_m2_x_nombre_zona_Mitchel\n-0.42\n    area_hab_m2_x_nombre_zona_NAmes\n-0.31\n    area_hab_m2_x_nombre_zona_NoRidge\n-0.16\n    area_hab_m2_x_nombre_zona_NridgHt\n-0.03\n    area_hab_m2_x_nombre_zona_NWAmes\n-0.26\n    area_hab_m2_x_nombre_zona_OldTown\n-0.32\n    area_hab_m2_x_nombre_zona_Sawyer\n-0.43\n    area_hab_m2_x_nombre_zona_SawyerW\n-0.07\n    area_hab_m2_x_nombre_zona_Somerst\n0.00\n    area_hab_m2_x_nombre_zona_Timber\n-0.14\n    area_hab_m2_x_nombre_zona_otras\n0.00\n    area_garage_m2_x_calidad_garage_Fa\n-0.59\n    area_garage_m2_x_calidad_garage_Gd\n-0.97\n    area_garage_m2_x_calidad_garage_TA\n-0.78\n    area_sotano_m2_x_calidad_sotano_Fa\n-0.86\n    area_sotano_m2_x_calidad_sotano_Gd\n-0.53\n    area_sotano_m2_x_calidad_sotano_TA\n-0.67\n  \n  \n  \n\n\n\n\nNótese que:\n\nEn esta tabla están los coeficientes \\(\\beta_i\\) en las covariables que creamos a partir de las variables de entrada.\nEl modelo lineal no tiene que ser lineal en las variables que recibimos originalmente en la tabla de datos.\nEn este ejemplo, convertimos algunas variables a dummy, y multiplicamos algunas variables de área por esas variables dummy.\n\nFinalmente, evaluamos el desempeño sobre las ventas normales:\n\nmetricas &lt;- metric_set(mape, mae, rmse, rsq)\ncasas_prueba_normal &lt;- testing(casas_split) |&gt; \n  filter(condicion_venta == \"Normal\")\nmetricas(casas_prueba_normal |&gt; bind_cols(predict(ajuste, casas_prueba_normal)), \n     truth = precio_miles, estimate = .pred) |&gt; \n  gt() |&gt; fmt_number(.estimate, decimals = 2)\n\n\n\n\n\n  \n    \n    \n      .metric\n      .estimator\n      .estimate\n    \n  \n  \n    mape\nstandard\n10.34\n    mae\nstandard\n17.12\n    rmse\nstandard\n23.49\n    rsq\nstandard\n0.89"
  },
  {
    "objectID": "04-lineales-ingenieria.html#no-linealidad-y-atípicos",
    "href": "04-lineales-ingenieria.html#no-linealidad-y-atípicos",
    "title": "4  Métodos lineales e ingenería de entradas",
    "section": "4.6 No linealidad y atípicos",
    "text": "4.6 No linealidad y atípicos\nEn un primer ejemplo consideremos la variable de área de lote:\n\nlibrary(patchwork)\ng_1 &lt;- ggplot(casas_entrena, aes(x = area_lote_m2, y = precio_miles)) +\n  geom_point() + #geom_smooth(method = \"loess\", span = 0.5, se = FALSE,\n                #             method.args = list(degree = 1)) +\n  geom_smooth(method = \"lm\", se = FALSE)\ng_2 &lt;- ggplot(casas_entrena |&gt; filter(area_lote_m2 &lt; 5000), aes(x = area_lote_m2, y = precio_miles)) +\n  geom_point(data = casas_entrena, aes(colour = area_lote_m2 &gt; 5000)) + \n  #geom_smooth(method = \"loess\", span = 0.5, se = FALSE,\n  #                           method.args = list(degree = 1)) +\n  geom_smooth(method = \"lm\", se = FALSE)\ng_1 + g_2\n\n\n\n\nY notamos que hay algunos valores grandes que pueden perturbar el ajuste lineal. Esto puede producir varianza alta en las predicciones, pues el ajuste depende mucho de unos cuantos valores de entrenamiento. Una solución puede ser transformar la entrada por ejempo usando el logaritmo, que comprime la cola derecha de la distribución de la variable que tiene mucho sesgo:\n\nggplot(casas_entrena, aes(x = area_lote_m2, y = precio_miles)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", span = 0.5, se = FALSE) +\n  scale_x_log10()\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nNótese que probablemente tendremos que agregar más flexibilidad en nuestro predictor para capturar apropiadamente la información en esta variable."
  },
  {
    "objectID": "04-lineales-ingenieria.html#no-linealidad-y-splines",
    "href": "04-lineales-ingenieria.html#no-linealidad-y-splines",
    "title": "4  Métodos lineales e ingenería de entradas",
    "section": "4.7 No linealidad y splines",
    "text": "4.7 No linealidad y splines\nEn algunos casos, la relación de una variable de entrada con la predicción es no lineal. Podemos entonces incluír entradas derivadas de la original usando transformaciones no lineales: por ejemplo, transformar entradas usando el logaritmo, o agregar el cuadrado o la raíz de las variables de entrada.\nUna de las maneras más simples y menos problemáticas de hacer esto es usando splines naturales para modelar, que son funciones cúbicas por tramos dos veces diferenciables. Los tramos están definidos por nudos que podemos definir por ejemplo igualmente espaciados en los datos.\n\nvalores_x &lt;- seq(-10, 110, 1)\nbase_splines &lt;- splines::ns(x = valores_x, \n  knots = c(33, 66), Boundary.knots = c(0, 100))\nspline_1 &lt;- base_splines %*% c(1, 1, 1)\nspline_2 &lt;- base_splines %*% c(-0.1, 2, 1)\ntibble(x = valores_x, y = spline_1, spline = 1) |&gt; \nbind_rows(tibble(x = valores_x, y = spline_2, spline = 2)) |&gt; \n  ggplot(aes(x = x, y = y, \n    group = spline, colour = factor(spline))) + \n  geom_point() + geom_line() +\n  geom_vline(xintercept = c(0, 33, 66, 100), \n    colour = \"red\")\n\n\n\n\nEstos dos son ejemplos de funciones cúbicas por tramos y dos veces diferenciables, con nudos en 0, 33, 66 y 100. Su forma particular depende de tres coeficientes, que pueden pensarse también como definidos por dónde tienen que pasar la curva en \\(y\\) para los valores \\(x = 33, 66\\) y \\(100\\). Extrapolan linealmente fuera del rango de los datos.\nLa ventaja de utilizar estos splines es que son estables en el cálculo, pues a lo más utilizan potencias cúbicas, y la complejidad puede aumentarse incrementando el número de nodos.\n\nEjemplo\nRevisamos nuestro ejemplo de rendimiento de coches:\n\nlibrary(tidyverse)\nlibrary(gt)\nauto &lt;- read_csv(\"../datos/auto.csv\")\ndatos &lt;- auto[, c('name', 'weight','year', 'mpg', 'displacement')]\ndatos &lt;- datos |&gt; mutate(\n  peso_kg = weight * 0.45359237,\n  rendimiento_kpl = mpg * (1.609344 / 3.78541178), \n  año = year)\n\nVamos a separar en muestra de entrenamiento y de prueba estos datos. Podemos hacerlo como sigue (75% para entrenamiento aproximadamente en este caso, así obtenemos alrededor de 100 casos para prueba):\n\nlibrary(tidymodels)\nset.seed(121)\ndatos_split &lt;- initial_split(datos, prop = 0.75)\ndatos_entrena &lt;- training(datos_split)\ndatos_prueba &lt;- testing(datos_split)\n\nVamos a usar año y peso de los coches para predecir su rendimiento:\n\nggplot(datos_entrena, aes(x = peso_kg, y = rendimiento_kpl, colour = año)) +\n  geom_point()\n\n\n\n\nNuestra receta incluye la transformación no lineal de splines:\n\nreceta_lineal &lt;- recipe(rendimiento_kpl ~ peso_kg + año, datos_entrena) |&gt; \n  step_ns(peso_kg, deg_free = 3) |&gt; \n  step_ns(año, deg_free = 2)\nmod_lineal &lt;- linear_reg() |&gt;  \n  set_engine(\"lm\")  \nflujo &lt;- workflow() |&gt;  \n  add_recipe(receta_lineal) |&gt; \n  add_model(mod_lineal)\n\nLos datos de entrada son los siguientes:\n\njuice(prep(receta_lineal)) |&gt; head() |&gt; gt()\n\n\n\n\n\n  \n    \n    \n      rendimiento_kpl\n      peso_kg_ns_1\n      peso_kg_ns_2\n      peso_kg_ns_3\n      año_ns_1\n      año_ns_2\n    \n  \n  \n    12.754311\n-0.1384501\n0.3919536\n-0.2338715\n0.1263158\n-0.08343893\n    13.136941\n-0.1508427\n0.4978146\n-0.2970367\n0.5652102\n0.00590925\n    12.754311\n0.3794499\n0.4646633\n-0.2232209\n0.4765544\n0.35513660\n    7.695101\n0.4471996\n0.4245669\n-0.1625354\n0.5652102\n0.00590925\n    8.757960\n0.4368600\n0.4313780\n-0.1743974\n0.5652102\n0.00590925\n    14.242314\n-0.1126420\n0.2985773\n-0.1781555\n0.5794245\n-0.12316573\n  \n  \n  \n\n\n\n\nNótese que tenemos 4 entradas en lugar de las 2 originales, pues creamos dos transformaciones no lineales de peso_kg. El modelo es lineal en estas 4 variables, pero no en las 2 originales. Ajustamos:\n\nflujo_ajustado &lt;- fit(flujo, datos_entrena)\n\nY ahora podemos graficar los resultados y vemos cómo pudimos capturar la relación no lineal entre peso y rendimiento:\n\ndat_graf &lt;- tibble(peso_kg = seq(900, 2200, by = 10)) |&gt;   \n  crossing(tibble(año = c(70, 75, 80)))\ndat_graf &lt;- dat_graf |&gt; \n  mutate(pred_1 = predict(flujo_ajustado, dat_graf) |&gt; pull(.pred))\nggplot(datos_entrena, aes(x = peso_kg, group = año, colour = año)) +\n  geom_point(aes(y = rendimiento_kpl), alpha = 0.6) + \n  geom_line(data = dat_graf, aes(y = pred_1),  size = 1.2)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nLos grados de libertad también pueden afinarse utilizando un conjunto de validación como hicimos antes en vecinos más cercanos.\n\n\nEjemplo: casas\nPor ejemplo, podríamos incluir un efecto no lineal de area_lote, calidad y condición general y año de construcción:\n\nreceta_casas &lt;- recipe(precio_miles ~ \n           nombre_zona + \n           area_hab_m2 + area_garage_m2 + area_sotano_m2 + \n           area_lote_m2 + \n           año_construccion + \n           calidad_gral + calidad_garage + calidad_sotano + \n           condicion_gral + \n           num_coches  + \n           aire_acondicionado + condicion_venta, \n           data = casas_entrena) |&gt; \n  step_filter(condicion_venta == \"Normal\") |&gt; \n  step_select(-condicion_venta, skip = TRUE) |&gt; \n  \n  step_novel(nombre_zona, calidad_sotano, calidad_garage) |&gt; \n  step_unknown(calidad_sotano, calidad_garage) |&gt; \n  step_other(nombre_zona, threshold = 0.02, other = \"otras\") |&gt; \n  step_mutate(area_sotano_m2 = \n    ifelse(is.na(area_sotano_m2), 0, area_sotano_m2)) |&gt; \n  step_mutate(area_garage_m2 = \n    ifelse(is.na(area_garage_m2), 0, area_garage_m2)) |&gt;\n # step_log(area_lote_m2) |&gt; \n  step_ns(año_construccion, deg_free = 2) |&gt; \n  step_ns(calidad_gral, deg_free = 2) |&gt; \n  step_ns(condicion_gral, deg_free = 2) |&gt; \n  step_ns(area_lote_m2, deg_free = 3) |&gt; \n  step_dummy(nombre_zona,  calidad_garage, calidad_sotano, aire_acondicionado) |&gt; \n  step_interact(terms = ~ area_hab_m2:starts_with(\"calidad_gral\")) |&gt; \n  step_interact(terms = ~ area_hab_m2:starts_with(\"nombre_zona\")) |&gt; \n  step_interact(terms = ~ area_garage_m2:starts_with(\"calidad_garage\")) |&gt; \n  step_interact(terms = ~ area_sotano_m2: starts_with(\"calidad_sotano\")) |&gt; \n  step_nzv(all_predictors(), freq_cut = 500 / 1, unique_cut = 1)\n\n\nflujo_casas &lt;- workflow() |&gt; \n  add_recipe(receta_casas) |&gt; \n  add_model(linear_reg() |&gt; set_engine(\"lm\"))\najuste &lt;- fit(flujo_casas, casas_entrena)\n\nFinalmente, evaluamos el desempeño sobre las ventas normales, y obtenemos una mejoría con respecto a nuestro modelo anterior:\n\nmetricas &lt;- metric_set(mape, mae, rmse, rsq)\ncasas_prueba_normal &lt;- testing(casas_split) |&gt; \n  filter(condicion_venta == \"Normal\")\nmetricas(casas_prueba_normal |&gt; \n  bind_cols(predict(ajuste, casas_prueba_normal)), \n     truth = precio_miles, estimate = .pred) |&gt; \n  gt() |&gt; fmt_number(.estimate, decimals = 2)\n\n\n\n\n\n  \n    \n    \n      .metric\n      .estimator\n      .estimate\n    \n  \n  \n    mape\nstandard\n8.47\n    mae\nstandard\n14.45\n    rmse\nstandard\n19.77\n    rsq\nstandard\n0.92\n  \n  \n  \n\n\n\n\nFinalmente, examinamos la respuesta contra la predicción:\n\ncasas_prueba_normal |&gt; \n  bind_cols(predict(ajuste, casas_prueba_normal)) |&gt; \n  ggplot(aes(x = .pred, y = precio_miles)) + geom_abline() + \n    geom_point(colour = \"red\") + coord_obs_pred()"
  },
  {
    "objectID": "05-regularizacion-1.html#ejemplo-datos-simulados-y-varianza",
    "href": "05-regularizacion-1.html#ejemplo-datos-simulados-y-varianza",
    "title": "5  Regularización y variabilidad",
    "section": "5.1 Ejemplo: datos simulados y varianza",
    "text": "5.1 Ejemplo: datos simulados y varianza\nConsideremos un problema donde tenemos unas 100 entradas con 120 casos. Supondremos que la función verdadera es\n\\[f(x) = \\sum_{j=1}^{100} \\beta_j x_j\\]\n\nlibrary(tidyverse)\nlibrary(gt)\nset.seed(28015)\nbeta_vec &lt;- rnorm(100, 0, 0.2)\np &lt;- length(beta_vec)\nbeta &lt;- tibble(term = str_c('V', 1:p), valor = beta_vec)\nhead(beta)\n\n# A tibble: 6 × 2\n  term     valor\n  &lt;chr&gt;    &lt;dbl&gt;\n1 V1    -0.121  \n2 V2     0.0374 \n3 V3    -0.129  \n4 V4     0.240  \n5 V5    -0.00962\n6 V6    -0.0443 \n\n\nSimulamos datos:\n\nsim_datos &lt;- function(n, beta){\n  p &lt;- nrow(beta)\n  mat_x &lt;- matrix(rnorm(n * p, 0, 1), n, p) + rnorm(n, 0, 5) \n  colnames(mat_x) &lt;- beta |&gt; pull(term)\n  beta_vec &lt;- beta |&gt; pull(valor)\n  f_x &lt;- mat_x %*% beta_vec \n  y &lt;- as.numeric(f_x) + rnorm(n, 0, 1)\n  datos &lt;- as_tibble(mat_x) \n  datos |&gt; mutate(y = y)\n}\ndatos &lt;- sim_datos(n = 4000, beta = beta)\n\nSeparamos datos de entrenamiento y prueba y definimos y ajustamos un predictor lineal:\n\nlibrary(tidymodels)\nset.seed(994)\nn_entrena &lt;- nrow(datos) * 0.03\nseparacion &lt;- initial_split(datos, 0.03)\ndat_ent &lt;- training(separacion)\nmodelo &lt;-  linear_reg() |&gt; set_engine(\"lm\")\nreceta &lt;- recipe(y ~ ., dat_ent)\nflujo &lt;- workflow() |&gt; \n  add_model(modelo) |&gt; \n  add_recipe(receta)\nflujo_ajustado &lt;- fit(flujo, dat_ent)\nmod_1  &lt;- flujo_ajustado |&gt; extract_fit_engine()\n\nExtraemos los coeficientes y graficamos ajustados contra verdaderos:\n\ncoefs_1 &lt;- tidy(mod_1) |&gt; \n  left_join(beta, by = \"term\")\nggplot(coefs_1 |&gt; filter(term != \"(Intercept)\"), \n       aes(x = valor, y = estimate)) +\n  geom_point() +\n  xlab('Coeficientes verdaderos') + \n  ylab('Coeficientes estimados') +\n  geom_abline() \n\n\n\n\nY notamos que las estimaciones no son buenas. Podemos hacer otra simulación para confirmar que el problema es que las estimaciones son muy variables.\nCon otra muestra de entrenamiento, vemos que las estimaciones tienen varianza alta.\n\ndatos_ent_2 &lt;- sim_datos(n = 120, beta = beta)\nmod_2 &lt;- fit(flujo, datos_ent_2) |&gt; extract_fit_engine()\ncoefs_2 &lt;- tidy(mod_2)\nqplot(coefs_1$estimate, coefs_2$estimate) + xlab('Coeficientes mod 1') + \n  ylab('Coeficientes mod 2') +\n  geom_abline(intercept=0, slope =1)\n\nWarning: `qplot()` was deprecated in ggplot2 3.4.0.\n\n\n\n\n\nEn la práctica, nosotros tenemos una sola muestra de entrenamiento. Así que, con una muestra de tamaño\n\\(n=120\\) como en este ejemplo, obtendremos típicamente resultados no muy buenos. Estos coeficientes ruidosos afectan nuestras predicciones de manera negativa, aún cuando el modelo ajustado parece reproducir razonablemente bien la variable respuesta:\n\nlibrary(patchwork)\ndat_pr &lt;- testing(separacion)\npreds_entrena &lt;- predict(flujo_ajustado, dat_ent) |&gt; \n  bind_cols(dat_ent |&gt; select(y))\npreds_prueba &lt;- predict(flujo_ajustado, dat_pr) |&gt; \n  bind_cols(dat_pr |&gt; select(y))\ng_1 &lt;- ggplot(preds_entrena, aes(x = .pred, y = y)) +\n  geom_abline(colour = \"red\") +\n  geom_point() + \n  xlab(\"Predicción\") + ylab(\"y\") +\n  labs(subtitle = \"Muestra de entrenamiento\")\ng_2 &lt;- ggplot(preds_prueba, aes(x = .pred, y = y)) + \n  geom_abline(colour = \"red\") +\n  geom_point() + \n  xlab(\"Predicción\") + ylab(\"y\") +\n  labs(subtitle = \"Muestra de prueba\")\ng_1 + g_2"
  },
  {
    "objectID": "05-regularizacion-1.html#ejemplo-controlando-la-varianza",
    "href": "05-regularizacion-1.html#ejemplo-controlando-la-varianza",
    "title": "5  Regularización y variabilidad",
    "section": "5.2 Ejemplo: controlando la varianza",
    "text": "5.2 Ejemplo: controlando la varianza\nComo el problema es la variabilidad de los coeficientes (en este ejemplo sabemos que no hay sesgo pues conocemos el modelo verdadero), podemos atacar este problema poniendo restricciones a los coeficientes, de manera que caigan en rangos más aceptables.\nUna manera de hacer esto es restringir el rango de los coeficientes cambiando la función que minimizamos para ajustar el modelo lineal. Recordamos que la cantidad que queremos minimizar es\n\\[D(\\beta) = D(a_0, \\beta_1, \\ldots, \\beta_p) = \\sum_{i=1}^N (y^{(i)} - f_\\beta (x^{(i)}))^2 = \\sum_{i=1}^N (y^{(i)} - \\beta_0 - \\beta_1 x_1^{(i)}-\\beta_2x_2^{(i)} - \\cdots - \\beta_px_p^{(i)})^2\\]\ndonde la suma es sobre los datos de entrenamiento. Queremos encontrar \\(a =(\\beta_0, \\beta_1, \\ldots, \\beta_p)\\) para resolver\n\\[\\min_\\beta D(\\beta)\\]\nEn el ejemplo que estamos considerando, vemos que existe mucha variación en los coeficientes obtenidos de muestra de entrenamiento a muestra de entrenamiento, y que algunos de ellos toman valores muy grandes positivos o negativos. Podemos entonces intentar resolver mejor el problema penalizado\n\\[\\min_\\beta D(\\beta) + \\lambda \\sum_{j=1}^p \\beta_j^2\\]\nSi escogemos un valor relativamente grande de \\(\\lambda &gt; 0\\), entonces terminaremos con una solución donde los coeficientes\nno pueden alejarse mucho de 0, y esto previene parte del sobreajuste que observamos en nuestro primer ajuste. Otra manera de decir esto es: intentamos minimizar cuadrados, pero no permitimos que los coeficientes se alejen demasiado de cero, o ponemos un costo a soluciones que intentan “mover” mucho los coeficientes para ajustar mejor al conjunto de entrenamiento.\n\nNormalmente normalizamos las variables de entrada \\(x\\) para que tenga sentido normalizar todos los coeficientes con una misma \\(\\lambda\\).\nTambién es posible poner restricciones sobre el tamaño de \\(\\sum_j \\beta_j^2\\), lo cual es equivalente al problema de penalización.\nUsualmente no penalizamos la constante \\(\\beta_0\\), de forma que si \\(\\lambda\\) es muy grande, nuestro modelo ajustado predice simplemente la media de los datos de entrenamiento.\nEste tipo de penalización se llama muchas veces \\(L_2\\), o penalización ridge.\n\nEn este caso obtenemos:\n\nmodelo_reg &lt;-  linear_reg(mixture = 0, penalty = 0.1) |&gt;\n  set_engine(\"glmnet\", lambda.min.ratio = 0)\nflujo_reg &lt;- workflow() |&gt; \n  add_model(modelo_reg) |&gt; \n  add_recipe(receta)\nflujo_reg &lt;- fit(flujo_reg, dat_ent)\nmod_reg  &lt;- flujo_reg |&gt; extract_fit_parsnip()\n\nLos coeficientes del modelo penalizado son:\n\ncoefs_penalizado &lt;- tidy(mod_reg) \n\nLoading required package: Matrix\n\n\n\nAttaching package: 'Matrix'\n\n\nThe following objects are masked from 'package:tidyr':\n\n    expand, pack, unpack\n\n\nLoaded glmnet 4.1-7\n\ncoefs_penalizado\n\n# A tibble: 101 × 3\n   term        estimate penalty\n   &lt;chr&gt;          &lt;dbl&gt;   &lt;dbl&gt;\n 1 (Intercept)  -0.236      0.1\n 2 V1           -0.0774     0.1\n 3 V2            0.0340     0.1\n 4 V3           -0.0405     0.1\n 5 V4            0.151      0.1\n 6 V5            0.150      0.1\n 7 V6            0.114      0.1\n 8 V7           -0.207      0.1\n 9 V8            0.0148     0.1\n10 V9            0.191      0.1\n# ℹ 91 more rows\n\n\nNótese que efectivamente la suma de cuadrados de los coeficientes penalizados es considerablemente más chica que las del modelo no penalizado:\n\nsum(coefs_penalizado$estimate[-1]^2)\n\n[1] 1.957447\n\n\n\nsum(coefs_1$estimate[-1]^2)\n\n[1] 12.59754\n\n\nLos nuevos coeficientes estimados tienen menor variación, y están más cercanos a los valores reales:\n\nqplot(coefs_1$valor[-1], coefs_penalizado$estimate[-1]) + \n  xlab('Coeficientes') + \n  ylab('Coeficientes estimados') +\n  geom_abline()\n\n\n\n\n\npreds_prueba_2 &lt;- predict(mod_reg, dat_pr) |&gt; \n  bind_cols(dat_pr |&gt; select(y))\npreds_prueba_ambas &lt;- bind_rows(\n          preds_prueba |&gt; mutate(tipo = \"sin penalizar\"),\n          preds_prueba_2 |&gt; mutate(tipo = \"penalizado\"))\nggplot(preds_prueba_ambas, aes(x = y, y = .pred)) +\n  geom_abline(colour = \"red\") +\n  geom_point(alpha = 0.3) + \n  xlab(\"Predicción\") + ylab(\"y\") +\n  facet_wrap(~ tipo, nrow = 1) + \n  labs(subtitle = \"Muestra de prueba\") \n\n\n\n\n\nmetricas &lt;- metric_set(mae, rmse)\nres_1 &lt;- metricas(preds_prueba, truth = y, estimate = .pred) |&gt; \n  mutate(tipo = \"no penalizado\")\nres_2 &lt;- metricas(preds_prueba_2, truth = y, estimate = .pred) |&gt; \n  mutate(tipo = \"penalizado\")\nbind_rows(res_1, res_2) |&gt;\n  arrange(.metric) |&gt; \n  gt() |&gt; fmt_number(.estimate, decimals = 2)\n\n\n\n\n\n  \n    \n    \n      .metric\n      .estimator\n      .estimate\n      tipo\n    \n  \n  \n    mae\nstandard\n2.34\nno penalizado\n    mae\nstandard\n1.27\npenalizado\n    rmse\nstandard\n2.95\nno penalizado\n    rmse\nstandard\n1.60\npenalizado\n  \n  \n  \n\n\n\n\nY vemos que los errores de predicción se reducen considerablemente.\n\nObsérvese que esta mejora en varianza tiene un costo: un aumento en el sesgo (observa en los extremos de las predicciones regularizadas).\nSin embargo, lo que nos importa principalmente es reducir el error de predicción, y eso lo logramos escogiendo un balance sesgo-varianza apropiado para los datos y el problema.\n\n\n\n\n\n\n\nRegularización L2\n\n\n\nCuando agregamos el término de penalización tipo ridge al error de entrenamiento como objetivo a minimizar en el ajuste, los coeficientes de la solución penalizada están encogidos con respecto a los no penalizados.\nRegularizar reduce la varianza de los coeficientes a lo largo de distintas muestras de entrenamiiento, lo que reduce la posibilidad de sobreajuste.\nUtilizamos regularización para reducir el error de predicción cuando el problema es variabilidad grande de los coeficientes (coeficientes ruidosos) en modelos relativamente grandes o con pocos datos de entrenamiento.\n\n\nEn general, a métodos donde restringimos el espacio de modelos o penalizamos ajustes complejos en la función de pérdida que nos interesa se llaman métodos con regularización. Un ejemplos es todos los modelos donde en lugar de considerar la función de perdida \\(L\\) solamente, consideramos minimizar\n\\[L(f) + \\Omega(f),\\] donde \\(f\\) es una medida de la complejidad, como puede ser: que la función \\(f\\) tiene oscilaciones grandes o pendientes grandes, tiene un número grande de discontinuidades, etc."
  },
  {
    "objectID": "05-regularizacion-1.html#ejemplo-2-penalización-y-estimaciones-ruidosas",
    "href": "05-regularizacion-1.html#ejemplo-2-penalización-y-estimaciones-ruidosas",
    "title": "5  Regularización y variabilidad",
    "section": "5.3 Ejemplo 2: penalización y estimaciones ruidosas",
    "text": "5.3 Ejemplo 2: penalización y estimaciones ruidosas\nConsideremos los siguientes datos clásicos de Radiación Solar, Temperatura, Velocidad del Viento y Ozono para distintos días en Nueva York (Chambers et al. (1983)):\n\nair_data &lt;- airquality |&gt; \n    mutate(Wind_cat = cut(Wind, quantile(Wind, c(0, 0.33, 0.66, 1)), \n                          include.lowest = T)) |&gt; \n    filter(!is.na(Ozone) & !is.na(Solar.R))\nair &lt;- air_data\nggplot(air, aes(x = Solar.R, y = Ozone,  colour = Temp)) + \n  geom_point() +\n  facet_wrap(~Wind_cat, ncol = 3) + \n  scale_colour_gradientn(colours = rainbow(2, rev = TRUE))\n\n\n\n\nLa gráfica muestra algunas interacciones y relaciones no lineales. Formulamos un modelo lineal como sigue:\n\nreceta_ozono &lt;- recipe(Ozone ~ Temp + Wind + Solar.R,\n                       data = air) |&gt; \n  step_ns(Temp, Wind, Solar.R, deg_free = 2) |&gt; \n  step_interact(terms = ~ starts_with(\"Temp_ns\"):starts_with(\"Wind_ns\")) |&gt; \n  step_interact(terms = ~ starts_with(\"Temp_ns\"):starts_with(\"Solar.R_ns\"))\najuste_ozono &lt;- workflow() |&gt; \n  add_recipe(receta_ozono) |&gt; \n  add_model(linear_reg() |&gt; set_engine(\"lm\")) |&gt; \n  fit(air)\n\nY el ajuste se ve como sigue:\n\npred_grid &lt;- expand_grid(Wind = c(5,10,15), \n                         Temp = seq(60, 90, 10), \n                         Solar.R = seq(20, 300, by = 10)) |&gt; \n    mutate(Wind_cat = cut(Wind, \n           quantile(airquality$Wind, c(0, 0.33, 0.66, 1)), \n           include.lowest = T))\npred_grid &lt;- pred_grid |&gt; \n  bind_cols(predict(ajuste_ozono, pred_grid))\ng_lineal &lt;- ggplot(air, aes(x = Solar.R, colour = Temp)) + \n    geom_point(aes(y = Ozone)) +\n    facet_wrap( ~ Wind_cat) + \n    scale_colour_gradientn(colours = rainbow(2, rev = TRUE)) +\n    geom_line(data = pred_grid, \n      aes(y = .pred, group = interaction(Temp, Wind_cat)), size = 1) +\n    labs(subtitle = \"Curvas de modelo lineal, para viento = 5, 10, 15\") \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ng_lineal\n\n\n\n\nNótese que algunos aspectos de este modelo parecen ser muy ruidosos: por ejemplo, el comportamiento de las curvas para el primer pánel (donde hay pocos datos de temperatura baja), el hecho de que en algunos casos parece haber curvaturas decrecientes e incluso predicciones negativas. No deberíamos dar mucho crédito a las predicciones de este modelo, y tiene peligro de producir predicciones desastrosas.\nSin embargo, si usamos algo de regularización:\n\najuste_ozono &lt;- workflow() |&gt; \n  add_recipe(receta_ozono) |&gt; \n  add_model(linear_reg(mixture = 0, penalty = 3.0) |&gt; \n              set_engine(\"glmnet\", lambda.min.ratio = 0)) |&gt; \n  fit(air)\n# nota: normalmente no es necesario usar lambda.min.ratio\n\nY el ajuste se ve como sigue:\n\npred_grid &lt;- expand_grid(Wind = c(5,10,15), \n                         Temp = seq(60, 90, 10), \n                         Solar.R = seq(10, 320, by = 10)) |&gt; \n    mutate(Wind_cat = \n           cut(Wind, quantile(airquality$Wind, c(0, 0.33, 0.66, 1)), \n               include.lowest = T))\npred_grid &lt;- pred_grid |&gt; \n  bind_cols(predict(ajuste_ozono, pred_grid))\ng_lineal &lt;- ggplot(air, aes(x = Solar.R, colour = Temp)) + \n    geom_point(aes(y = Ozone)) +\n    facet_wrap( ~ Wind_cat) + \n    scale_colour_gradientn(colours = rainbow(2, rev = TRUE)) +\n    geom_line(data = pred_grid, aes(y = .pred, group = interaction(Temp, Wind_cat)), size = 1) +\n    labs(subtitle = \"Curvas de modelo lineal, para viento = 5, 10, 15\") \ng_lineal\n\n\n\n\nEste ajuste se ve mucho más razonable."
  },
  {
    "objectID": "05-regularizacion-1.html#regresión-ridge-escogiendo-el-parámetro-de-complejidad",
    "href": "05-regularizacion-1.html#regresión-ridge-escogiendo-el-parámetro-de-complejidad",
    "title": "5  Regularización y variabilidad",
    "section": "5.4 Regresión ridge: escogiendo el parámetro de complejidad",
    "text": "5.4 Regresión ridge: escogiendo el parámetro de complejidad\nComo vimos antes, no es posible seleccionar el parámetro \\(\\lambda\\) usando la muestra de entrenamiento (¿con qué \\(\\lambda\\) cómo se obtiene el menor error cuadrático medio sobre la muestra de entrenamiento). Usaremos un conjunto de validación relativamente grande\n\nset.seed(191)\nsource(\"../R/casas_traducir_geo.R\")\n\nRows: 1460 Columns: 81\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (43): MSZoning, Street, Alley, LotShape, LandContour, Utilities, LotConf...\ndbl (38): Id, MSSubClass, LotFrontage, LotArea, OverallQual, OverallCond, Ye...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nRows: 27 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Neighborhood\ndbl (2): lat, long\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# esta proporción es para ejemplificar\ncasas_split &lt;- initial_split(casas, prop = 0.25) \ncasas_entrena &lt;- training(casas_split)\nreceta_casas &lt;- \n  recipe(precio_miles ~ calidad_gral +\n           area_hab_m2 + area_garage_m2 + area_sotano_m2 + \n           area_2o_piso_m2 + \n           año_construccion + año_venta + condicion_venta +\n           nombre_zona + \n           condicion_gral + \n           condicion_exteriores + \n           tipo_sotano + calidad_sotano +\n           baños_completos +  num_coches +\n           aire_acondicionado + \n           tipo_edificio + estilo, \n         data = casas_entrena) |&gt; \n  step_filter(condicion_venta == \"Normal\") |&gt; \n  step_select(-condicion_venta, skip = TRUE) |&gt; \n  step_cut(calidad_gral, breaks = c(3, 5, 7, 8), \n           include_outside_range = TRUE) |&gt; \n  step_cut(condicion_gral, breaks = c(3, 5, 7, 8), \n           include_outside_range = TRUE) |&gt; \n  step_mutate(sin_piso_2 = as.numeric(area_2o_piso_m2 == 0)) |&gt;\n  step_novel(tipo_sotano, calidad_sotano) |&gt; \n  step_novel(condicion_exteriores, tipo_edificio, estilo) |&gt; \n  step_unknown(tipo_sotano, calidad_sotano, new_level = \"sin_sotano\") |&gt; \n  step_unknown(condicion_exteriores) |&gt; \n  step_other(nombre_zona, threshold = 0.05) |&gt; \n  step_dummy(calidad_gral, condicion_gral, \n             nombre_zona, aire_acondicionado,\n             calidad_sotano, tipo_sotano, condicion_exteriores, \n             tipo_edificio, estilo) |&gt; \n  step_interact(terms = ~ c(area_hab_m2, area_garage_m2, \n    area_sotano_m2, area_2o_piso_m2):starts_with(\"calidad_gral\")) |&gt; \n  step_interact(terms = ~ area_sotano_m2:starts_with(\"calidad_sotano\")) |&gt; \n  step_interact(terms = ~ c(area_hab_m2, area_garage_m2, \n    area_sotano_m2, area_2o_piso_m2):starts_with(\"condicion_gral\")) |&gt; \n  step_interact(terms = ~ c(area_hab_m2, area_garage_m2, \n    area_sotano_m2, area_2o_piso_m2):starts_with(\"nombre_zona\")) |&gt; \n  step_zv(all_predictors())\n\nPara ver el número de entradas de este modelo:\n\nprep(receta_casas) |&gt; juice() |&gt; dim()\n\n[1] 289 108\n\n\n\nmodelo_penalizado &lt;- linear_reg(mixture = 0.0, penalty = tune()) |&gt; \n  set_engine(\"glmnet\", lambda.min.ratio = 0)\nflujo_casas &lt;- workflow() |&gt; \n  add_recipe(receta_casas) |&gt; \n  add_model(modelo_penalizado)\n\nConstruimos manualmente el conjunto de validación:\n\n# creamos un objeto con datos de entrenamiento y de prueba\nval_split &lt;- manual_rset(casas_split |&gt; list(), \"validación\")\nlambda_params &lt;- parameters(penalty(range = c(-3, 3), \n                                    trans = log10_trans()))\nlambda_grid &lt;- grid_regular(lambda_params, levels = 20)\nlambda_grid\n\n# A tibble: 20 × 1\n      penalty\n        &lt;dbl&gt;\n 1    0.001  \n 2    0.00207\n 3    0.00428\n 4    0.00886\n 5    0.0183 \n 6    0.0379 \n 7    0.0785 \n 8    0.162  \n 9    0.336  \n10    0.695  \n11    1.44   \n12    2.98   \n13    6.16   \n14   12.7    \n15   26.4    \n16   54.6    \n17  113.     \n18  234.     \n19  483.     \n20 1000      \n\n\n\nmis_metricas &lt;- metric_set(rmse)\neval_tbl &lt;- tune_grid(flujo_casas,\n                      resamples = val_split,\n                      grid = lambda_grid,\n                      metrics = mis_metricas) \nridge_ajustes_tbl &lt;- eval_tbl |&gt;\n  unnest(cols = c(.metrics)) |&gt; \n  select(id, penalty, .metric, .estimate)\nridge_ajustes_tbl |&gt; gt()\n\n\n\n\n\n  \n    \n    \n      id\n      penalty\n      .metric\n      .estimate\n    \n  \n  \n    validación\n1.000000e-03\nrmse\n35.36721\n    validación\n2.069138e-03\nrmse\n35.36721\n    validación\n4.281332e-03\nrmse\n35.36721\n    validación\n8.858668e-03\nrmse\n35.36721\n    validación\n1.832981e-02\nrmse\n35.36721\n    validación\n3.792690e-02\nrmse\n35.36721\n    validación\n7.847600e-02\nrmse\n34.88798\n    validación\n1.623777e-01\nrmse\n33.64199\n    validación\n3.359818e-01\nrmse\n32.41837\n    validación\n6.951928e-01\nrmse\n31.22570\n    validación\n1.438450e+00\nrmse\n30.26859\n    validación\n2.976351e+00\nrmse\n29.62744\n    validación\n6.158482e+00\nrmse\n29.45135\n    validación\n1.274275e+01\nrmse\n29.65517\n    validación\n2.636651e+01\nrmse\n30.23900\n    validación\n5.455595e+01\nrmse\n31.52315\n    validación\n1.128838e+02\nrmse\n34.17121\n    validación\n2.335721e+02\nrmse\n38.82727\n    validación\n4.832930e+02\nrmse\n45.67700\n    validación\n1.000000e+03\nrmse\n54.01752\n  \n  \n  \n\n\n\n\n\nggplot(ridge_ajustes_tbl, \n    aes(x = penalty, y = .estimate, colour = .metric)) + \n  geom_point() + geom_line() + scale_x_log10() \n\n\n\n\nY vemos que con una penalización alrededor de \\(\\lambda = 1\\) podemos obtener mejor desempeño que con el modelo no regularizado.\nPregunta: en qué partes de la gráfica es relativamente grande la varianza? ¿en qué parte es relativamente grande el sesgo?"
  },
  {
    "objectID": "05-regularizacion-1.html#regresión-lasso",
    "href": "05-regularizacion-1.html#regresión-lasso",
    "title": "5  Regularización y variabilidad",
    "section": "5.5 Regresión lasso",
    "text": "5.5 Regresión lasso\nSe puede controlar la varianza de mínimos cuadrados de otras maneras. Cuando la varianza proviene también de la inclusión de variables que no necesariamente están relacionadas con la respuesta, podemos usar métodos de selección de variables, como en stepwise regression, por ejemplo.\nOtra manera interesante de lograr mejor desempeño predictivo con modelos más parsimoniosos resulta de usar un término de penalización distinto al de ridge. En ridge, el problema que resolvemos es minimizar el objetivo\n\\[D(\\beta) + \\lambda \\sum_{j=1}^p \\beta_j^2\\]\nEn regresión lasso, usamos una penalización de tipo \\(L_1\\):\n\\[D(a) + \\lambda \\sum_{j=1}^p |\\beta_j|\\] En un principio, no parece ser muy diferente a ridge. Veremos sin embargo que usar esta penalización también se puede ver como un proceso de selección de variables."
  },
  {
    "objectID": "05-regularizacion-1.html#lasso-vs-ridge",
    "href": "05-regularizacion-1.html#lasso-vs-ridge",
    "title": "5  Regularización y variabilidad",
    "section": "5.6 Lasso vs Ridge",
    "text": "5.6 Lasso vs Ridge\nConsideramos cómo predecir el porcentaje de grasa corporal a partir de distintas mediciones de dimensiones corporales:\n\ndat_grasa &lt;- read_csv(file = '../datos/bodyfat.csv') \nset.seed(183)\ngrasa_particion &lt;- initial_split(dat_grasa, 0.7)\ngrasa_ent &lt;- training(grasa_particion)\ngrasa_pr &lt;- testing(grasa_particion)\n\n\n# nota: con glmnet no es necesario normalizar, pero aquí lo hacemos\n# para ver los coeficientes en términos de las variables estandarizadas:\ngrasa_receta &lt;- recipe(grasacorp ~ ., grasa_ent) |&gt; \n  update_role(cadera, cuello, muñeca, \n              tobillo, rodilla, new_role = \"ninguno\") |&gt; \n  step_normalize(all_predictors()) |&gt; \n  prep()\nmodelo_2 &lt;- linear_reg(mixture = 0, penalty = 0) |&gt; \n  set_engine(\"glmnet\", lambda.min.ratio = 1e-20) \nflujo_2 &lt;- workflow() |&gt; \n  add_model(modelo_2) |&gt; \n  add_recipe(grasa_receta)\nflujo_2 &lt;- flujo_2 |&gt; fit(grasa_ent) \nmodelo_2 &lt;- extract_fit_parsnip(flujo_2)\ncoefs &lt;- modelo_2 |&gt; pluck(\"fit\") |&gt;tidy() |&gt; \n  filter(term != \"(Intercept)\")\ng_l2 &lt;- ggplot(coefs, aes(x = lambda, y = estimate, colour = term)) +\n  geom_line(size = 1.4) + scale_x_log10() +\n  scale_colour_manual(values = cbb_palette) +\n  labs(subtitle = \"Regularizacion L2\")\ng_l2\n\n\n\n\nEstas gráfica se llama traza de los coeficientes, y nos muestra cómo cambian los coefi´cientes conforme cambiamos la regularización. Nótese que cuando la regularización es chica, obtenemos algunos resultados contra-intuitivos como que el coeficiente de peso es negativo para predecir el nivel de grasa corporal. Cuando regularizamos más, este coeficiente es positivo. La razón de esto tiene qué ver con la correlación fuerte de las variables de entrada, por ejemplo:\n\ncor(grasa_ent |&gt; select(peso, abdomen, biceps, muslo)) |&gt; \n  round(2)\n\n        peso abdomen biceps muslo\npeso    1.00    0.91   0.81  0.88\nabdomen 0.91    1.00   0.71  0.81\nbiceps  0.81    0.71   1.00  0.75\nmuslo   0.88    0.81   0.75  1.00\n\n\nAhora probemos con regularización lasso:\n\n## mixture = 1 es regresión lasso\nmodelo_1 &lt;-  linear_reg(mixture = 1, penalty = 0) |&gt; \n  set_engine(\"glmnet\", lambda.min.ratio = 0) \nflujo_1 &lt;- workflow() |&gt; \n  add_model(modelo_1) |&gt; \n  add_recipe(grasa_receta)\n\n\nflujo_1 &lt;- flujo_1 |&gt; fit(grasa_ent) \nmodelo_1 &lt;- extract_fit_parsnip(flujo_1)\ncoefs &lt;- modelo_1 |&gt; pluck(\"fit\") |&gt; tidy() |&gt; \n  filter(term != \"(Intercept)\")\nggplot(coefs, \n    aes(x = lambda, y = estimate, colour = term)) +\n  geom_line(size = 1.4) + scale_x_log10() +\n  scale_colour_manual(values = cbb_palette) +\n  labs(subtitle = \"Regularizacion L1\")\n\n\n\n\nY nótese que conforme aumentamos la penalización, algunas variables salen del modelo (sus coeficientes son cero). Por ejemplo, para un valor de \\(lambda\\) intermedio, obtenemos un modelo simple de la forma:\n\ncoefs |&gt; filter(step == 21) |&gt; \n  select(term, estimate, lambda)\n\n# A tibble: 3 × 3\n  term     estimate lambda\n  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n1 edad        0.160  0.434\n2 estatura   -0.452  0.434\n3 abdomen     6.67   0.434\n\n\nY nótese que este modelo solo incluye 3 variables.La traza confirma que la regularización lasso, además de encoger coeficientes, saca variables del modelo conforme el valor de regularización aumenta.\nLa razón de esta diferencia cualitativa entre cómo funciona lasso y ridge se puede entender considerando que los problemas de penalización mostrados arriba puede escribirse en forma de problemas de restricción. Por ejemplo, lasso se puede reescribir como el problema de resolver\n\\[\\min_a D(\\beta)\\] sujeto a \\[\\sum_{i=1}^p |\\beta_j| &lt; t\\] En la gráfica siguiente (tomada de Hastie, Tibshirani, y Friedman (2017)), lasso está a la izquierda y ridge está a la derecha, las curvas rojas son curvas de nivel de la suma de cuadrados \\(D(a)\\), y \\(\\hat{\\beta}\\) es el estimador usual de mínimos cuadrados de los coeficientes (sin penalizar). En azul está la restricción:\n\n\n\nRidge vs Lasso\n\n\n\n\n\n\n\n\nRegularización para modelos lineales\n\n\n\n\nEn regresión ridge, los coeficientes se encogen gradualmente desde la solución no restringida hasta el origen. Ridge es un método de encogimiento de coeficientes. Regresión ridge es especialmente útil cuando tenemos varias variables de entrada fuertemente correlacionadas. Regresión ridge intenta encoger juntos coeficientes de variables correlacionadas para reducir varianza en las predicciones.\nEn regresión lasso, los coeficientes se encogen gradualmente, pero también se excluyen variables del modelo. Por eso lasso es un método de encogimiento y selección de variables. Lasso encoge igualmente coeficientes para reducir varianza, pero también comparte similitudes con regresión de mejor subconjunto, en donde para cada número de variables \\(l\\) buscamos escoger las \\(l\\) variables que den el mejor modelo. Sin embargo, el enfoque de lasso es más escalable y puede calcularse de manera más simple.\n\n\n\nNota: es posible también utilizar una penalización que mezcla ridge y lasso:\n\\[\\lambda \\left (\\alpha \\sum_j |a_j| + (1-\\alpha)\\sum_j a_j^2 \\right )\\]\ny \\(\\alpha\\) es un parámetro que podemos afinar:\n\n# elastic net = ridge + lasso\n# mixture es alpha y penalty es lambda\nmodelo_enet &lt;- linear_reg(mixture = 0.5, penalty = 0.05)\n# y si queremos afinar:\nmodelo_enet &lt;- linear_reg(mixture = tune(), penalty = tune())"
  },
  {
    "objectID": "05-regularizacion-1.html#regularización-con-descenso-en-gradiente",
    "href": "05-regularizacion-1.html#regularización-con-descenso-en-gradiente",
    "title": "5  Regularización y variabilidad",
    "section": "5.7 Regularización con descenso en gradiente",
    "text": "5.7 Regularización con descenso en gradiente\nOtra forma de hacer regularización que se utiliza comunmente se basa en el método de minimización que usamos para obtener nuestra función \\(\\hat{f}\\) para hacer predicciones. La idea es utilizar un método iterativo que comience con una \\(f_0\\) simple, y luego iterar a una nueva \\(f_1\\) que se adapta mejor a los datos pero no es muy diferente a \\(f_0\\). En lugar de seguir iterando hasta llegar a un mínimo de \\(L(f),\\) evaluamos con una muestra de prueba para encontrar un lugar apropiado para detenernos (early stopping). También podemos modificar \\(L(f)\\) en cada paso para evitar atorarnos en un mínimo sobreajustado.\nUna manera de hacer esto es usando el método de descenso estocástico, (ver apéndices Apéndice A y Apéndice B) que consiste en:\n\nEn cada iteración \\(i\\) construimos una función de pérdida \\(L^{(i)}(f)\\) basada solamente en una parte de los datos (batch).\nEn cada iteración \\(i\\) sólo nos movemos en una dirección de descenso para los parámetros, sin intentar buscar un mínimo local o global. La dirección de descenso está dada por \\(-\\nabla L^{(i)}\\).\n\nAunque este método es más útil en casos como redes neuronales o métodos basados en árboles, podemos comenzar por un ejemplo en regresión lineal para entender su efecto regularizador:\n\nlibrary(keras)\nx_grasa &lt;- grasa_receta |&gt; juice() |&gt; \n  select(abdomen, edad, antebrazo, biceps, estatura, muslo, pecho, peso) |&gt; \n  as.matrix()\nvars_nombres &lt;- colnames(x_grasa)\ny_grasa &lt;- grasa_receta |&gt; juice() |&gt; pull(grasacorp)\n## keras tiene distintos algos de optimización\nmodelo_reg &lt;- keras_model_sequential() |&gt; \n  layer_dense(units = 1, \n    kernel_initializer = initializer_constant(0))\nmodelo_reg |&gt; compile(\n  loss = \"mse\",\n  optimizer = optimizer_sgd(learning_rate = 0.01)\n)\n# esto es más eficiente hacerlo con callbacks en general:\npesos_tbl &lt;- map_dfr(1:400, function(epoca){\n    modelo_reg |&gt; fit(\n      x = x_grasa, y = y_grasa,\n      epochs = 1, \n      verbose = FALSE)\n    pesos_tbl &lt;- get_weights(modelo_reg)[[1]] |&gt; t() |&gt; \n      as_tibble() \n    names(pesos_tbl) &lt;- vars_nombres\n    pesos_tbl |&gt; mutate(epoca = epoca)\n  }\n)\n\n\nlibrary(patchwork)\ng_dest &lt;- pesos_tbl |&gt; pivot_longer(cols  = -contains(c(\"grasacorp\", \"epoca\"))) |&gt; \n  ggplot(aes(x = epoca, y = value, colour = name)) + \n  geom_line(linewidth = 1.1) +   scale_colour_manual(values = cbb_palette) +\n  scale_x_continuous(trans  = compose_trans(\"log10\", \"reverse\")) +\n  labs(subtitle = \"Descenso estocástico\")\n\ng_dest + g_l2\n\n\n\n\nY vemos que si inicializamos el proceso de minimización con valores chicos, pararnos en una época (iteración completa sobre los datos) nos permite tener un efecto similar al de utilizar regularización tipo L2.\n\n\n\n\n\n\nDescenso estocástico\n\n\n\nEl método de descenso estocástico (usualmente por minilotes) nos permite resolver problemas de optimización, y muchas veces actúa también como regularizador (al cambiar en cada paso la función de pérdida, y utilizando early stopping). Tiene las ventajas adicionales de que:\n\nAl cambiar la función de pérdida en cada paso, también es posible escapar de puntos estacionarios subóptimos (si el problema no tiene varios puntos estacionarios, es decir, donde el gradiente es cero).\nEs eficiente en el sentido de que no es necesario utilizar todo los datos para hacer un paso suficientemente bueno, y es escalable a grandes conjuntos de datos.\n\nEs crucial escoger un tamaño de paso adecuado para cada problema. Generalmente se considera un parámetro que debe ser afinado, de manera similar al parámetro de regularización L2 que vimos arriba.\n\n\n\n\n\n\nChambers, J. M., W. S. Cleveland, B. Kleiner, y P. A. Tukey. 1983. Graphical Methods for Data Analysis. Chapman & Hall statistics series. Wadsworth International Group. https://books.google.com.mx/books?id=I-tQAAAAMAAJ.\n\n\nHastie, Trevor, Robert Tibshirani, y Jerome Friedman. 2017. The Elements of Statistical Learning. Springer Series en Statistics. Springer New York Inc. http://web.stanford.edu/~hastie/ElemStatLearn/."
  },
  {
    "objectID": "06-redes-neuronales-1.html#introducción-a-redes-neuronales",
    "href": "06-redes-neuronales-1.html#introducción-a-redes-neuronales",
    "title": "6  Redes neuronales (intro)",
    "section": "6.1 Introducción a redes neuronales",
    "text": "6.1 Introducción a redes neuronales\nEn partes anteriores, vimos cómo hacer más flexibles los métodos de regresión: la idea es construir entradas derivadas a partir de las variables originales, e incluirlas en el modelo de regresión. Este enfoque es bueno cuando tenemos relativamente pocas variables originales de entrada, y tenemos una idea de qué variables derivadas es buena idea incluir (por ejemplo, splines para una variable como edad, interacciones para variables importantes, etc). Sin embargo, si hay una gran cantidad de entradas, esta técnica puede ser prohibitiva en términos de cálculo y trabajo manual.\nPor ejemplo, si tenemos unas 100 entradas numéricas, al crear todas las interacciones \\(x_i x_j\\) y los cuadrados \\(x_i^2\\) terminamos con unas 5150 variables. Para el problema de dígitos (256 entradas o pixeles) terminaríamos con unas 32 mil entradas adicionales. Aún cuando es posible regularizar, en estos casos suena más conveniente construir entradas derivadas a partir de los datos.\nPara hacer esto, consideramos entradas \\(X_1, . . . , X_p\\), y supongamos que tenemos un problema regresión donde queremos predecir \\(Y\\). Aunque hay muchas maneras de construir entradas derivadas, una manera simple sería construir \\(m\\) nuevas entradas mediante:\n\\[a_k = h \\left ( \\theta_{k,0} + \\sum_{j=1}^p \\theta_{k,j}x_j\n\\right)\\]\npara \\(k=1,\\ldots, m\\), donde \\(h\\) es una función no lineal (logística o relu entre otras), y las \\(\\theta\\) son parámetros que seleccionaremos más tarde. La idea es hacer combinaciones lineales de variables transformadas.\nModelamos ahora la respuesta usando las entradas derivadas en lugar de las originales en una regresión lineal:\n\\(a_1, . . . , a_m\\): \\[f(x) =  \\beta_0 + \\sum_{j=1}^m \\beta_ja_j\\]\nPodemos representar este esquema con una red dirigida (\\(m=3\\) variables derivadas):\n\n\n\n\n\n\nLa función logística\nUna de las transformaciones \\(h\\) más comunes para construir entradas derivadas es la función logística:\n\n\n\nLa función logística está dada por \\[h(x)=\\frac{e^x}{1+e^x}\\]\n\n\n\nh &lt;- function(x){exp(x)/(1+exp(x)) }\nggplot(tibble(x = seq(-6, 6, 0.01)), aes(x = x)) + stat_function(fun = h)\n\n\n\n\nObservaciones:\n\n¿Por qué usar \\(h\\) para las entradas derivadas \\(a_k\\)? En primer lugar, nótese que si no transformamos con alguna función no lineal \\(h\\), el modelo final \\(p_1\\) para la probabilidad condicional es el mismo que el de regresión logística (combinaciones lineales de combinaciones lineales son combinaciones lineales). Sin embargo, al transformar con \\(h\\), las \\(x_j\\) contribuyen de manera no lineal a las entradas derivadas.\nLas variables \\(a_k\\) que se pueden obtener son similares (para una variable de entrada) a los splines que vimos en la parte anterior.\nEs posible demostrar que si se crean suficientes entradas derivadas (\\(m\\) es suficientemente grande), entonces la función \\(f(x)\\) puede aproximar cualquier función continua. La función \\(h\\) (que se llama función de activación no es especial: funciones continuas con forma similar a la sigmoide (logística) pueden usarse también (por ejemplo, arcotangente, o lineal rectificada). La idea es que cualquier función se puede aproximar mediante superposición de funciones tipo sigmoide (ver por ejemplo Cybenko 1989, Approximation by Superpositions of a Sigmoidal Function).\n\n\n\n¿Cómo construyen entradas las redes neuronales?\nComencemos por un ejemplo simple de clasificación binaria con una sola entrada \\(x\\). Supondremos que el modelo verdadero está dado por:\n\nh &lt;- function(x){\n    1/(1 + exp(-x)) # es lo mismo que exp(x)/(1 + exp(x))\n}\nx &lt;- seq(-2, 2, 0.1)\nf &lt;- atan(2 - 2 * x^2)\nset.seed(2805721)\nx_1 &lt;- runif(10, -2, 2)\ny &lt;- rnorm(10, atan(2 - 2 * x_1^2), 0.2)\ndatos &lt;- tibble(x_1, y)\ndat_f &lt;- tibble(x, f)\ng &lt;- ggplot(dat_f) + geom_line(aes(x, f))\ng\n\n\n\ng + geom_point(data = datos, aes(x = x_1, y = y), colour = 'red')\n\n\n\n\ndonde adicionalmente graficamos 30 datos simulados. Recordamos que queremos ajustar la curva roja, que da la probabilidad condicional de clase. Podríamos ajustar un modelo de regresión logística expandiendo manualmente el espacio de entradas agregando \\(x^2\\), y obtendríamos un ajuste razonable. Pero la idea aquí es que podemos crear entradas derivadas de forma automática.\nSupongamos entonces que pensamos crear dos entradas \\(a_1\\) y \\(a_2\\), funciones de \\(x_1\\), y luego predecir \\(g.1\\), la clase, en función de estas dos entradas. Por ejemplo, podríamos tomar:\n\n\n\n\n\ndonde hacemos una regresión para predecir \\(y\\) mediante \\[f(a) = \\beta_0 + \\beta_1a_1+\\beta_2 a_2,\\] \\(a_1\\) y \\(a_2\\) están dadas por \\[a_1(x)=h(\\beta_{1,0} + \\beta_{1,1} x_1),\\] \\[a_2(x)=h(\\beta_{2,0} + \\beta_{2,1} x_1).\\]\nPor ejemplo, podríamos tomar\n\na_1 &lt;- h( 1 + 2 * x)  # 2(x+1/2)\na_2 &lt;- h(-1 + 2 * x)  # 2(x-1/2) # una es una versión desplazada de otra.\n\nLas funciones \\(a_1\\) y \\(a_2\\) dependen de \\(x\\) de la siguiente forma:\n\ndat_a &lt;- tibble(x = x, a_1 = a_1, a_2 = a_2)\ndat_a_2 &lt;- dat_a |&gt; gather(variable, valor, a_1:a_2)\nggplot(dat_a_2, aes(x=x, y=valor, colour=variable, group=variable)) + geom_line()\n\n\n\n\nSi las escalamos y sumamos, obtenemos\n\ndat_a &lt;- tibble(x=x, a_1 = a_1, a_2 =  a_2, \n  suma = -1.5 +  6 * a_1 -  6 * a_2)\ndat_a_2 &lt;- dat_a |&gt; \n  pivot_longer(a_1:suma, names_to = \"variable\", values_to = \"valor\")\nggplot(dat_a_2, aes(x = x, y = valor, colour = variable, group = variable)) + geom_line()\n\n\n\n\ny finalmente obtenemos:\n\ndat_2 &lt;- tibble(x, f = (-1.5 + 6 * a_1 - 6 * a_2))\nggplot(dat_2, aes(x=x, y = f)) + geom_line()+\ngeom_line(data=dat_f, aes(x=x,y=f), col='red') +\n   geom_point(data = datos, aes(x = x_1, y = y))\n\n\n\n\nque da un ajuste razonable. Este es un ejemplo de cómo la mezcla de dos funciones logísticas puede replicar esta función con forma de chipote. Otras funciones más complejas se pueden obtener incluyendo más \\(a_j\\)’s que son versiones escaladas y desplazadas de la función logística. El mecanismo para combinar estas \\(a_j\\)’s es similar al de los splines que vimos en la sección anterior.\n\n\n¿Cómo ajustar los parámetros?\nPara encontrar los mejores parámetros, minimizamos la devianza sobre los parámetros \\(\\beta_0,\\beta_1,\\beta_2\\) y \\(\\beta_{1,0},\\beta_{1,1},\\beta_{2,0},\\beta_{2,1}\\).\nVeremos más adelante que conviene hacer esto usando descenso o en gradiente o descenso en gradiente estocástico, pero por el momento usamos la función optim de R para minimizar la devianza. En primer lugar, creamos una función que para todas las entradas calcula los valores de salida. En esta función hacemos feed-forward de las entradas a través de la red para calcular la salida.\n\n## esta función calcula los valores de cada nodo en toda la red,\n## para cada entrada\nfeed_fow &lt;- function(beta, x){\n  a_1 &lt;- h(beta[1] + beta[2] * x) # calcula variable 1 de capa oculta\n  a_2 &lt;- h(beta[3] + beta[4] * x) # calcula variable 2 de capa oculta\n  f &lt;- (beta[5] + beta[6] * a_1 + beta[7] * a_2) # calcula capa de salida\n  f\n}\n\nNótese que simplemente seguimos el diagrama mostrado arriba para hacer los cálculos, combinando linealmente las entradas en cada capa.\nAhora definimos una función para calcular la devianza. Conviene crear una función que crea funciones, para obtener una función que sólo se evalúa en los parámetros para cada conjunto de datos de entrenamiento fijos:\n\nperdida_cuad_fun &lt;- function(x, y){\n    # esta función es una fábrica de funciones\n   perdida_cuad &lt;- function(beta){\n      f &lt;- feed_fow(beta, x)\n      mean((y - f)^2)\n   }\n  perdida_cuad\n}\n\nPor ejemplo:\n\nperdida_cuad &lt;- perdida_cuad_fun(x_1, y) # crea función\n## ahora dev toma solamente los 7 parámetros beta:\nperdida_cuad(c(0,0,0,0,0,0,0))\n\n[1] 1.034101\n\n\nFinalmente, intentamos resolver el problema de minimización de la pérdida cuadrática de los datos de entrenamiento. Para esto usaremos la función optim de R:\n\nset.seed(5)\nsalida &lt;- optim(rnorm(7), perdida_cuad, method = 'BFGS') # inicializar al azar punto inicial\nbeta &lt;- salida$par\nbeta\n\n[1] -9.097577  5.315080 -6.973249 -6.762489  1.093208 -3.309966 -2.488820\n\n\nY ahora podemos graficar con el vector \\(\\beta\\) encontrado:\n\n## hacer feed forward con beta encontrados\np_2 &lt;- feed_fow(beta, x)\ndat_2 &lt;- data.frame(x, p_2 = p_2)\nggplot(dat_2, aes(x = x, y = p_2)) + geom_line()+\ngeom_line(data = dat_f, aes(x = x, y = f), col='red') +\n   geom_point(data = datos, aes(x = x_1, y = y))\n\n\n\n\nLos coeficientes estimados, que en este caso muchas veces se llaman pesos, son:\n\nbeta |&gt; round(2)\n\n[1] -9.10  5.32 -6.97 -6.76  1.09 -3.31 -2.49\n\n\nque parecen ser muy grandes. Igualmente, de la figura vemos que el ajuste no parece ser muy estable (esto se puede confirmar corriendo con distintos conjuntos de entrenamiento). Podemos entonces regularizar ligeramente la devianza para resolver este problema. En primer lugar, definimos la devianza regularizada (ridge), donde penalizamos todos los coeficientes que multiplican a una variable, pero no los intercepts:\n\nperdida_cuad_fun_r &lt;- function(x, y, lambda){\n    # esta función es una fábrica de funciones\n   perdida_reg &lt;- function(beta){\n         f &lt;- feed_fow(beta, x)\n         # en esta regularizacion quitamos sesgos, pero puede hacerse también con sesgos.\n         mean((y - f)^2) + lambda * sum(beta[c(2,4,6:7)]^2) \n   }\n  perdida_reg\n}\n\n\nperdida_r &lt;- perdida_cuad_fun_r(x_1, y, 0.001) # crea función dev\nset.seed(5)\nsalida &lt;- optim(rnorm(7, 0, 1), perdida_r, method = 'BFGS') # inicializar al azar punto inicial\nbeta &lt;- salida$par\nperdida_cuad(beta) / nrow(datos)\n\n[1] 0.001831033\n\nf_2 &lt;- feed_fow(beta, x)\ndat_2 &lt;- data.frame(x, f_2 = f_2)\nbeta\n\n[1] -2.072798  2.136928 -4.317303 -4.221802  1.458438 -3.053558 -2.952405\n\nggplot(dat_2, aes(x = x, y = f_2)) + geom_line() +\ngeom_line(data = dat_f, aes(x = x, y = f), col='red') +\n   geom_point(data = datos, aes(x = x_1, y = y))\n\n\n\n\ny obtenemos un ajuste más estable. Podemos usar también keras. El modelo, con una capa intermedia de dos unidades, y regularización ridge para los coeficientes, y optimización por descenso en gradiente se define como:\n\nlibrary(keras)\n# para reproducibilidad:\ntensorflow::set_random_seed(13) \n# construir modelo\nejemplo_mod &lt;- keras_model_sequential()\nejemplo_mod |&gt; \n   layer_dense(units = 2, \n    activation = \"sigmoid\", kernel_regularizer = regularizer_l2(0.001)) |&gt; \n  layer_dense(units = 1, \n    activation = \"linear\", kernel_regularizer = regularizer_l2(0.001))\n\n\nx_mat &lt;- as.matrix(datos$x_1, ncol = 1)\ny &lt;- datos$y\n# usamos devianza como medida de error y descenso en gradiente:\nejemplo_mod |&gt; compile(loss = \"mse\", \n  optimizer = optimizer_sgd(learning_rate = 0.2),\n  metrics = \"mse\")\n# nota: esta learning rate (lr) es demasiado alta para problemas típicos\nhistoria &lt;- ejemplo_mod |&gt; \n  fit(x_mat, y, \n      batch_size = nrow(x_mat), epochs = 500, verbose = 0)\n\nDespués de verificar convergencia (chécalo examinando la variable historia), graficamos para ver que obtuvimos resultados similares:\n\ndat_3 &lt;- tibble(x = x, f_2 = predict(ejemplo_mod, as.matrix(x, ncol = 1))[,1])\nggplot(dat_3, aes(x = x, y = f_2)) + geom_line()+\ngeom_line(data = dat_f, aes(x = x, y = f), col='red') +\n   geom_point(data = datos, aes(x = x_1, y = y))\n\n\n\n\nLos coeficientes obtenidos se muestran abajo. Nótese: la primera componente de la lista son los coeficientes de la unidad 1 y 2 para \\(x\\). La segunda son los sesgos u ordenadas al origen, la tercera los coeficientes de la respuesta para las unidades 1 y 2, y el cuarto es el sesgo u ordenada al origen de la unidad de salida:\n\nget_weights(ejemplo_mod)\n\n[[1]]\n         [,1]      [,2]\n[1,] -2.45195 -2.848296\n\n[[2]]\n[1] -2.567334  2.578543\n\n[[3]]\n          [,1]\n[1,] -3.460155\n[2,]  3.080144\n\n[[4]]\n[1] -1.392124\n\n\nEjercicio: compara los coeficientes que obtuviste en este ejemplo con los anteriores."
  },
  {
    "objectID": "06-redes-neuronales-1.html#interacciones-en-redes-neuronales",
    "href": "06-redes-neuronales-1.html#interacciones-en-redes-neuronales",
    "title": "6  Redes neuronales (intro)",
    "section": "6.2 Interacciones en redes neuronales",
    "text": "6.2 Interacciones en redes neuronales\nEs posible capturar interacciones con redes neuronales. Consideremos el siguiente ejemplo simple:\n\nf &lt;- function(x1, x2){\n  2 + 0.1* x1 + 0.1 * x2 + 10 * (x1 - 0.5) * (x2 - 0.5)\n}\ndat &lt;- expand.grid(x1 = seq(0, 1, 0.05), x2 = seq(0, 1, 0.05))\ndat &lt;- dat |&gt; mutate(f = f(x1, x2))\nggplot(dat, aes(x=x1, y=x2)) + geom_tile(aes(fill=f))\n\n\n\n\nEsta función puede entenderse como un o exclusivo: la respuesta es alta sólo cuando \\(x_1\\) y \\(x_2\\) tienen valores opuestos (\\(x_1\\) grande pero \\(x_2\\) chica y viceversa).\nNo es posible modelar correctamente esta función mediante el modelo lineal (sin interacciones). Pero podemos incluir la interacción en el modelo lineal o intentar usar una red neuronal. Primero simulamos unos datos y probamos el modelo logístico con y sin interacciones:\n\nset.seed(322)\nn &lt;- 2000\ndat_ent &lt;- tibble(x1 = rbeta(n, 1, 1), x2 = rbeta(n, 1, 1)) |&gt;\n  mutate(f = f(x1, x2)) |&gt;\n  mutate(y = f + rnorm(n, 0, 0.1))\nmod_1 &lt;- lm(y ~ x1 + x2, data = dat_ent)\nmod_1\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = dat_ent)\n\nCoefficients:\n(Intercept)           x1           x2  \n     1.8936       0.2046       0.2097  \n\n\nEl resultado del modelo lineal no es bueno:\n\ntibble(y_hat = fitted(mod_1), y = dat_ent$y) |&gt; \n  ggplot(aes(x = y_hat, y = y)) + geom_point(color = \"red\") +\n  geom_abline() +\n  coord_obs_pred()\n\n\n\n\nSin embargo, agregando una interacción lo mejoramos considerablemente (examina la raíz del error cuadrático medio, por ejemplo):\n\nmod_2 &lt;- lm(y ~ x1 + x2 + x1:x2, data = dat_ent)\nmod_2\n\n\nCall:\nlm(formula = y ~ x1 + x2 + x1:x2, data = dat_ent)\n\nCoefficients:\n(Intercept)           x1           x2        x1:x2  \n      4.499       -4.895       -4.885        9.964  \n\ntibble(y_hat = fitted(mod_2), y = dat_ent$y) |&gt; \n  ggplot(aes(x = y_hat, y = y)) + geom_point(color = \"red\") +\n  geom_abline() +\n  coord_obs_pred()\n\n\n\n\nObservese la gran diferencia de error entre los dos modelos (en este caso, el sobreajuste no es un problema).\nAhora consideramos qué red neuronal puede ser apropiada.\n\ntensorflow::set_random_seed(421) \nmod_inter &lt;- keras_model_sequential()\nmod_inter |&gt; \n  layer_dense(units = 4, activation = \"sigmoid\",\n              name = \"capa_intermedia\", input_shape = c(2)) |&gt;\n  layer_dense(units = 1, name = \"capa_final\",\n              activation = \"linear\") \n\n\nmod_inter |&gt; compile(loss = \"mse\", \n  optimizer = optimizer_sgd(learning_rate = 0.3, momentum = 0.5))\nhistoria &lt;- mod_inter |&gt; \n  fit(dat_ent |&gt; select(x1, x2) |&gt; as.matrix(), dat_ent$y,\n      batch_size = 20,\n      epochs = 100, verbose = 0)\n\nVerificamos que esta red captura la interacción:\n\npreds &lt;- predict(mod_inter,\n  dat |&gt; select(x1, x2) |&gt; as.matrix())\ndat &lt;- dat |&gt; mutate(f_red = preds)\nggplot(dat, aes(x = x1, y = x2)) + \n  geom_tile(aes(fill = f_red))\n\n\n\n\n\npreds_ent &lt;- predict(mod_inter, dat_ent |&gt; select(x1, x2) |&gt; as.matrix())\ntibble(pred = preds_ent[,1], f = dat_ent$y) |&gt; \n  ggplot(aes(x = pred, y = f)) +\n  geom_point() +\n  geom_abline(colour = \"red\") +\n  coord_obs_pred()\n\n\n\n\nAunque podemos extraer los cálculos de la red ajustada, vamos a hacer el cálculo de la red a mano. La función feed forward es:\n\nbeta &lt;- get_weights(mod_inter)\nfeed_fow &lt;- function(beta, x){\n  a &lt;- h(t(beta[[1]]) %*% x + as.matrix(beta[[2]], 2, 1)) \n  f &lt;- t(beta[[3]]) %*% a + as.matrix(beta[[4]], 1, 1)\n  f\n}\n\nObservación: ¿cómo funciona esta red? Consideremos la capa intermedia (3 unidades) para cuatro casos: \\((0,0), (0,1), (1,0), (1,1)\\):\n\nmat_entrada &lt;- tibble(x_1 = c(0,0,1,1), x_2 = c(0,1,0,1)) |&gt; as.matrix()\ncapa_1 &lt;- keras_model(inputs = mod_inter$input,\n    outputs = get_layer(mod_inter, \"capa_intermedia\")$output)\npred_mat &lt;- predict(capa_1, mat_entrada) |&gt; round(2)\nrownames(pred_mat) &lt;- c(\"apagadas\", \"segunda\", \"primera\", \"ambas\")\npred_mat\n\n         [,1] [,2] [,3] [,4]\napagadas 0.15 0.00 0.64 0.12\nsegunda  0.59 0.05 0.09 0.01\nprimera  0.01 0.05 0.07 0.60\nambas    0.05 0.56 0.00 0.06\n\n\nLos pesos de la última capa son:\n\nbeta[3:4]\n\n[[1]]\n          [,1]\n[1,] -5.422091\n[2,]  4.781280\n[3,]  5.289693\n[4,] -5.083941\n\n[[2]]\n[1] 2.370601\n\n\nEjercicio: interpreta la red en términos de qué unidades están encendidas (valor cercano a 1) o apagadas (valor cercano a 0). ¿Puedes ajustar este modelo con dos tres unidades intermedias? Haz varias pruebas: ¿qué dificultades encuentras?"
  },
  {
    "objectID": "06-redes-neuronales-1.html#cálculo-en-redes-feed-forward",
    "href": "06-redes-neuronales-1.html#cálculo-en-redes-feed-forward",
    "title": "6  Redes neuronales (intro)",
    "section": "6.3 Cálculo en redes: feed-forward",
    "text": "6.3 Cálculo en redes: feed-forward\nAhora generalizamos lo que vimos arriba para definir la arquitectura básica de redes neuronales y cómo se hacen cálculos en las redes.\n\n\n\n\n\n\nTip\n\n\n\nA las variables originales les llamamos capa de entrada de la red, y a la variable de salida capa de salida. Puede haber más de una capa intermedia. A estas les llamamos capas ocultas.\nCuando todas las conexiones posibles de cada capa a la siguiente están presente, decimos que la red es completamente conexa.\n\n\n\n\n\n\n\nComo vimos en el ejemplo de arriba, para hacer cálculos en la red empezamos con la primera capa, hacemos combinaciones lineales y aplicamos nuestra función no lineal \\(h\\). Una vez que calculamos la segunda capa, podemos calcular la siguiente de la misma forma: combinaciones lineales y aplicación de \\(h\\). Y así sucesivamente hasta que llegamos a la capa final."
  },
  {
    "objectID": "06-redes-neuronales-1.html#notación",
    "href": "06-redes-neuronales-1.html#notación",
    "title": "6  Redes neuronales (intro)",
    "section": "6.4 Notación",
    "text": "6.4 Notación\nSea \\(L\\) el número total de capas. En primer lugar, para un cierto caso de entrada \\(x = (x_1,x_2,\\ldots, x_p)\\), denotamos por:\n\n\\(a^{(l)}_j\\) el valor que toma la unidad \\(j\\) de la capa \\(l\\), para \\(j=0,1,\\ldots, n_{l}\\), donde \\(n_l\\) es el número de unidades de la capa \\(l\\).\nPonemos \\(a^{(l)}_0=1\\) para lidiar con los sesgos.\n*En particular, ponemos \\(a^{(1)}_j = x_j\\), que son los valores de las entradas (primera capa)\nPara un problema de regresión, la última capa solo tiene un elemento, que es \\(y = a^{(L)}\\).\n\nAdicionalmente, escribimos\n\\(\\theta_{i,k}^{(l)}=\\) es el peso de entrada \\(a_{k}^{(l-1)}\\) de capa \\(l-1\\) en la entrada \\(a_{i}^{(l)}\\) de la capa \\(l\\).\nLos sesgos están dados por \\[\\theta_{i,0}^{(l)}\\]\n\nEjemplo\nEn nuestro ejemplo, tenemos que en la capa \\(l=3\\) hay dos unidades. Así que podemos calcular los valores \\(a^{(3)}_1\\) y \\(a^{(3)}_2\\). Están dados por\n\\[a_1^{(3)} = h(\\theta_{1,0}^{(2)} + \\theta_{1,1}^{(2)} a_1^{(2)}+ \\theta_{1,2}^{(2)}a_2^{(2)}+ \\theta_{1,3}^{(2)} a_3^{(2)})\\] \\[a_2^{(3)} = h(\\theta_{2,0}^{(2)} + \\theta_{2,1}^{(2)} a_1^{(2)}+ \\theta_{2,2}^{(2)}a_2^{(2)}+ \\theta_{2,3}^{(2)} a_3^{(2)})\\]\nComo se ilustra en la siguiente gráfica:\n\n\n\n\n\nPara visualizar las ordenadas (que también se llaman sesgos en este contexto), ponemos \\(a_{0}^{(2)}=1\\).\n\n\n\n\n\n\n\nEjemplo\nConsideremos propagar a la capa 3 a partir de la capa 2. Usaremos los siguientes pesos para capa 3 y valores de la capa 2 (en gris están los sesgos):\n\n\n\n\n\nQue en nuestra notación escribimos como \\[a^{(2)}_0 = 1, a^{(2)}_1 = -2, a^{(2)}_2 = 5, a^{(2)}=3\\] y los pesos son, para la primera unidad: \\[\\theta^{(2)}_{1,0} = 3,  \\,\\,\\, \\theta^{(2)}_{1,1} = 1.5,\\,\\,\\,\\theta^{(2)}_{1,2} = -1,\\,\\,\\theta^{(2)}_{1,3} = -0.5 \\] y para la segunda unidad \\[\\theta^{(2)}_{2,0} = 1,  \\,\\,\\, \\theta^{(2)}_{2,1} = 2,\\,\\,\\,\\theta^{(2)}_{2,2} = 0.5,\\,\\, \\theta^{(2)}_{2,3} = -0.2\\] Y ahora queremos calcular los valores que toman las unidades de la capa 3, que son \\(a^{(3)}_1\\) y \\(a^{(3)}_2\\)$\nPara hacer feed forward a la siguiente capa, hacemos entonces\n\\[a^{(3)}_1 = h(3 + a^{(2)}_1 - a^{(2)}_2 -0.5 a_3^{(2)}),\\] \\[a^{(3)}_2 = h(1 + 2a^{(2)}_1 + 0.5a^{(2)}_2 - 0.2 a_3^{(2)}),\\]\nPonemos los pesos y valores de la capa 2 (incluyendo sesgo):\n\na_2 &lt;- c(1, -2, 5, 3) # ponemos un 1 al principio para el sesgo\ntheta_2_1 = c(3, 1.5, -1.0, -0.5)\ntheta_2_2 = c(1, 2, 0.5, -0.2)\n\ny calculamos\n\na_3 &lt;- c(1, h(sum(theta_2_1*a_2)),h(sum(theta_2_2*a_2))) # ponemos un 1 al principio\na_3\n\n[1] 1.000000000 0.001501182 0.249739894"
  },
  {
    "objectID": "06-redes-neuronales-1.html#algoritmo-de-feed-forward",
    "href": "06-redes-neuronales-1.html#algoritmo-de-feed-forward",
    "title": "6  Redes neuronales (intro)",
    "section": "6.5 Algoritmo de Feed forward",
    "text": "6.5 Algoritmo de Feed forward\nPara calcular los valores de salida de una red a partir de pesos y datos de entrada, usamos el algoritmo feed-forward, calculando capa por capa.\n\n\n\n\n\n\nFeed-forward\n\n\n\nPara la primera capa, escribimos las variables de entrada: \\[a^{(1)}_j = x_j, j=1\\ldots,n_1\\] Para la primera capa oculta, o la segunda capa \\[a^{(2)}_j = h\\left( \\theta_{j,0}^{(1)}+ \\sum_{k=1}^{n_1}  \\theta_{j,k}^{(1)}  a^{(1)}_k    \\right), j=1\\ldots,n_2\\] para la \\(l\\)-ésima capa: \\[a^{(l)}_j = h\\left( \\theta_{j,0}^{(l-1)}+ \\sum_{k=1}^{n_{l-1}}  \\theta_{j,k}^{(l-1)}  a^{(l-1)}_k    \\right), j=1\\ldots,n_{l}\\] y así sucesivamente. Para la capa final o de salida en un problema de regresión, suponiendo que tenemos \\(L\\) capas (\\(L-2\\) capas ocultas): \\[f(x) =     \\theta_{1,0}^{(L-1)}+ \\sum_{k=1}^{n_{L-1}}  \\theta_{1,k}^{(L-1)}  a^{(L-1)}_k     .\\]\n\n\nNótese que entonces:\n\n\n\n\n\n\nTip\n\n\n\nCada capa se caracteriza por el conjunto de parámetros \\(\\Theta^{(l)}\\), que es una matriz de \\(n_l\\times n_{l-1}\\).\nLa red completa entonces se caracteriza por:\n\nLa estructura elegida (número de capas ocultas y número de nodos en cada capa oculta).\nLas matrices de pesos en cada capa \\(\\Theta^{(1)},\\Theta^{(2)},\\ldots, \\Theta^{(L-1)}\\)\n\n\n\nAdicionalmente, escribimos en forma vectorial: \\[a^{(l)} = (a^{(l)}_0, a^{(l)}_1, a^{(l)}_2, \\ldots, a^{(l)}_{n_l})^t\\]\nPara calcular la salidas, igual que hicimos, antes, propagaremos hacia adelante los valores de las variables de entrada usando los pesos. Agregando entradas adicionales en cada capa \\(a_0^{(l)}\\), \\(l=1,2,\\ldots, L-1\\), donde \\(a_0^{l}=1\\), y agregando a \\(\\Theta^{(l)}\\) una columna con las ordenadas al origen (o sesgos) podemos escribir:\n\n\n\n\n\n\nFeed-forward matricial\n\n\n\n\nCapa 1 (vector de entradas) \\[ a^{(1)} = x\\]\nCapa 2 \\[ a^{(2)} = h(\\Theta^{(1)}a^{(1)})\\]\nCapa \\(l\\) (oculta) \\[ a^{(l)} = h(\\Theta^{(l-1)}a^{(l-1)})\\] donde \\(h\\) se aplica componente a componente sobre los vectores correspondientes.\nCapa de salida:\n\nEn un problema de regresión, la capa de salida se calcula como un regresión lineal: \\[a^{(L)}= f(x) = \\Theta^{(L-1)}a^{(L-1)}\\] Nótese que feed-foward consiste principalmente de multiplicaciones de matrices con algunas aplicaciones de \\(h\\)"
  },
  {
    "objectID": "06-redes-neuronales-1.html#algoritmo-de-backpropagation-cálculo-del-gradiente-regresión",
    "href": "06-redes-neuronales-1.html#algoritmo-de-backpropagation-cálculo-del-gradiente-regresión",
    "title": "6  Redes neuronales (intro)",
    "section": "6.6 Algoritmo de Backpropagation: cálculo del gradiente (regresión)",
    "text": "6.6 Algoritmo de Backpropagation: cálculo del gradiente (regresión)\nPara ajustar los pesos y sesgos de las redes (valores \\(\\theta\\)), utilizaremos descenso en gradiente y otros algoritmos derivados del gradiente (descenso estocástico). En esta parte entonces veremos cómo calcular estos gradientes con el algoritmo de back-propagation, que es una aplicación de la regla de la cadena para derivar. Back-propagation resulta en una fórmula recursiva donde propagamos errores de la red como gradientes desde el final de red (capa de salida) hasta el principio, capa por capa.\nConsideramos el problema de regresión\nRecordamos que la pérdida cuadrática (con regularización ridge, dividiendo entre 2 por conveniencia) es\n\\[D = -\\frac{1}{2n}\\sum_{i=1}^n (y^{(i)} - f(x^{(i)}))^2  + \\lambda \\sum_{l=2}^{L} \\sum_{k=1}^{n_{l-1}} \\sum_{j=1}^{n_l}(\\theta_{j,k}^{(l)})^2.\\]\nQueremos entonces calcular las derivadas de la devianza o función de pérdida con respecto a cada parámetro \\(\\theta_{j,k}^{(l)}\\). Esto nos proporciona el gradiente para nuestro algoritmo de descenso.\nConsideramos aquí el problema de regresión con pérdida cuadrática y sin regularización. La parte de la parcial que corresponde al término de regularización es fácil de agregar al final.\nRecordamos también nuestra notación para la función logística (o sigmoide):\n\\[h(z)=\\frac{1}{1+e^{-z}}.\\] Necesitaremos su derivada, que está dada por (cálculala): \\[h'(z) = h(z)(1-h(z))\\]\n\nCálculo para un caso de entrenamiento\nPrimero simplificamos el problema y consideramos calcular las parciales para un solo caso de entrenamiento \\((x,y)\\): \\[ D=  \\frac{1}{2}\\left ( y -f(x)\\right)^2 . \\]\nDespués sumaremos sobre toda la muestra de entrenamiento. Entonces queremos calcular \\[\\frac{\\partial D}{\\partial \\theta_{j,k}^{(l)}}\\]\nY escribiremos, con la notación de arriba, \\[a^{(l+1)}_j = h(z^{(l+1)}_j)\\] donde \\[z^{(l+1)} = \\Theta^{(l)} a^{(l)},\\] que coordenada a coordenada se escribe como \\[z^{(l+1)}_j =  \\sum_{k=0}^{n_{l}}  \\theta_{j,k}^{(l)}  a^{(l)}_k\\]\n\nPaso 1: Derivar respecto a capa \\(l+1\\)\nComo los valores de cada capa determinan los valores de salida y la devianza, podemos escribir (recordemos que \\(a_0^{(l)}=1\\) es constante): \\[D=D(a_0^{(l+1)},a_1^{(l+1)},a_2^{(l+1)},\\ldots, a_{n_{l+1}}^{(l+1)})=D(a_1^{(l+1)},a_2^{(l+1)},\\ldots, a_{n_{l+1}}^{(l+1)})\\]\nAsí que por la regla de la cadena para varias variables: \\[\\frac{\\partial D}{\\partial \\theta_{j,k}^{(l)}} =\n\\sum_{t=1}^{n_{l}} \\frac{\\partial D}{\\partial a_t^{(l+1)}}\\frac{\\partial a_t^{(l+1)}}\n{\\partial \\theta_{j,k}^{(l)} }\\]\nPero si vemos dónde aparece \\(\\theta_{j,k}^{(l)}\\) en la gráfica de la red:\n\\[ \\cdots a^{(l)}_k \\xrightarrow{\\theta_{j,k}^{(l)}} a^{(l+1)}_j  \\cdots \\rightarrow  D\\] Entonces podemos concluir que \\(\\frac{\\partial a_t^{(l+1)}}{\\partial \\theta_{j,k}^{(l)}} =0\\) cuando \\(t\\neq j\\) (pues no dependen de \\(\\theta_{j,k}^{(l)}\\)),\ny entonces, para toda \\(j=1,2,\\ldots, n_{l+1}, k=0,1,\\ldots, n_{l}\\) \\[\n\\frac{\\partial D}{\\partial \\theta_{j,k}^{(l)}} =\n\\frac{\\partial D}{\\partial a_j^{(l+1)}}\\frac{\\partial a_j^{(l+1)}}{\\partial \\theta_{j,k}^{(l)} }.\n\\tag{6.1}\\]\nAdicionalmente, como \\[a_j^{(l+1)} = h(z_j^{(l+1)}) = h\\left (\\sum_{k=0}^{n_{l}}  \\theta_{j,k}^{(l)}  a^{(l)}_k \\right )\\] y las \\(a_k^{(l)}\\) no dependen de \\(\\theta_{j,k}^{(l)}\\), tenemos por la regla de la cadena que\n\\[\n\\frac{\\partial a_j^{(l+1)}}{\\partial \\theta_{j,k}^{(l)} } = h'(z_j^{(l+1)})a_k^{(l)}.\n\\]\nEsta última expresión podemos calcularla pues sólo requiere la derivada de \\(h\\) y los valores otenidos en el paso de feed-forward.\n\n\nPaso 2: Obtener fórmula recursiva\nAsí que sólo nos queda calcular las parciales (\\(j = 1,\\ldots, n_l\\)) \\[\\frac{\\partial D}{\\partial a_j^{(l)}}\\]\nPara obtener una fórmula recursiva para esta cantidad (hacia atrás), aplicamos otra vez regla de la cadena, pero con respecto a la capa \\(l\\) (ojo: queremos obtener una fórmula recursiva!):\n\\[\\frac{\\partial D}{\\partial a_j^{(l)}}= \\sum_{s=1}^{n_{l+1}}\n\\frac{\\partial D}{\\partial a_s^{(l+1)}}\\frac{\\partial  a_s^{(l+1)}}{\\partial a_j^{(l)}},\\]\nque se puede entender a partir de este diagrama:\n\n\n\n\n\nNótese que la suma empieza en \\(s=1\\), no en \\(s=0\\), pues \\(a_0^{(l+1)}\\) no depende de \\(a_k^{(l)}\\).\nEn este caso los elementos de la suma no se anulan necesariamente. Primero consideramos la derivada de:\n\\[\\frac{\\partial  a_s^{(l+1)}}{\\partial a_j^{(l)}}=h'(z_s^{(l+1)})\\theta_{s,j}^{(l)},\\]\nde modo que\n\\[\\frac{\\partial D}{\\partial a_j^{(l)}}= \\sum_{s=1}^{n_l}\n\\frac{\\partial D}{\\partial a_s^{(l+1)}} h'(z_s^{(l+1)})\\theta_{s,j}^{(l)}.\\]\nNótese que esto nos da una fórmula recursiva para las parciales que nos falta calcular (de \\(D\\) con respecto a \\(a\\)), pues las otras cantidades las conocemos por backpropagation.\n\n\nPaso 3: Simplificación de la recursión\nDefinimos para \\(l=1,\\ldots,L-2\\):\n\\[\n\\delta_s^{ (l+1)}=\\frac{\\partial D}{\\partial a_s^{(l+1)}} h'(z_s^{(l+1)})\n\\tag{6.2}\\]\nde manera que la ecuación recursiva es\n\\[\n\\frac{\\partial D}{\\partial a_j^{(l)}} = \\sum_{s=1}^{n_{l+1}}\n\\delta_s^{(l+1)}\\theta_{s,j}^{(l)}.\n\\tag{6.3}\\]\nTenemos que si \\(l=2,\\ldots,L-1\\), entonces podemos escribir (usando (Ecuación 6.3)) como fórmula recursiva:\n\\[\n\\delta_j^{(l)}\n= \\left (\\sum_{s=1}^{n_l} \\delta_s^{(l+1)} \\theta_{s,j}^{(l)}\\right ) h'(z_j^{(l)}),\n\\tag{6.4}\\] para \\(j=1,2,\\ldots, n_{l}\\).\n\n\nPaso 4: Condiciones iniciales\nPara la última capa, tenemos que (en la ecuación de arriba, en este caso la activación \\(h\\) es \\(h(z)=z\\) para la última capa):\n\\[\\delta_1^{(L)}=-(y - f(x)).\\]\nNótese que esta cantidad indica hacia dónde tenemos que mover \\(f(x)\\) para hacer el error más chico.\n\n\nPaso 5: Cálculo de parciales\nFinalmente, usando (Ecuación 6.1) y (Ecuación 6.2) , obtenemos \\[\\frac{\\partial D}{\\partial \\theta_{j,k}^{(l)}} = \\delta_j^{(l+1)}a_k^{(l)},\\]\ny con esto ya podemos hacer backpropagation para calcular el gradiente sobre cada caso de entrenamiento, y solo resta acumular para obtener el gradiente sobre la muestra de entrenamiento.\nMuchas veces es útil escribir una versión vectorizada (importante para implementar):\n\n\nPaso 6: Versión matricial\nAhora podemos escribir estas ecuaciones en forma vectorial. En primer lugar, \\[\\delta^{(L)}=f(x)-y.\\] Y además se puede ver de la ecuación (Ecuación 6.4) que (\\(\\Theta_{*}^{(l+1)}\\) denota la matriz de pesos sin la columna correspondiente al sesgo):\n\\[\n\\delta^{(l)}=\\left( \\Theta_{*}^{(l)}    \\right)^t\\delta^{(l+1)} \\circ h'(z^{(l)})\n\\tag{6.5}\\]\ndonde \\(\\circ\\) denota el producto componente a componente.\nAhora todo ya está calculado. Lo interesante es que las \\(\\delta^{(l)}\\) se calculan de manera recursiva.\n\n\n\nAlgoritmo de backpropagation\n\n\n\n\n\n\nNota\n\n\n\n#Backpropagation\nPara problema de clasificación con regularización $ $. Para \\(i=1,\\ldots, N,\\) tomamos el dato de entrenamiento \\((x^{(i)}, y^{(i)})\\) y hacemos:\n\nPonemos \\(a^{(1)}=x^{(i)}\\) (vector de entradas, incluyendo 1).\nCalculamos \\(a^{(2)},a^{(3)},\\ldots, a^{(L)}\\) usando feed forward para la entrada \\(x^{(i)}.\\)\nCalculamos \\(\\delta^{(L)}=a^{(L)}-y^{(i)}\\), y luego \\(\\delta^{(L-1)},\\ldots, \\delta^{(2)}\\) según la recursión (Ecuación 6.4).\nAcumulamos \\(\\Delta_{j,k}^{(l)}=\\Delta_{j,k}^{(l)} + \\delta_j^{(l+1)}a_k^{(l)}\\).\nFinalmente, ponemos, si \\(k\\neq 0\\), \\[D_{j,k}^{(l)} = \\frac{2}{N}\\Delta_{j,k}^{(l)} + 2\\lambda\\theta_{j,k}^{(l)}\\] y si \\(k=0\\), \\[D_{j,k}^{(l)} = \\frac{2}{N}\\Delta_{j,k}^{(l)} .\\] Entonces: \\[D_{j,k}^{(l)} =\\frac{\\partial D}{\\partial \\theta_{j,k}^{(l)}}.\\]\n\nNótese que back-propagation consiste principalmente de multiplicaciones de matrices con algunas aplicaciones de \\(h\\) y acumulaciones, igual que feed-forward."
  },
  {
    "objectID": "06-redes-neuronales-1.html#ajuste-de-parámetros-introducción",
    "href": "06-redes-neuronales-1.html#ajuste-de-parámetros-introducción",
    "title": "6  Redes neuronales (intro)",
    "section": "6.7 Ajuste de parámetros (introducción)",
    "text": "6.7 Ajuste de parámetros (introducción)\nConsideramos la versión con regularización ridge (también llamada L2) de la devianza de entrenamiento como nuestro función objetivo:\n\n\n\n\n\n\nAjuste de redes neuronales\n\n\n\nPara un problema de regresión, ajustamos los pesos \\(\\Theta^{(1)},\\Theta^{(2)},\\ldots, \\Theta^{(L)}\\) de la red intentando minimizar el error cuadrático medio (penalizado) sobre la muestra de entrenamiento: \\[D = -\\frac{1}{2n}\\sum_{i=1}^n (y^{(i)} - f(x^{i}))^2= + \\lambda \\sum_{l=2}^{L} \\sum_{k=1}^{n_{l-1}} \\sum_{j=1}^{n_l}(\\theta_{j,k}^{(l)})^2.\\] Este problema en general no es convexo y puede tener múltiples mínimos.\n\n\nVeremos el proceso de ajuste, selección de arquitectura, etc. más adelante. Por el momento hacemos unas observaciones acerca de este problema de minimización:\n\nHay varios algoritmos para minimizar este error, algunos avanzados incluyendo información de segundo orden (como Newton), pero actualmente las técnicas más populares, para redes grandes, están derivadas de descenso en gradiente. Más específicamente, una variación, que es descenso estocástico.\nQue el algoritmo depende principalmente de multiplicaciones de matrices y acumulaciones implica que puede escalarse de diversas maneras. Una es paralelizando sobre la muestra de entrenamiento (y calcular acumulados al final), pero también se pueden paralelizar las multiplicaciones de matrices (para lo cual los GPUs se prestan muy bien).\nPara redes neuronales, el gradiente se calcula con un algoritmo que se llama back-propagation, que es una aplicación de la regla de la cadena para propagar errores desde la capa de salida a lo largo de todas las capas para ajustar los pesos y sesgos.\nEn estos problemas no buscamos el mínimo global, sino un mínimo local de buen desempeño. Puede haber múltiples mínimos, puntos silla, regiones relativamente planas, precipicios (curvatura alta). Nótese que la simetría implica que podemos obtener la misma red cambiando pesos entre neuronas y las conexiones correspondientes. Esto implica que necesariamente hay varios mínimos.\nTodo esto dificulta el entrenamiento de redes neuronales grandes. Para redes grandes, ni siquiera esperamos a alcanzar un mínimo local, sino que nos a veces detenemos prematuramente cuando obtenemos el mejor desempeño posible.\nPara este problema, no tiene sentido comenzar las iteraciones con todos los pesos igual a cero, pues las unidades de la red son simétricas: no hay nada que distinga una de otra si todos los pesos son iguales. Esto quiere decir que si iteramos, todas las neuronas van a aprender lo mismo.\nEs importante no comenzar valores de los pesos grandes, pues las funciones logísticas pueden quedar en regiones planas donde la minimización es lenta, o podemos tener gradientes demasiado grandes y produzcan inestabilidad en el cálculo del gradiente.\nEl ajuste de la tasa de aprendizaje es un parámetro importante, más delicado que para problemas convexos. Generalmente lo tratamos con un hiperparámetro más que hay que afinar. Tasas demasiado grandes pueden llevarnos a mínimos locales relativamente malos.\nGeneralmente los pesos se inicializan al azar con variables independientes gaussianas o uniformes centradas en cero, y con varianza chica (por ejemplo \\(U(-0.5,0.5)\\)). Una recomendación es usar \\(U(-1/\\sqrt{m}, 1/\\sqrt{m})\\) donde \\(m\\) es el número de entradas. En general, hay que experimentar con este parámetro.\n\nEl proceso para ajustar una red es entonces:\n\nDefinir número de capas ocultas, número de neuronas por cada capa, y un valor del parámetro de regularización. Estandarizar las entradas. Usualmente podemos probar comenzar con una o dos capas ocultas, de tamaño proporcional al número de entradas. Es buena idea comenzar con una red relativamente grande que tienen error bajo de entrenamiento aunque sobreajuste, y después regularizar y refinar su tamaño.\nSeleccionar parámetros al azar para \\(\\Theta^{(2)},\\Theta^{(3)},\\ldots, \\Theta^{(L)}\\). Se toman, por ejemplo, normales con media 0 y varianza chica.\nCorrer un algoritmo de minimización del error mostrada arriba. Es necesario experimentar con los parámetros del algoritmo de minimización.\nVerificar convergencia del algoritmo a un mínimo local (o el algoritmo no está mejorando).\nPredecir usando el modelo ajustado.\n\nFinalmente, podemos probar distintas arquitecturas y valores del parámetros de regularización, para afinar estos parámetros según validación cruzada o una muestra de validación.\n\nEjemplo (regresión)\n\ndat_grasa &lt;- read_csv(file = '../datos/bodyfat.csv') \nset.seed(183)\ngrasa_particion &lt;- initial_split(dat_grasa, 0.5)\ngrasa_ent &lt;- training(grasa_particion)\ngrasa_pr &lt;- testing(grasa_particion)\nnrow(grasa_ent)\n\n[1] 126\n\n\nUna exploración de este conjunto de datos revela algunos datos sospechosos. En particular un individuo con estatura de 30 pulgadas (alrededor de 75 cm), con peso normal. Probablemente no queremos incluir en entrenamiento este caso, y tampoco hacer predicciones para posibles personas que tengan tales dimensiones:\n\nlibrary(patchwork)\ng_1 &lt;- grasa_ent |&gt; ggplot(aes(x = estatura, y = peso)) + \n  geom_point()\ng_2 &lt;- grasa_ent |&gt; ggplot(aes(x = abdomen, y = peso)) + \n  geom_point()\ng_1 + g_2\n\n\n\n\n\ngrasa_receta &lt;- recipe(grasacorp ~ ., grasa_ent) |&gt; \n  step_filter(estatura &gt; 50) |&gt;\n  step_normalize(all_predictors()) |&gt; \n  prep()\n\n\nlibrary(keras)\n# entrenamiento\nx_grasa &lt;- grasa_receta |&gt; juice() |&gt; \n  select(-grasacorp) |&gt; as.matrix()\nvars_nombres &lt;- colnames(x_grasa)\ny_grasa &lt;- grasa_receta |&gt; juice() |&gt; pull(grasacorp)\n# validación\nx_grasa_pr &lt;- grasa_receta |&gt; bake(grasa_pr) |&gt; \n  select(-grasacorp) |&gt; as.matrix()\ny_grasa_pr &lt;- grasa_receta |&gt; bake(grasa_pr) |&gt; pull(grasacorp)\n\n\nmodelo_red &lt;- keras_model_sequential() |&gt; \n  layer_dense(units = 50, activation = \"sigmoid\") |&gt; \n  layer_dense(units = 50, activation = \"sigmoid\") |&gt; \n  layer_dense(units = 1, activation = \"linear\")\nmodelo_red |&gt; compile(\n  loss = \"mse\", metrics = \"mse\",\n  optimizer = optimizer_sgd(learning_rate = 0.01, momentum = 0.9)\n)\n# esto es más eficiente hacerlo con callbacks en general:\nhistoria &lt;- modelo_red |&gt; fit(\n  x = x_grasa, y = y_grasa,\n  validation_data = list(x_grasa_pr, y_grasa_pr),\n  batch_size = 30, epochs = 250, verbose = 1)\n\nVemos que con esta red podemos alcanzar un error de entrenamiento cercano a cero, aún cuando vemos que sobreajusta al evaluar con la muestra de validación.\n\nplot(historia, smooth = FALSE)\n\n\n\n\nNotamos que las predicciones no son muy buenas:\n\npreds &lt;- predict(modelo_red, x_grasa_pr) \npreds |&gt; head()\n\n          [,1]\n[1,]  9.117618\n[2,] 22.663441\n[3,]  8.569652\n[4,]  8.558598\n[5,]  8.842549\n[6,]  8.559493\n\n\nY obtenemos el siguiente resultado:\n\ng_1 &lt;- tibble(preds = preds[, 1], y = y_grasa_pr) |&gt; \n  ggplot(aes(x = preds, y = y)) + \n  geom_point() + \n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  coord_obs_pred()\ng_1\n\n\n\n\nPodemos ahora experimentar con los parámetros del optimizador, número de unidades, número de capas y regularización L2.\n\nCada cambio de número de unidades/capas o regularización requiere ajustes a la tasa de aprendizaje y otros parámetros del optimizador.\nVarias arquitecturas (número de capas y unidades) pueden dar resultados similares. En este caso, usualmente escogemos el modelo más computacionalmente simple, o dependiendo del tipo de errores de cada modelo.\nRecordamos que una consecuencia del sobreajuste es que el error de prueba es mayor que el de entrenamiento (hay un gap de generalización). Para mejorar el desempeño, podemos reducir el error de entrenamiento (reducir sesgo), y/o reducir sobreajuste (gap entre entrenamiento y prueba).\n\n\nmodelo_red_2 &lt;- keras_model_sequential() |&gt; \n  layer_dense(units = 30, activation = \"sigmoid\", \n              kernel_regularizer = regularizer_l2(0.1)) |&gt; \n  layer_dense(units = 30, activation = \"sigmoid\",\n              kernel_regularizer = regularizer_l2(0.1)) |&gt; \n  layer_dense(units = 1, activation = \"linear\", \n              kernel_regularizer = regularizer_l2(0.01))\nmodelo_red_2 |&gt; compile(loss = \"mse\",metrics = c(\"mse\"),\n  optimizer = optimizer_sgd(learning_rate = 0.0005, momentum = 0.95)\n)\n# esto es más eficiente hacerlo con callbacks en general:\nhistoria &lt;- modelo_red_2 |&gt; fit(\n  x = x_grasa, y = y_grasa,\n  validation_data = list(x_grasa_pr, y_grasa_pr),\n  batch_size = 30, epochs = 500, verbose = 1)\n\n\nplot(historia, smooth = FALSE)\n\n\n\n\nLa afinación nos da mejores resultados:\n\npreds_2 &lt;- predict(modelo_red_2, x_grasa_pr) \ng_2 &lt;- tibble(preds_2 = preds_2[, 1], y = y_grasa_pr) |&gt; \n  ggplot(aes(x = preds_2, y = y)) + \n  geom_point() + \n  geom_abline(slope = 1, intercept = 0, color = \"red\") +\n  coord_obs_pred()\ng_1 + g_2\n\n\n\n\n\n\nResumen\nEjercicio: En nuestra referencia The Deep Learning Book, puedes revisar la sección 11.4.1 (afinación manual) y 11.4.2 (afinación por búsqueda automática). Explica qué efecto tienen sobre sesgo y sobreajuste los siguientes parámetros:\n\nNúmero de capas\nNúmero de unidades por capa oculta\nRegularización L2 de los pesos\nTasa de aprendizaje (ojo, este parámetro es especial)\n\nEn la parte 2 de redes neuronales veremos más estrategias de regularización, y cómo agregar estructura a redes adaptada a problemas particulares. Notamos para por el momento que las redes neuronales con solamente capas conexas no han sido particularmente exitosas para ningún problema particular. Típicamente requieren una gran cantidad de datos y entrenarlas es más difícil que otros métodos. Sin embargo, la historia es diferente cuando escogemos adecuadamente la arquitectura de la red para un problema dado, es decir, qué unidades están conectadas y bajo qué patrones. En estos casos, las conexiones pueden ser relativamente pocas comparadas con redes totalmente conexas con el mismo tamaño de unidades, y si la estructura es correcta, no incurrimos en mucho sesgo. Ejemplos son procesamiento de imágenes, audio, o lenguaje natural."
  },
  {
    "objectID": "07-intervalos-predictivos.html#inferencia-predictiva-conforme",
    "href": "07-intervalos-predictivos.html#inferencia-predictiva-conforme",
    "title": "7  Incertidumbre en las predicciones",
    "section": "7.1 Inferencia predictiva conforme",
    "text": "7.1 Inferencia predictiva conforme\nTradicionalmente, este tipo de intervalos predictivos se construyen bajo argumentos teóricos en modelos relativamente simples con supuestos fuertes que hay que checar. En aprendizaje de máquina, donde utilizamos predictores mucho más complejos que modelos lineales, en dimensión alta y con mecanismos complejos de limpieza y selección de variables, es muy difícil seguir esta ruta tradicional.\nEn lugar de eso, utilizaremos la idea fundamental de división de muestras (que en este caso a veces les llamamos entrenamiento-calibración) para producir intervalos con cobertura garantizada independientemente de si se cumplen o no ciertos supuestos teóricos. La idea es la siguiente:\n\n\n\n\n\n\nNota\n\n\n\nIntervalos predictivos conformes.\nSuponiendo que los datos se extraen de forma independiente de una misma población,\n\nConstruimos con una muestra de entrenamiento \\((x_i, y_i)\\) nuestro predictor \\(\\hat{f}(x)\\).\nUsamos una muestra de calibración separada para evaluar el error promedio, y adicionalmente, calculamos los residuales \\(\\mathbf{r}_i = |\\mathbf{y}_i - \\hat{f}(\\mathbf{x}_i)|\\)\nSi queremos intervalos del 90%, calculamos ahora \\(q\\), que es el cuantil 90% de los valores \\(\\mathbf{r}_i\\)\nPara un nuevo valor de las entradas \\(\\mathbf{x}\\), nuestro intervalo es \\[[\\hat{f}(\\mathbf{x}) - d, \\hat{f}(\\mathbf{x}) + d]\\]\n\nPara esta nueva observación \\((\\mathbf{x}, \\mathbf{y})\\),\n\\[P(\\mathbf{y} \\in[\\hat{f}(\\mathbf{x}) - d, \\hat{f}(\\mathbf{x}) + d])\\gtrsim 0.90\\]\ndonde la desigualdad quiere decir que la cobertura es al menos de 90%, y muy cercana a 90% si la muestra de prueba cumple \\(n\\geq 100\\).\n\n\nLa demostración es relativamente simple (especialmente el hecho de que la cobertura es mayor o igual a 90%) y no requiere ningún supuesto adicional acerca del predictor o al calidad del ajuste (ver Distribution-Free Predictive Inference for Regression)."
  },
  {
    "objectID": "07-intervalos-predictivos.html#ejemplo-bodyfat",
    "href": "07-intervalos-predictivos.html#ejemplo-bodyfat",
    "title": "7  Incertidumbre en las predicciones",
    "section": "7.2 Ejemplo: bodyfat",
    "text": "7.2 Ejemplo: bodyfat\nEn el ejemplo de grasa corporal utilizamos lasso para seleccionar un modelo. Podemos construir intervalos predictivos (split-conformal) como sigue:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gt)\ndat_grasa &lt;- read_csv(file = '../datos/bodyfat.csv') \n# dividir muestra\nset.seed(183)\ngrasa_particion &lt;- initial_split(dat_grasa, 0.5)\ngrasa_ent &lt;- training(grasa_particion)\ngrasa_cal &lt;- testing(grasa_particion)\n# receta\ngrasa_receta &lt;- recipe(grasacorp ~ ., grasa_ent) \n# lasso\nmodelo_gc &lt;- linear_reg(mixture = 1, penalty = 0.2) |&gt; \n  set_engine(\"glmnet\", lambda.min.ratio = 1e-20) \n# definir flujo y ajustar\nflujo_2 &lt;- workflow() |&gt; \n  add_model(modelo_gc) |&gt; \n  add_recipe(grasa_receta)\n# ajuste\nflujo_2 &lt;- flujo_2 |&gt; fit(grasa_ent)\n\nAhora, sobre la muestra de prueba (calibración) evaluamos el error y calculamos residuales y su distribución:\n\npreds_gc_tbl &lt;- predict(flujo_2, grasa_cal) |&gt; \n  bind_cols(grasa_cal) |&gt; \n  mutate(residual = abs(grasacorp - .pred))\n# obtener cuantil\nq_gc &lt;- quantile(preds_gc_tbl |&gt; pull(residual), \n                 probs = c(0.90))\nggplot(preds_gc_tbl, aes(x = residual)) +\n  geom_histogram(binwidth = 0.75) + \n  geom_vline(xintercept = q_gc, colour = \"red\")\n\n\n\nq_gc |&gt; round(2)\n\n 90% \n7.26 \n\n\nUna gráfica útil es la de predicciones en el eje horizontal contra intervalos y valores observados en el eje \\(y\\):\n\npreds_gc_tbl &lt;- preds_gc_tbl |&gt; \n  mutate(inf = .pred -  q_gc, sup = .pred + q_gc)\nggplot(preds_gc_tbl, aes(x = .pred, ymin = inf, ymax = sup, y = grasacorp)) +\n  geom_abline() +\n  geom_point(colour = \"red\") +\n  geom_linerange(alpha = 0.5) \n\n\n\n\nDonde vemos que la cobertura parece ser similar para todos los rangos de valores de predicción. Podemos hacer también una tabla simple como la que sigue para verificar la cobertura:\n\nn_grupos &lt;- 4 # podemos usar más grupos si tenemos más datos\npreds_gc_tbl |&gt; \n  rename(y = grasacorp) |&gt; \n  mutate(grupo_pred = cut_number(.pred, n = n_grupos)) |&gt; \n  group_by(grupo_pred) |&gt; \n  summarise(n = n(), cobertura = mean(y &gt;= inf & y &lt;= sup)) |&gt;\n  mutate(error_cob = 2 * sqrt(cobertura * (1- cobertura) / n)) |&gt; \n  gt() |&gt; fmt_number(where(is_double), decimals = 2)\n\n\n\n\n\n  \n    \n    \n      grupo_pred\n      n\n      cobertura\n      error_cob\n    \n  \n  \n    [5.27,15.1]\n32\n0.88\n0.12\n    (15.1,18.4]\n31\n0.87\n0.12\n    (18.4,21.9]\n31\n0.97\n0.06\n    (21.9,39.9]\n32\n0.88\n0.12\n  \n  \n  \n\n\n\n\nAdicionalmente, podemos también ver cobertura con respecto a alguna variable de interés, por ejemplo, la medida de abdomen:\nY finalmente, podemos hacer distintas verificaciones para ver cómo se comportan los intervalos:\n\nggplot(preds_gc_tbl, aes(x = edad, ymin = inf, ymax = sup, y = grasacorp)) +\n  geom_linerange(position = position_dodge2(width = 0.5)) +\n  geom_point(colour = \"red\", position = position_dodge2(width = 0.5))"
  },
  {
    "objectID": "07-intervalos-predictivos.html#cobertura-local-para-intervalos-conformes",
    "href": "07-intervalos-predictivos.html#cobertura-local-para-intervalos-conformes",
    "title": "7  Incertidumbre en las predicciones",
    "section": "7.3 Cobertura local para intervalos conformes",
    "text": "7.3 Cobertura local para intervalos conformes\nLa cobertura es confiable y robusta, sin embargo, se requieren algunos elementos adicionales para que los intervalos sean más útiles. Quisiéramos también que la cobertura local alrededor de cualquier región del las \\(x\\)’s sea cercana al 90% (cobertura condicional). Esto es más dificíl de alcanzar. Un chequeo básico que podemos hacer es el siguiente:\n\nPara cada nivel de predicción \\(\\hat{y} = \\hat{f}(x)\\), los intervalos tienen cobertura de 90%. Como esto sólo involucra las predicciones, los valores observados, y los intervalos predictivos, esto puede checarse en la práctica con una tabla o gráfica.\n\nEn problemas de dimensión alta, sin embargo, es difícil checar que la cobertura local se cumple en toda \\(x\\). Podemos, sin embargo, hacer verificaciones de cobertura a lo largo de entradas \\(x_i\\) particulares que sean de particular importancia. Por ejemplo, si \\(x_i\\) indica nivel socioeconómico de un hogar, no quisiéramos introducir artefactos en la decisión debido a que la cobertura es desigual para distintos valores de esta variable de entrada.\nGeneralmente, deficiencias grandes de cobertura local pueden revelarse con alguna de estas verificaciones.\n\n7.3.1 Ejemplo: fallas en cobertura local\nRevisamos nuestro ejemplo de rendimiento de coches:\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gt)\nauto &lt;- read_csv(\"../datos/auto.csv\")\ndatos &lt;- auto[, c('name', 'weight','year', 'mpg', 'displacement')]\ndatos &lt;- datos %&gt;% mutate(\n  peso_kg = weight * 0.45359237,\n  rendimiento_kpl = mpg * (1.609344 / 3.78541178), \n  año = year)\n\nVamos a separa en muestra de entrenamiento y de prueba estos datos. Podemos hacerlo como sigue (75% para entrenamiento aproximadamente en este caso, así obtenemos alrededor de 100 casos para prueba):\n\nset.seed(121)\ndatos_split &lt;- initial_split(datos, prop = 0.3)\ndatos_entrena &lt;- training(datos_split)\ndatos_prueba &lt;- testing(datos_split)\n# preprocesamiento y flujo\nreceta_lineal &lt;- recipe(rendimiento_kpl ~ peso_kg + año, datos_entrena) |&gt; \n  step_ns(peso_kg, deg_free = 3) |&gt; \n  step_ns(año, deg_free = 2)\nmod_lineal &lt;- linear_reg() |&gt;  \n  set_engine(\"lm\")  \nflujo &lt;- workflow() |&gt;  \n  add_recipe(receta_lineal) |&gt; \n  add_model(mod_lineal)\nflujo_ajustado &lt;- fit(flujo, datos_entrena)\n\nUna vez que tenemos el flujo ajustado, podemos ver cómo se comportan los residuales:\n\npreds_tbl &lt;- predict(flujo_ajustado, datos_prueba) |&gt; \n  bind_cols(datos_prueba) |&gt; \n  mutate(r = abs(rendimiento_kpl - .pred))\nggplot(preds_tbl, aes(x = r)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\nq &lt;- quantile(preds_tbl |&gt; pull(r), probs = c(0.90)) |&gt; \n  round(2)\nq\n\n 90% \n1.77 \n\n\nPodemos ahora construir intervalos de 90% para nuestras predicciones de la siguiente forma:\n\npreds_tbl &lt;- preds_tbl |&gt; \n  mutate(inf = .pred - q, \n         sup = .pred + q)\n\nPor definición, estos intervalos tienen cobertura promedio sobre nuevos datos de aproximadamente el 90%. Sin embargo, la cobertura puede nos ser uniforme en distintas regiones de las entradas. Como sugerimos arriba, podemos checar primero la respuesta en función de la predicción:\n\nggplot(preds_tbl, aes(x = .pred, y = rendimiento_kpl, ymin = inf, ymax = sup)) +\n  geom_linerange() +\n  geom_point(colour = \"red\") + coord_obs_pred()\n\n\n\n\nTambién podemos verificar con una tabla que la cobertura no es uniforme:\n\nn_grupos &lt;- 6 # podemos usar más grupos si tenemos más datos\npreds_tbl |&gt; \n  rename(y = rendimiento_kpl) |&gt; \n  mutate(grupo_pred = cut_number(.pred, n = n_grupos)) |&gt; \n  group_by(grupo_pred) |&gt; \n  summarise(n = n(), cobertura = mean(y &gt;= inf & y &lt;= sup)) |&gt;\n  mutate(error_e = 2 * sqrt(cobertura * (1- cobertura) / n)) |&gt; \n  gt() |&gt; fmt_number(where(is_double), decimals = 2)\n\n\n\n\n\n  \n    \n    \n      grupo_pred\n      n\n      cobertura\n      error_e\n    \n  \n  \n    [5.1,6.46]\n46\n1.00\n0.00\n    (6.46,8.08]\n46\n0.98\n0.04\n    (8.08,10.1]\n46\n0.93\n0.07\n    (10.1,11.6]\n45\n0.89\n0.09\n    (11.6,13.6]\n46\n0.78\n0.12\n    (13.6,16.5]\n46\n0.83\n0.11\n  \n  \n  \n\n\n\n\nEstos intervalos son poco útiles porque exageran la incertidumbre para valores altos y la subestiman para valores bajos. Adicionalmente, podemos checar variables que consideramos importantes para ver cómo se comportan los intervalos. En este caso, por ejemplo, usamos la variable peso,\n\nggplot(preds_tbl, aes(x = peso_kg, y =  rendimiento_kpl, ymin = inf, ymax = sup)) +\n  geom_linerange() +\n  geom_point(colour = \"red\") \n\n\n\n\nY vemos que aunque nuestros intervalos son del 90%, tienen baja cobertura para pesos bajos y sobrecubren para pesos altos.\nPodemos mejorar los intervalos usando regresión cuantílica (ver también Conformalized Quantile Regression), donde la respuesta es la variable que queremos predecir y la única entrada es nuestra predicción puntual. Primero necesitamos una muestra adicional de calibración (por ejemplo dividimos la muestra de prueba en una muestra de calibración y otra de evaluación):\n\nlibrary(quantreg)\n\nLoading required package: SparseM\n\n\n\nAttaching package: 'SparseM'\n\n\nThe following object is masked from 'package:base':\n\n    backsolve\n\nlambda &lt;- 1 # suavizamiento splines reg cuantílica\ncalib_eval_split &lt;- initial_split(preds_tbl, 0.5)\ncalibracion_tbl &lt;- training(calib_eval_split)\neval_tbl &lt;- testing(calib_eval_split)\nggplot(calibracion_tbl, aes(x = .pred, y = rendimiento_kpl)) +  \n  geom_point() +\n  geom_quantile(method = \"rqss\", \n    lambda = lambda, quantiles = c(0.05, 0.95))\n\nSmoothing formula not specified. Using: y ~ qss(x, lambda = 1)\n\n\n\n\nsup_qreg &lt;- quantreg::rqss(rendimiento_kpl ~ .pred, \n  lambda = lambda, data = preds_tbl, tau = 0.95)\ninf_qreg &lt;- quantreg::rqss(rendimiento_kpl ~ .pred, \n  lambda = lambda, data = preds_tbl, tau = 0.05)\ncalibracion_tbl &lt;- calibracion_tbl |&gt; \n  mutate(sup_q = predict(sup_qreg, \n            newdata = calibracion_tbl |&gt; select(rendimiento_kpl, .pred)),\n         inf_q = predict(inf_qreg, \n          newdata = calibracion_tbl |&gt; select(rendimiento_kpl, .pred))\n         )\n\nLos nuevos intervalos se ven como sigue, por ejemplo en términos de la variable peso:\n\nggplot(calibracion_tbl, \n  aes(x = peso_kg, y =  rendimiento_kpl, \n      ymin = inf_q, ymax = sup_q)) +\n  geom_linerange() +\n  geom_point(colour = \"red\") \n\n\n\n\nFinalmente verificamos con la muestra de evaluación (en este punto, podemos ajustar la regresión cuantílica si es necesario):\n\neval_tbl &lt;- eval_tbl |&gt; \n  mutate(sup_q = predict(sup_qreg, newdata = eval_tbl),\n         inf_q = predict(inf_qreg, newdata = eval_tbl))\n\n\nn_grupos &lt;- 5 # podemos usar más grupos si tenemos más datos\neval_tbl |&gt; \n  rename(y = rendimiento_kpl) |&gt; \n  mutate(grupo_pred = cut_number(.pred, n = n_grupos)) |&gt; \n  group_by(grupo_pred) |&gt; \n  summarise(n = n(), \n            cobertura = mean(y &gt;= inf_q & y &lt;= sup_q), \n            .pred = mean(.pred)) |&gt;\n  mutate(error_cob = 2 * sqrt(cobertura * (1- cobertura) / n)) |&gt; \n  ggplot(aes(x = .pred, y = cobertura, \n    ymin = cobertura - error_cob, ymax = cobertura + error_cob)) +\n  geom_hline(yintercept = 0.9, colour = \"red\") +\n  geom_point() + geom_linerange() +\n  ylim(c(0,1.1))\n\n\n\n\n\n\n\n\n\n\nProbando intervalos predictivos\n\n\n\n\nChecamos la cobertura uniforme de nuestros intervalos predictivos primero viendo el comportamiento de intervalos dependiendo de la predicción.\nAdicionalmente, podemos también checar intervalos en función de variables importantes para ver si en distintas regiones la cobertura es uniforme.\nCuando detectamos que los intervalos predictivos conformes no tienen niveles de cobertura uniforme sobre el espacio de entradas, podemos usar una muestra de calibración y usar regresión cuantílica tomando como respuesta la variable respuesta y como entrada la predicción puntual de nuestro modelo ajustado."
  },
  {
    "objectID": "07-intervalos-predictivos.html#ejemplo-otras-funciones-de-pérdida",
    "href": "07-intervalos-predictivos.html#ejemplo-otras-funciones-de-pérdida",
    "title": "7  Incertidumbre en las predicciones",
    "section": "7.4 Ejemplo: otras funciones de pérdida",
    "text": "7.4 Ejemplo: otras funciones de pérdida\nEl mismo método puede aplicarse para otras funciones de pérdida más apropiadas para cada problema. Supongamos que en el problema de predicción de precios, nos interesa particularmente la pérdida relativa dada por \\[L(y, \\hat{f}(x)) = \\frac{|y - \\hat{f}(x)|}{\\hat{f}(x)}\\] En este caso, a la pérdida \\(L(y, \\hat{f}(x))\\) a veces se le llama medida de conformidad de las predicciones. Podemos aplicar entonces el mismo procedimiento: 1. Construimos con una muestra de entrenamiento \\((x_i, y_i)\\) nuestro predictor \\(\\hat{f}(x)\\) 2. Usamos una muestra de prueba separada para evaluar el error promedio, y adicionalmente, calculamos los valores \\(\\mathbf{r}_i = L(\\mathbf{y}_i , \\hat{f}(\\mathbf{x}_i))\\) 3. Si queremos intervalos del 90%, calculamos ahora \\(q\\), que es el cuantil 90% de los valores \\(\\mathbf{r}_i\\) 3. Para un nuevo valor de las entradas \\(\\mathbf{x}\\), nuestro intervalo ( o más bien región predictiva) es todos los valores de \\(y\\) que cumplen \\[I(\\mathbf{x}) = \\{y : L(y, \\hat{f}(\\mathbf{x})) \\leq q\\} \\] Y resulta ser que para una nueva observación, \\[P(\\mathbf{y} \\in I(\\mathbf{x}))\\gtrsim 0.90\\] Podemos ver esto con el ejemplo de precios de casas:\n\nsource(\"../R/casas_traducir_geo.R\")\nset.seed(83)\ncasas_split &lt;- initial_split(casas, prop = 0.75)\ncasas_entrena &lt;- training(casas_split)\nreceta_casas &lt;- recipe(precio_miles ~ \n           nombre_zona + \n           area_hab_m2 + area_garage_m2 + area_sotano_m2 + \n           area_2o_piso_m2 +\n           area_lote_m2 + \n           año_construccion + \n           calidad_gral + calidad_garage + calidad_sotano +\n           condicion_gral + \n           num_coches  + \n           aire_acondicionado + condicion_venta, \n           data = casas_entrena) |&gt; \n  step_filter(condicion_venta == \"Normal\") |&gt; \n  step_select(-condicion_venta, skip = TRUE) |&gt; \n  step_mutate(tiene_2o_piso = ifelse(area_2o_piso_m2 == 0, 1, 0)) |&gt; \n  step_mutate(\n    area_sotano_m2 = ifelse(is.na(area_sotano_m2), 0, area_sotano_m2)) |&gt; \n  step_mutate(area_garage_m2 = \n    ifelse(is.na(area_garage_m2), 0, area_garage_m2)) |&gt; \n  step_novel(nombre_zona, calidad_sotano, calidad_garage) |&gt; \n  step_ns(calidad_gral, deg_free = 2) |&gt; \n  step_ns(condicion_gral, deg_free = 2) |&gt; \n  step_ns(starts_with(\"area_lote\"), deg_free = 3) |&gt; \n  step_ns(starts_with(\"año_construccion\"), deg_free = 3) |&gt; \n  step_unknown(calidad_sotano, calidad_garage) |&gt; \n  step_other(nombre_zona, threshold = 0.01, other = \"otras\") |&gt; \n  step_dummy(nombre_zona, calidad_garage, \n             calidad_sotano, aire_acondicionado) |&gt; \n  step_interact(\n    terms = ~ starts_with(\"area_garage_m2\"):starts_with(\"calidad_garage\")) |&gt; \n  step_interact(\n    terms = ~ starts_with(\"area_sotano_m2\"): starts_with(\"calidad_sotano\")) |&gt; \n  step_nzv(all_predictors(), freq_cut = 500 / 1, unique_cut = 1)\n\nUsaremos regresión ridge:\n\nflujo_casas &lt;- workflow() |&gt; \n  add_recipe(receta_casas) |&gt; \n  add_model(linear_reg(mixture = 0, penalty = 0.01) |&gt; \n            set_engine(\"glmnet\", lambda.min.ratio = 1e-20))  \najuste &lt;- fit(flujo_casas, casas_entrena)\n\nPara medir el desempeño convertimos a la variable de precio multiplicando la predicción por el área habitable:\n\nmetricas &lt;- metric_set(mape, mae, rmse, rsq)\ncasas_prueba_normal &lt;- testing(casas_split) |&gt; \n  filter(condicion_venta == \"Normal\")\nmetricas(casas_prueba_normal |&gt; \n  bind_cols(predict(ajuste, casas_prueba_normal)), \n     truth = precio_miles, estimate = .pred  ) |&gt; \n  gt() |&gt; fmt_number(.estimate, decimals = 2)\n\n\n\n\n\n  \n    \n    \n      .metric\n      .estimator\n      .estimate\n    \n  \n  \n    mape\nstandard\n9.05\n    mae\nstandard\n15.25\n    rmse\nstandard\n20.54\n    rsq\nstandard\n0.92\n  \n  \n  \n\n\n\n\nLa distribución de los residuales (que en este caso se llaman maś bien valores de conformidad) se ve como sigue:\n\npreds_tbl &lt;- casas_prueba_normal |&gt; \n  bind_cols(predict(ajuste, casas_prueba_normal)) |&gt; \n  mutate(residual = abs(precio_miles - .pred)/.pred)\npreds_tbl |&gt; ggplot(aes(x = residual)) + geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nq &lt;- quantile(preds_tbl$residual, 0.90)\n\n\nset.seed(832)\npreds_tbl &lt;- preds_tbl |&gt; \n  mutate(inf = .pred *(1 - q), sup = .pred  *(1 + q)) |&gt; \n  mutate(pred_precio = .pred ) |&gt; \n  mutate(inf_precio = inf, sup_precio =  sup)\nggplot(preds_tbl, aes(x = pred_precio, y = precio_miles, ymin = inf_precio, \n                      ymax = sup_precio)) +\n  geom_abline() + \n  geom_linerange() +\n  geom_point(colour = \"red\") + coord_obs_pred()\n\n\n\n\nChecamos finalmente que la calibración es razonable con una tabla:\n\nn_grupos &lt;- 10 # podemos usar más grupos si tenemos más datos\npreds_tbl |&gt; \n  rename(y = precio_miles) |&gt; \n  mutate(grupo_pred = cut_number(pred_precio, n = n_grupos)) |&gt; \n  group_by(grupo_pred) |&gt; \n  summarise(n = n(), \n            cobertura = mean(y &gt;= inf_precio & y &lt;= sup_precio), \n            pred_precio = mean(pred_precio)) |&gt;\n  mutate(error_cob = 2 * sqrt(cobertura * (1- cobertura) / n)) |&gt; \n  ggplot(aes(x = pred_precio, y = cobertura, \n    ymin = cobertura - error_cob, ymax = cobertura + error_cob)) +\n  geom_hline(yintercept = 0.9, colour = \"red\") +\n  geom_point() + geom_linerange() + ylim(c(0.5, 1.1))"
  },
  {
    "objectID": "07-intervalos-predictivos.html#resumen",
    "href": "07-intervalos-predictivos.html#resumen",
    "title": "7  Incertidumbre en las predicciones",
    "section": "7.5 Resumen",
    "text": "7.5 Resumen\n\nLos intervalos conformes producidos aquí tienen garantías de cobertura promedio, pero no necesariamente condicional a valores de \\(x\\) particulares.\nEl chequeo básico consiste en ver cómo se comporta la cobertura para distintos valores de la predicción.\nCuando un atributo \\(x\\) es importante (por ejemplo por razones de discriminación, o razones de negocio), podemos checar la cobertura condicional a \\(x\\) (como en el ejemplo de grasa corporal de arriba).\nCuando la cobertura condicional no se cumple, podemos usar una muestra adicional para calibrar los intervalos. Esto se puede hacer ad-hoc o usando regresión cuantílica.\nUna alternativa adicional que se puede utilizar es intentar estimar directamente los cuantiles de la respuesta (por ejemplo 5 y 95% para un intervalo del 90%). Existe una función de pérdida diseñada para este propósito (veremos más adelante) que se puede aplicar a regresión lineal, redes neuronales, métodos basados en árboles y otros. Igualmente, es necesario checar y calibrar si es necesario los intervalos resultantes.\nLa selección de medida de conformidad (o función de pérdida) para cada modelo no es trivial, y de esa medida depende el comportamiento de los intervalos. En problemas de regresión, pérdida absoluta y MAPE (error porcentual absoluto promedio) son usuales, y una puede desempeñarse mejor que otra.\n\nFinalmente, es posible hacer predicción conforme con tidymodels (o paquetes de Python), consultar por ejemplo Conformal inference for regression models o para Python, Introduction To Conformal Prediction With Python."
  },
  {
    "objectID": "08-clasificacion-1.html#qué-estimar-en-problemas-de-clasificación",
    "href": "08-clasificacion-1.html#qué-estimar-en-problemas-de-clasificación",
    "title": "8  Clasificación",
    "section": "8.1 ¿Qué estimar en problemas de clasificación?",
    "text": "8.1 ¿Qué estimar en problemas de clasificación?\nCuando clasificamos según entradas \\(x\\) en una clase, podemos estar más o menos seguros de la clasificación. Por ejemplo: puede ser que la la decisión es clasificar a un cliente dado como “impago en los próximos tres meses”. La incertidumbe está en que quizá la probabilidad de impago es de 95%, pero existe una probabilidad de 5% de que el cliente se mantenga al corriente. Esto es muy diferente a un cliente con probabilidades respectivas de 60% y 40%. En general, cualquier tipo de análisis costo-beneficio que utilice el modelo debe intentar tomar en cuenta que estos dos clientes son muy diferentes.\nConsideramos primero un problema de clasificación binaria, y denotamos por \\(y\\in \\{0,1\\}\\) la indicadora de una de las dos de las categorías. Sea \\(p(x)\\) una función que mide qué tan seguros estamos que la observación es de clase \\(y=1\\). Supondremos que \\(p(x)\\) es una función que toma valores entre \\(0\\) y \\(1\\).\nAhora necesitamos una función de pérdida \\(L(y, p)\\) que evalúa el error cuando nuestra medida de confianza es \\(p\\) y la clase observada es \\(y\\). Podemos usar por ejemplo la pérdida cuadrática:\n\\[L(y, p) = (y - p)^2,\\] que también se llama pérdida de Brier en este contexto. Igual que en regresión, dada una población, podemos encontrar la función \\(p^*(x)\\) que minimiza la pérdida esperada sobre toda la población. En este caso, \\[p^*(x) = E(y|x) = P(y=1|x)\\] es decir, la verdadera probabilidad de que la clase sea 1 es la función \\(p^*(x)\\) que minimiza la pérdida cuadrática. Si usamos por ejemplo la pérdida absoluta, entonces la solucion es tomar como \\(p^* (x) = 1\\) si \\(P(y= 1|x) &gt; 0.5\\), y \\(p^*(x)= 0\\) en otro caso (muestra por qué).\nAunque utilizaremos otras pérdidas mejor adaptadas para el problema del clasificación, por el momento notemos que igual que planteamos el problema aprendizaje en regresión como un problema de aproximar una curva \\(f^*(x)\\) óptima con una función \\(\\hat{f}(x)\\) construida a partir de datos, igualmente podemos plantear el problema de clasificación binaria como sigue:\n\nBuscamos algoritmos \\({\\mathcal L} \\to \\hat{p}(x)\\) tal que \\(\\hat{p}(x)\\) está cercana a la probabilidad de clase \\(p^* (x) = P(y=1 |x)\\).\nLos argumentos de error irreducible, sesgo y variabilidad aplican también en esta situación bajo la pérdida de Brier y puede darse un argumento para cada clase (considerando \\(y_k - \\hat{p}_k(x)\\) como residual). En este caso, el error irreducible proviene del hecho de que \\(p^*_k(x)\\) no necesariamente toman solo los valores 0 o 1, y dadas las \\(x\\), existe incertidumbre en la clase que vamos a observar.\n\n\nEjemplo\n(Impago de tarjetas de crédito) Supongamos que \\(x=\\) porcentaje del crédito máximo usado, y \\(y\\in\\{0, 1\\}\\), donde \\(1\\) corresponde al corriente y \\(0\\) representa impago. Las probabilidades condicionales de clase para la clase al corriente podrían ser, por ejemplo:\n\n\\(p(x) = P(y=1|x) =0.95\\) si \\(x &lt; 0.15\\)\n\\(p(x) = P(y=1|x) = 0.95 - 0.7(x - 0.15)\\) si \\(x&gt;=0.15\\)\n\nEstas son probabilidades y no determinan el resultado, pues hay otras variables que influyen en que un cliente permanezca al corriente o no en sus pagos más allá de información contenida en el porcentaje de crédito usado. Nótese que estas probabilidades son diferentes a las no condicionadas, por ejempo, podríamos tener que a total \\(P(y=1)=0.83\\)\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(gt)\np_1 &lt;- function(x){\n  ifelse(x &lt; 0.15, 0.95, 0.95 - 0.7 * (x - 0.15))\n}\nggplot(tibble(x = seq(0, 1, 0.01)), aes(x = x)) + \n    stat_function(fun = p_1)  +\n    ylab(\"Prob al corriente\")"
  },
  {
    "objectID": "08-clasificacion-1.html#estimación-de-probabilidades-de-clase",
    "href": "08-clasificacion-1.html#estimación-de-probabilidades-de-clase",
    "title": "8  Clasificación",
    "section": "8.2 Estimación de probabilidades de clase",
    "text": "8.2 Estimación de probabilidades de clase\n¿Cómo estimamos ahora las probabilidades de clase a partir de una muestra de entrenamiento? Veremos por ahora dos métodos: k-vecinos más cercanos y regresión logística.\n\nEjemplo\nVamos a generar unos datos con el modelo simple del ejemplo anterior:\n\nsimular_impago &lt;- function(n = 500){\n    # suponemos que los valores de x están concentrados en valores bajos,\n    # quizá la manera en que los créditos son otorgados\n    clases &lt;- c(\"al_corriente\", \"impago\")\n    x &lt;- pmin(rexp(n, 100 / 40), 1)\n    # las probabilidades de estar al corriente:\n    prob &lt;- p_1(x)\n    # finalmente, simulamos cuáles clientes siguen al corriente y cuales no:\n    g &lt;- map_chr(1:length(x), ~ sample(clases, size = 1, prob = c(prob[.x], 1- prob[.x])))\n    g &lt;- factor(g, levels = c(\"al_corriente\", \"impago\"))\n    datos &lt;- tibble(x = x, p_1 = prob, g = g) |&gt; \n      mutate(y = ifelse(g == \"al_corriente\", 1, 0))\n    datos\n}\nset.seed(193)\ndat_ent  &lt;- simular_impago() |&gt; select(x, g, y) \ndat_ent |&gt; sample_n(20)\n\n# A tibble: 20 × 3\n         x g                y\n     &lt;dbl&gt; &lt;fct&gt;        &lt;dbl&gt;\n 1 0.118   al_corriente     1\n 2 0.109   al_corriente     1\n 3 0.444   al_corriente     1\n 4 0.153   al_corriente     1\n 5 0.100   al_corriente     1\n 6 0.0109  al_corriente     1\n 7 0.216   al_corriente     1\n 8 1       impago           0\n 9 0.0846  al_corriente     1\n10 0.144   al_corriente     1\n11 0.377   impago           0\n12 0.0908  al_corriente     1\n13 0.128   al_corriente     1\n14 0.00262 al_corriente     1\n15 0.411   al_corriente     1\n16 0.545   al_corriente     1\n17 0.402   al_corriente     1\n18 0.0544  al_corriente     1\n19 0.00265 al_corriente     1\n20 0.0927  al_corriente     1\n\n\nComo este problema es de dos clases, podemos graficar como sigue (agregamos variación artificial en \\(y\\) para evitar traslape de los puntos):\n\ngraf_1 &lt;- ggplot(dat_ent, aes(x = x)) +\n  geom_jitter(aes(colour = factor(g), y = y), \n    width=0.02, height=0.1) + ylab(\"\") + \n    labs(colour = \"Clase\")\ngraf_1"
  },
  {
    "objectID": "08-clasificacion-1.html#k-vecinos-más-cercanos",
    "href": "08-clasificacion-1.html#k-vecinos-más-cercanos",
    "title": "8  Clasificación",
    "section": "8.3 k-vecinos más cercanos",
    "text": "8.3 k-vecinos más cercanos\nPara usar \\(k\\)-vecinos más cercanos para estimar la probabilidades de clase para cada \\(x\\), podemos tomar una vecindad de la \\(x\\) donde queremos predecir, y tomar el siguiente promedio:\n\\[\\hat{p}(x) = \\frac{1}{k}\\sum_{x^{(i)} \\in N_k(x)} y^{(i)},\\]\nque es la proporción de unos en una vecindad \\(N_k(x)\\) de \\(x\\).\n\nEjemplo\nVamos a intentar estimar la probabilidad condicional de estar al corriente usando k vecinos más cercanos:\n\nvmc_modelo &lt;- nearest_neighbor(neighbors = 100, weight_func = \"gaussian\") |&gt; \n  set_engine(\"kknn\") |&gt; \n  set_mode(\"classification\")\najuste_vmc &lt;- vmc_modelo |&gt; fit(g ~ x, dat_ent)\n# para graficar:\ngraf_kvmc &lt;- tibble(x = seq(0, 1, 0.01))\ngraf_kvmc &lt;- predict(ajuste_vmc, graf_kvmc, type = \"prob\") |&gt; \n  bind_cols(graf_kvmc) |&gt; \n  select(x, .pred_al_corriente)\ngraf_kvmc |&gt; head()\n\n# A tibble: 6 × 2\n      x .pred_al_corriente\n  &lt;dbl&gt;              &lt;dbl&gt;\n1  0                 0.947\n2  0.01              0.946\n3  0.02              0.948\n4  0.03              0.954\n5  0.04              0.973\n6  0.05              0.985\n\n\nY la curva roja da nuestra estimación de probabilidad de impago para cada $x4:\n\ngraf_verdadero &lt;- tibble(x = seq(0, 1, 0.01), p_1 = p_1(x))\ngraf_2 &lt;- graf_1 + \n  geom_line(data = graf_kvmc, aes(y = .pred_al_corriente), colour = 'red', size=1.2) +\n  geom_line(data = graf_verdadero, aes(y = p_1)) +\n  ylab('Prob al corriente') + xlab('% crédito usado') \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\ngraf_2\n\n\n\n\nAhora podríamos usar una muestra de prueba para evaluar nuestra estimación, pues no tenemos la curva negra óptima para comparar."
  },
  {
    "objectID": "08-clasificacion-1.html#ejemplo-diabetes",
    "href": "08-clasificacion-1.html#ejemplo-diabetes",
    "title": "8  Clasificación",
    "section": "8.4 Ejemplo: diabetes",
    "text": "8.4 Ejemplo: diabetes\nConsideremos datos de diabetes en mujeres Pima:\nA population of women who were at least 21 years old, of Pima Indian heritage and living near Phoenix, Arizona, was tested for diabetes according to World Health Organization criteria. The data were collected by the US National Institute of Diabetes and Digestive and Kidney Diseases. We used the 532 complete records after dropping the (mainly missing) data on serum insulin.\n\nnpreg number of pregnancies.\nglu plasma glucose concentration in an oral glucose tolerance test.\nbp diastolic blood pressure (mm Hg).\nskin triceps skin fold thickness (mm).\nbmi body mass index (weight in kg/(height in m)^2).\nped diabetes pedigree function.\nage age in years.\ntype Yes or No, for diabetic according to WHO criteria.\n\n\ndiabetes_ent &lt;- as_tibble(MASS::Pima.tr)\ndiabetes_pr &lt;- as_tibble(MASS::Pima.te)\ndiabetes_ent\n\n# A tibble: 200 × 8\n   npreg   glu    bp  skin   bmi   ped   age type \n   &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt;\n 1     5    86    68    28  30.2 0.364    24 No   \n 2     7   195    70    33  25.1 0.163    55 Yes  \n 3     5    77    82    41  35.8 0.156    35 No   \n 4     0   165    76    43  47.9 0.259    26 No   \n 5     0   107    60    25  26.4 0.133    23 No   \n 6     5    97    76    27  35.6 0.378    52 Yes  \n 7     3    83    58    31  34.3 0.336    25 No   \n 8     1   193    50    16  25.9 0.655    24 No   \n 9     3   142    80    15  32.4 0.2      63 No   \n10     2   128    78    37  43.3 1.22     31 Yes  \n# ℹ 190 more rows\n\n\nIntentaremos predecir diabetes dependiendo del una medición de glucosa en la sangre:\n\nggplot(diabetes_ent, aes(x = glu, y= ifelse(type=='Yes', 1, 0), colour = type)) +\n  geom_jitter(height = 0.05)\n\n\n\n\nUsamos \\(30\\) vecinos más cercanos para estimar \\(p(x)\\):\n\ngraf_data &lt;- tibble(glu = seq(50, 200, 1))\n# ajustar modelo\najuste_vmc_diabetes &lt;- vmc_modelo |&gt; set_args(neighbors = 50) |&gt; \n  fit(type ~ glu, diabetes_ent)\n# graficar\ngraf_data &lt;- predict(ajuste_vmc_diabetes, graf_data, type = \"prob\") |&gt; \n  bind_cols(graf_data) |&gt; \n  select(glu, .pred_Yes)\nggplot(diabetes_ent, aes(x = glu)) + \n  geom_point(aes(y = as.numeric(type == \"Yes\"), colour = type)) + \n  geom_line(data = graf_data, aes(y = .pred_Yes)) +\n  ylab('Probabilidad diabetes')\n\n\n\n\nFinalmente, evaluamos por ejemplo con la pérdida de Brier:\n\npreds_tbl &lt;- predict(ajuste_vmc_diabetes, diabetes_pr, type = \"prob\") |&gt; \n  bind_cols(diabetes_pr |&gt; select(type)) |&gt; \n  mutate(y = as.numeric(type == \"Yes\")) \npreds_tbl |&gt; head()\n\n# A tibble: 6 × 4\n  .pred_No .pred_Yes type      y\n     &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt;\n1    0.482    0.518  Yes       1\n2    0.921    0.0793 No        0\n3    0.902    0.0980 No        0\n4    0.925    0.0752 Yes       1\n5    0.250    0.750  Yes       1\n6    0.342    0.658  Yes       1\n\n\n\npreds_tbl |&gt; \n  rmse(truth = y, estimate = .pred_Yes)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.405\n\n\nPodemos comparar este error con la predicción que haríamos usando la proporción de unos en los datos, por ejemplo:\n\npromedio_ent &lt;- diabetes_ent |&gt; mutate(y = type == \"Yes\") |&gt; \n  pull(y) |&gt; mean()\npreds_tbl |&gt; mutate(promedio = promedio_ent) |&gt; \n  rmse(truth = y, estimate = promedio)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.470\n\n\nFinalmente, probemos usando todas las variables, teniendo cuidado de estandarizar las variables de entranda:\n\nreceta_diabetes &lt;- recipe(type ~ ., diabetes_ent) |&gt; \n  step_normalize(all_predictors())\nmodelo_vmc &lt;- vmc_modelo |&gt; \n  set_args(neighbors = 50) \nflujo_vmc_diabetes &lt;- workflow() |&gt; \n  add_recipe(receta_diabetes) |&gt; \n  add_model(modelo_vmc)\npreds_todas &lt;- fit(flujo_vmc_diabetes, diabetes_ent) |&gt; \n  predict(diabetes_pr, type = \"prob\") |&gt; \n  bind_cols(diabetes_pr |&gt; select(type)) |&gt; \n  mutate(y = as.numeric(type == \"Yes\")) \npreds_todas |&gt; \n  rmse(truth = y, estimate = .pred_Yes)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;\n1 rmse    standard       0.396"
  },
  {
    "objectID": "08-clasificacion-1.html#pérdida-logarítmica",
    "href": "08-clasificacion-1.html#pérdida-logarítmica",
    "title": "8  Clasificación",
    "section": "8.5 Pérdida logarítmica",
    "text": "8.5 Pérdida logarítmica\nLa pérdida de Brier es una medida útil para evaluar modelos, pero tiene algunos defectos cuando se usa en el ajuste de probabilidades de clase. Uno importante es que es penaliza relativamente poco a errores donde predecimos por ejemplo \\(\\hat{p}_1(x) = 0.0001\\), y resulta que observamos \\(g=1\\). La penalización es similar que cuando \\(\\hat{p}_1(x) = 0.01\\), pero se puede argumentar que el primero de los errores es considerablemente más grave que el segundo.\nConsideremos entonces que tenemos una estimación \\(\\hat{p}_g(x)\\) de las probabilidad de clase. Supongamos que observamos ahora \\((x, g)\\) (la clase verdadera es \\(g\\)).\n\nSi \\(\\hat{p}_{g}(x)\\) es muy cercana a uno, deberíamos penalizar poco, pues dimos probabilidad alta a la clase \\(g\\) que ocurrió.\nSi \\(\\hat{p}_{g}(x)\\) es chica, deberíamos penalizar más, pues dimos probabilidad baja a observar la clase \\(g\\).\nSi \\(\\hat{p}_{g}(x)\\) es muy cercana a cero, y observamos \\(g\\), deberíamos hacer una penalización muy alta (convergiendo a \\(\\infty\\), pues no es aceptable que sucedan eventos con probabilidad estimada extremadamente baja).\n\nQuisiéramos encontrar una función \\(h\\) apropiada, de forma que la pérdida al observar \\((x, g)\\) sea \\[s(\\hat{p}_{g}(x)),\\] y que cumpla con los puntos arriba señalados. Entonces tenemos que\n\n\\(s\\) debe ser una función continua y decreciente en \\([0,1]\\)\nPodemos poner \\(s(1)=0\\) (no hay pérdida si ocurre algo con que dijimos tiene probabilidad 1)\n\\(s(p)\\) debe ser muy grande is \\(p\\) es muy chica.\n\nUna opción analíticamente conveniente es la pérdida logarítmica: \\[s(p) = - \\log(p)\\]\n\nperdidas_tbl &lt;- tibble(p = seq(0.01, 1, 0.001)) |&gt; \n  mutate(logarítmica = - log(p), brier  = 2 * (1 - p)^2) |&gt; \n  pivot_longer(cols = logarítmica:brier, names_to = \"tipo\", values_to = \"perdida\")\nggplot(perdidas_tbl, aes(x = p, y = perdida, colour = tipo)) +\n  geom_line(size = 1.1)\n\n\n\n\nAsí que la pérdida para un caso con entradas \\(x\\) y clase \\(g\\) es\n\\[-\\log \\hat{p}_g (x)\\] Se puede demostrar que, igual que la pérdida de Brier, si queremos minimizar la pérdida logarítmica sobre toda la población, la solución está dada por las verdaderas probabilidades de clase\n\\[p^*(x) = E(y|x) = P(y = 1|x).\\]\nDe modo que la función que queremos estimar es la misma en ambos casos. La pérdida de Brier sin embargo, es menos sensible a errores en los extremos de la escala de probabilidad, y puede producir estimaciones distintas cuando se usa en entrenamiento.\nObservaciones:\n\nLa pérdida logarítmica también se llama devianza binomial o devianza multinomial en otros lugares, usualmente multipicada por 2 (lo cual no cambia sus propiedades).\nUna razón importante para usar la pérdida logarítmica como el objetivo a minimizar es que equivale a la estimación por máxima verosimilitud (intenta demostrarlo).\nNo es fácil interpretar la pérdida logarítmica, pero es útil para ajustar y comparar modelos. Veremos otras medidas más fáciles de interpretar más adelante.\n\nCompara la siguiente definición con la que vimos para modelos de regresión:\n\n\n\n\n\n\nPérdida logarítmica\n\n\n\nSea \\[{\\mathcal L}=\\{ (x^{(1)},g^{(1)}),(x^{(2)},g^{(2)}), \\ldots, (x^{(N)}, g^{(N)}) \\}\\] una muestra de entrenamiento, a partir de las cuales construimos mediante un algoritmo funciones estimadas \\(\\hat{p}_{g} (x)\\) para \\(g=1,\\ldots, K\\). La pérdida logarítmica de entrenamiento está dada por \\[\\begin{equation}\n\\overline{err} = - \\frac{1}{N}\\sum_{i=1}^N log(\\hat{p}_{g^{(i)}} (x^{(i)}))\n\\end {equation}\\] Sea \\[{\\mathcal T}=\\{ (\\mathbf{x}^{(1)},\\mathbf{g}^{(1)}),(\\mathbf{x}^{(2)},\\mathbf{g}^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, \\mathbf{g}^{(m)}) \\}\\] una muestra de prueba. La pérdida logarítmica de prueba es \\[\\begin{equation}\n\\hat{Err} = - \\frac{1}{m}\\sum_{i=1}^m log(\\hat{p}_{\\mathbf{g}^{(i)}} (\\mathbf{x}^{(i)}))\n\\end {equation}\\] que es una estimación de la devianza de predicción \\[-E\\left [ \\log(\\hat{p}_g(x)) \\right ],\\] donde el promedia se toma sobre todos los valores \\((\\mathbf{x}, \\mathbf{g})\\) de la población.\n\n\n\nEjemplo\nRegresamos a nuestros ejemplo simulado de impago de tarjetas de crédito. Primero calculamos la pérdida logarítmica de entrenamiento\n\ns &lt;- \\(x) -log(x)\ndat_log_loss &lt;- ajuste_vmc |&gt;  \n  predict(dat_ent, type = \"prob\") |&gt; \n  bind_cols(dat_ent) |&gt; \n  select(x, g, .pred_impago, .pred_al_corriente)\ndat_log_loss &lt;- dat_log_loss |&gt;  \n  mutate(hat_p_g = ifelse(g==\"impago\", .pred_impago, .pred_al_corriente))\n\nNótese que dependiendo de qué clase observamos (columna \\(g\\)), extraemos la probabilidad correspondiente a la columna hat_p_g:\n\nset.seed(125)\ndat_log_loss |&gt; sample_n(20) |&gt; gt()\n\n\n\n\n\n  \n    \n    \n      x\n      g\n      .pred_impago\n      .pred_al_corriente\n      hat_p_g\n    \n  \n  \n    0.19852287\nal_corriente\n0.14038901\n0.8596110\n0.85961099\n    0.67376004\nal_corriente\n0.50190033\n0.4980997\n0.49809967\n    0.05182251\nal_corriente\n0.01304586\n0.9869541\n0.98695414\n    0.78516363\nal_corriente\n0.53011453\n0.4698855\n0.46988547\n    0.51357278\nal_corriente\n0.32252677\n0.6774732\n0.67747323\n    0.11636840\nal_corriente\n0.08958375\n0.9104162\n0.91041625\n    0.50414410\nimpago\n0.30908738\n0.6909126\n0.30908738\n    0.68843401\nimpago\n0.50778339\n0.4922166\n0.50778339\n    0.74915741\nimpago\n0.52349703\n0.4765030\n0.52349703\n    0.15106073\nal_corriente\n0.06850996\n0.9314900\n0.93149004\n    1.00000000\nimpago\n0.57659107\n0.4234089\n0.57659107\n    0.07148778\nal_corriente\n0.02543890\n0.9745611\n0.97456110\n    0.08934583\nal_corriente\n0.06888669\n0.9311133\n0.93111331\n    0.32848650\nal_corriente\n0.21323646\n0.7867635\n0.78676354\n    0.20386137\nal_corriente\n0.14978783\n0.8502122\n0.85021217\n    0.67871350\nimpago\n0.50258385\n0.4974162\n0.50258385\n    0.19050443\nal_corriente\n0.12406591\n0.8759341\n0.87593409\n    0.18182276\nal_corriente\n0.10562898\n0.8943710\n0.89437102\n    0.26726265\nal_corriente\n0.16922039\n0.8307796\n0.83077961\n    0.02035980\nimpago\n0.05230648\n0.9476935\n0.05230648\n  \n  \n  \n\n\n\n\nAhora aplicamos la función \\(s\\) que describimos arriba, y promediamos sobre el conjunto de entrenamiento:\n\ndat_log_loss &lt;- dat_log_loss |&gt; mutate(dev = s(hat_p_g))\ndat_log_loss |&gt; sample_n(20) |&gt; gt()\n\n\n\n\n\n  \n    \n    \n      x\n      g\n      .pred_impago\n      .pred_al_corriente\n      hat_p_g\n      dev\n    \n  \n  \n    0.32253044\nal_corriente\n0.21043820\n0.7895618\n0.7895618\n0.23627717\n    0.10851963\nal_corriente\n0.09528056\n0.9047194\n0.9047194\n0.10013039\n    0.11801945\nal_corriente\n0.08830654\n0.9116935\n0.9116935\n0.09245146\n    1.00000000\nimpago\n0.57659107\n0.4234089\n0.5765911\n0.55062199\n    0.11771241\nal_corriente\n0.08871380\n0.9112862\n0.9112862\n0.09289827\n    0.03576024\nal_corriente\n0.03671995\n0.9632800\n0.9632800\n0.03741110\n    0.02947193\nal_corriente\n0.04638861\n0.9536114\n0.9536114\n0.04749904\n    0.06708467\nal_corriente\n0.01865320\n0.9813468\n0.9813468\n0.01882937\n    0.52670471\nal_corriente\n0.34240787\n0.6575921\n0.6575921\n0.41917040\n    0.48074458\nimpago\n0.27713415\n0.7228659\n0.2771341\n1.28325360\n    0.75320749\nimpago\n0.52403777\n0.4759622\n0.5240378\n0.64619152\n    0.28789759\nal_corriente\n0.18845940\n0.8115406\n0.8115406\n0.20882086\n    0.50724729\nal_corriente\n0.31267931\n0.6873207\n0.6873207\n0.37495430\n    0.65972691\nimpago\n0.49530580\n0.5046942\n0.4953058\n0.70257994\n    1.00000000\nal_corriente\n0.57659107\n0.4234089\n0.4234089\n0.85941682\n    0.03525545\nal_corriente\n0.03771126\n0.9622887\n0.9622887\n0.03844073\n    0.53221265\nimpago\n0.35093998\n0.6490600\n0.3509400\n1.04714008\n    0.12557127\nal_corriente\n0.08047375\n0.9195263\n0.9195263\n0.08389669\n    0.12686269\nal_corriente\n0.07830790\n0.9216921\n0.9216921\n0.08154406\n    0.11702054\nal_corriente\n0.08882314\n0.9111769\n0.9111769\n0.09301826\n  \n  \n  \n\n\n\ndat_log_loss |&gt; ungroup() |&gt; summarise(lloss_entrena = mean(dev))\n\n# A tibble: 1 × 1\n  lloss_entrena\n          &lt;dbl&gt;\n1         0.421\n\n\nQue también podemos calcular como sigue:\n\ndat_log_loss |&gt; mn_log_loss(g, .pred_al_corriente) |&gt; \n  mutate(.estimate = .estimate )\n\n# A tibble: 1 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 mn_log_loss binary         0.421\n\n\nRecordemos que la devianza de entrenamiento no es la cantidad que evalúa el desempeño del modelo. Hagamos el cálculo entonces para una muestra de prueba:\n\nset.seed(1213)\ndat_prueba &lt;- simular_impago(n = 5000) |&gt; select(x, g)\n## calcular para muestra de prueba\ndat_log_loss_prueba &lt;- ajuste_vmc |&gt; \n  predict(dat_prueba, type = \"prob\") |&gt; \n  bind_cols(dat_prueba) |&gt; \n  select(x, g, .pred_impago, .pred_al_corriente)\ndat_log_loss_prueba &lt;- dat_log_loss_prueba |&gt; \n  mutate(hat_p_g = ifelse(g == \"al_corriente\", .pred_al_corriente, .pred_impago))\ndat_log_loss_prueba &lt;- dat_log_loss_prueba |&gt; mutate(log_loss = s(hat_p_g))\ndat_log_loss_prueba |&gt; ungroup() |&gt; summarise(log_loss_prueba = mean(log_loss))\n\n# A tibble: 1 × 1\n  log_loss_prueba\n            &lt;dbl&gt;\n1           0.434"
  },
  {
    "objectID": "08-clasificacion-1.html#clasificación-multinomial",
    "href": "08-clasificacion-1.html#clasificación-multinomial",
    "title": "8  Clasificación",
    "section": "8.6 Clasificación multinomial",
    "text": "8.6 Clasificación multinomial\nCuando tenemos sólo dos clases (clasificación binaria), basta con estimar una probabilidad de clase, pues la segunda es complemento de la primera. Para tres o más clases introducimos notación adicional:\n\nConsideramos un problema donde \\(g\\) puede ser una de \\(K\\) clases posibles. Tenemos \\(K\\) probabilidades de clase \\(p(x) = (p_1(x), p_2(x), \\ldots p_K(x))\\) que deben sumar 1 (de forma que una de ellas es redundante dadas las otras).\nDefinimos \\((y_1,y_2, \\ldots, y_k)\\) variables indicadoras de las categorías, donde \\(y_k = 1\\) cuando \\(g = k\\) y \\(y_k = 0\\) en otro caso.\n\nLa pérdida de Brier en este caso se puede definir como\n\\[L(g, p(x)) = \\sum_{k=1}^K (y_k - p_k(x))^2 = (1 - p_g(x))^2 + \\sum_{k\\neq g} (p_k(x))^2\\] Esto quiere decir que el score de Brier es chico cuando \\(p_g(x)\\), la probabilidad de la clase \\(g\\), es cercana a uno y el resto de las probabilidades son cercanas a 0 (verifica que esta definición es equivalente para dos clases según la definición mostrada arriba para clasificación binaria). En este caso, la solución teórica que minimiza esta pérdida promediada sobre toda la población es\n\\[p_k^*(x) = E(y_k | x) = P(g = k| x)\\]\nSi usamos la pérdida logarítmica, entonces la pérdida es\n\\[L(g, p(x)) = -\\log p_g (x),\\] que en nuestra notación con indicadoras se escribe como\n\\[L(y, p(x)) = -\\sum_{k=1}^K y_k\\log p_k (x),\\]\nEjercicio: escribe las estimaciones de clase de \\(k\\)-vecinos más cercanos para clasificación multinomial."
  },
  {
    "objectID": "08-clasificacion-1.html#regresión-logística",
    "href": "08-clasificacion-1.html#regresión-logística",
    "title": "8  Clasificación",
    "section": "8.7 Regresión logística",
    "text": "8.7 Regresión logística\nEn \\(k\\) vecinos más cercanos, intentamos estimar directamente con promedios las probabilidades de clase, sin considerar ninguna estructura. Ahora consideramos modelos más estructurados, definidos por parámetros, e intentaremos ajustarlos minimizando la pérdida logarítmica.\nIgual que en regresión lineal, algunos de los modelos más simples que podemos imaginar son modelos lineales. Solo es necesario hacer una adaptación.\nSupongamos que nuestra variable respuesta es \\(y\\), que toma valores 0 o 1.\nAhora queremos definir \\(p(x) = p_1(x)\\) (probabilidad de que ocurra la clase 1) en términos de un promedio ponderado de las variables de entrada, como en regresión lineal:\n\\[\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_px_p.\\]\nSin embargo, observamos que esta expresión puede dar valores negativos o mayores a uno, de forma que no necesariamente puede interpetarse como una probabilidad \\(p(x)\\). Una de las formas más sencillas de resolver este problema es transformar esta expresión para que necesariamente esté en \\([0,1]\\) por medio de una función fija \\(h\\):\n\\[p_{\\beta}(x) = h(\\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_px_p),\\] donde \\(h\\) debe ser una función que mapea valores reales a valores en \\([0,1]\\).\nEn este punto hay muchas funciones que podríamos usar. Para simplificar la interpretación y uso de este modelo, podemos escoger entre funciones que satisfagan, por ejemplo:\n\n\\(h\\) toma valores en \\([0,1]\\) es creciente y diferenciable\n\\(h(0) = 0.5\\) (0 equivale a probabilidad 0.5, negativos dan probabilidades menores a 0.5 y positivos dan probabilidades mayores a 0.5)\n\\(h(-x)=1-h(x)\\) (simetría). Por ejemplo, si \\(h(-2)=0.16\\) entonces \\(h(2)= 1-0.16=0.84\\).\n\nHay todavía muchas opciones. Una de las más simples es usar la función logística\n\n\n\n\n\n\nTip\n\n\n\nLa función logística está dada por \\[h(x)=\\frac{e^x}{1+e^x}\\]\n\n\n\nh &lt;- function(x){exp(x)/(1+exp(x)) }\nggplot(tibble(x = seq(-6, 6, 0.01)), aes(x = x)) + stat_function(fun = h)\n\n\n\n\nEsta función comprime adecuadamente (para nuestros propósitos) el rango de todos los reales dentro del intervalo \\([0,1]\\). Si aplicamos al predictor lineal que consideramos, obtenemos:\n\n\n\n\n\n\nRegresión logística\n\n\n\nEl modelo de regresión logística está dado por \\[p_1(x)=p_1(x;\\beta)= h(\\beta_0+\\beta_1x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p)\\]\ny \\[p_0(x)=p_0(x;\\beta)=1-p_1(x;\\beta),\\] donde \\(\\beta=(\\beta_0,\\beta_1, \\beta_2, \\cdots, \\beta_p)\\).\n\n\n\nEjemplo\nConsideremos nuestro ejemplo de impago. Podemos examinar qué tipo de probilidades obtendríamos con regresión logística y distintos parametros beta:\n\ncrear_p &lt;- function(beta_0, beta_1){\n    function(x){\n        h(beta_0 + beta_1 * x)\n    }\n}\ndf_grid &lt;- tibble(x = seq(0, 1, 0.01))\nbetas &lt;- tibble(beta_0 = c(-5, -0.5, 2.5),\n                beta_1 = c(10,   -2, -4))\nbetas &lt;- betas |&gt; \n    mutate(p = map2(beta_0, beta_1, crear_p)) |&gt; \n    mutate(grid = map(p, ~ df_grid |&gt; mutate(p_1 = .(x)))) |&gt; \n    select(-p) |&gt; \n    mutate(fun_nom = paste(beta_0, \"+\", beta_1, \"x\")) |&gt; \n    unnest(cols = c(grid))\ngraf_1 + geom_line(data = betas, aes(x = x, y = p_1)) + facet_wrap(~fun_nom) \n\n\n\n\nExperimenta con otros valores de \\(\\beta_0\\) y \\(\\beta_1\\).\n\n\n\n\n\n\nTip\n\n\n\nEncontramos los coeficientes de la regresión logística minimizando la pérdida logarítmica de entrenamiento.\n\n\nEsto se puede hacer de diversas maneras. Tradicionalmente, se utiliza el método de Newton-Raphson, pero resulta más fácil escalar métodos derivados de descenso máximo. Es decir, calculamos el gradiente de la pérdida y tomamos un paso en la dirección contraria al gradiente, que es la dirección local de descenso máximo."
  },
  {
    "objectID": "08-clasificacion-1.html#ejercicio-datos-de-diabetes",
    "href": "08-clasificacion-1.html#ejercicio-datos-de-diabetes",
    "title": "8  Clasificación",
    "section": "8.8 Ejercicio: datos de diabetes",
    "text": "8.8 Ejercicio: datos de diabetes\nYa están divididos los datos en entrenamiento y prueba\n\ndiabetes_ent &lt;- as_tibble(MASS::Pima.tr)\ndiabetes_pr &lt;- as_tibble(MASS::Pima.te)\ndiabetes_ent |&gt; head() |&gt; gt()\n\n\n\n\n\n  \n    \n    \n      npreg\n      glu\n      bp\n      skin\n      bmi\n      ped\n      age\n      type\n    \n  \n  \n    5\n86\n68\n28\n30.2\n0.364\n24\nNo\n    7\n195\n70\n33\n25.1\n0.163\n55\nYes\n    5\n77\n82\n41\n35.8\n0.156\n35\nNo\n    0\n165\n76\n43\n47.9\n0.259\n26\nNo\n    0\n107\n60\n25\n26.4\n0.133\n23\nNo\n    5\n97\n76\n27\n35.6\n0.378\n52\nYes\n  \n  \n  \n\n\n\ndiabetes_ent$id &lt;- 1:nrow(diabetes_ent)\ndiabetes_pr$id &lt;- 1:nrow(diabetes_pr)\n\nAunque no es necesario, podemos normalizar:\n\nreceta_diabetes &lt;- recipe(type ~ ., diabetes_ent) |&gt;\n  update_role(id, new_role = \"id_variable\") |&gt; \n  step_normalize(all_numeric()) \ndiabetes_ent_s &lt;- receta_diabetes |&gt; prep() |&gt; juice() \ndiabetes_pr_s &lt;- receta_diabetes |&gt; prep() |&gt; bake(diabetes_pr)\n\n\nmodelo_lineal &lt;- logistic_reg(mode = \"classification\") |&gt; \n  set_engine(\"glm\")\nflujo_diabetes &lt;- workflow() |&gt; \n  add_model(modelo_lineal) |&gt; \n  add_recipe(receta_diabetes)\nflujo_ajustado &lt;- fit(flujo_diabetes, diabetes_ent)\nsaveRDS(flujo_ajustado, \"cache/flujo_ajustado_diabetes.rds\")\nflujo_ajustado\n\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n1 Recipe Step\n\n• step_normalize()\n\n── Model ───────────────────────────────────────────────────────────────────────\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n(Intercept)        npreg          glu           bp         skin          bmi  \n   -0.95583      0.34734      1.01705     -0.05473     -0.02247      0.51263  \n        ped          age  \n    0.55928      0.45201  \n\nDegrees of Freedom: 199 Total (i.e. Null);  192 Residual\nNull Deviance:      256.4 \nResidual Deviance: 178.4    AIC: 194.4\n\n\nAhora calculamos devianza de prueba y error de clasificación:\n\npreds_prueba &lt;- \n  predict(flujo_ajustado, diabetes_pr, type= \"prob\") |&gt; \n  bind_cols(predict(flujo_ajustado, diabetes_pr)) |&gt; \n  bind_cols(diabetes_pr |&gt; select(type))\npreds_prueba\n\n# A tibble: 332 × 4\n   .pred_No .pred_Yes .pred_class type \n      &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;       &lt;fct&gt;\n 1    0.232    0.768  Yes         Yes  \n 2    0.960    0.0403 No          No   \n 3    0.975    0.0253 No          No   \n 4    0.959    0.0413 No          Yes  \n 5    0.204    0.796  Yes         Yes  \n 6    0.265    0.735  Yes         Yes  \n 7    0.590    0.410  No          Yes  \n 8    0.780    0.220  No          No   \n 9    0.558    0.442  No          No   \n10    0.798    0.202  No          Yes  \n# ℹ 322 more rows\n\n\n\nlevels(preds_prueba$type)\n\n[1] \"No\"  \"Yes\"\n\n# ponemos event_level si \"positivo\" no es el primer factor\nmetricas &lt;- metric_set(accuracy, mn_log_loss)\nmetricas(preds_prueba, truth = type, .pred_Yes, estimate = .pred_class, \n         event_level = \"second\")\n\n# A tibble: 2 × 3\n  .metric     .estimator .estimate\n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;\n1 accuracy    binary         0.801\n2 mn_log_loss binary         0.441\n\n\nVamos a repetir usando keras.\n\nlibrary(keras)\nx_ent &lt;- diabetes_ent_s |&gt; select(-type, -id) |&gt; as.matrix()\ny_ent &lt;- diabetes_ent_s$type == \"Yes\"\nx_prueba &lt;- diabetes_pr_s |&gt; select(-type, -id) |&gt; as.matrix()\ny_prueba &lt;- diabetes_pr_s$type == 'Yes'\n# definición de estructura del modelo (regresión logística)\n# es posible hacerlo con workflows como vimos arriba, \n# pero aquí usamos directamente la interfaz de keras en R\nn_entrena &lt;- nrow(x_ent)\nmodelo_diabetes &lt;- keras_model_sequential() |&gt;\n        layer_dense(units = 1,        #una sola respuesta,\n            activation = \"sigmoid\",    # combinar variables linealmente y aplicar función logística\n            kernel_initializer = initializer_constant(0), #inicializamos coeficientes en 0\n            bias_initializer = initializer_constant(0))   #inicializamos ordenada en 0\n# compilar seleccionando cantidad a minimizar, optimizador y métricas\nmodelo_diabetes |&gt; compile(\n        loss = \"binary_crossentropy\",  # devianza es entropía cruzada\n        optimizer = optimizer_sgd(learning_rate = 0.75), # descenso en gradiente\n        metrics = list(\"binary_crossentropy\"))\n# Ahora iteramos\n# Primero probamos con un número bajo de iteraciones\nhistoria &lt;- modelo_diabetes |&gt; fit(\n  as.matrix(x_ent), # x entradas\n  y_ent,            # y salida o target\n  batch_size = nrow(x_ent), # para descenso en gradiente\n  epochs = 10 # número de iteraciones\n)\nplot(historia)\n\n\n\n\nY ahora podemos correr más iteraciones adicionales:\n\nhistoria &lt;- modelo_diabetes |&gt; fit(\n  as.matrix(x_ent), # x entradas\n  y_ent,            # y salida o target\n  batch_size = nrow(x_ent), # para descenso en gradiente\n  epochs = 1000, # número de iteraciones\n  verbose = 0\n)\n\nLos errores de entrenamiento y prueba son:\n\nevaluate(modelo_diabetes, x_ent, y_ent)\n\n               loss binary_crossentropy \n          0.4459766           0.4459766 \n\n\n\nevaluate(modelo_diabetes, x_prueba, y_prueba)\n\n               loss binary_crossentropy \n          0.4406986           0.4406986 \n\n\nVeamos que coeficientes obtuvimos:\n\nget_weights(modelo_diabetes)\n\n[[1]]\n            [,1]\n[1,]  0.34734303\n[2,]  1.01705003\n[3,] -0.05472934\n[4,] -0.02247145\n[5,]  0.51263183\n[6,]  0.55927497\n[7,]  0.45200703\n\n[[2]]\n[1] -0.9558301\n\n\nque coinciden con los valores que obtuvimos usando regresión logística de glm. La única diferencia es que el algoritmo de optimización que se usa en cada caso es diferente: con keras utilizamos descenso en gradiente, mientras que glm usa Newton-Raphson.\n\nflujo_ajustado |&gt; extract_fit_parsnip()\n\nparsnip model object\n\n\nCall:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)\n\nCoefficients:\n(Intercept)        npreg          glu           bp         skin          bmi  \n   -0.95583      0.34734      1.01705     -0.05473     -0.02247      0.51263  \n        ped          age  \n    0.55928      0.45201  \n\nDegrees of Freedom: 199 Total (i.e. Null);  192 Residual\nNull Deviance:      256.4 \nResidual Deviance: 178.4    AIC: 194.4"
  },
  {
    "objectID": "08-clasificacion-1.html#probabilidades-y-pérdida-0-1",
    "href": "08-clasificacion-1.html#probabilidades-y-pérdida-0-1",
    "title": "8  Clasificación",
    "section": "8.9 Probabilidades y pérdida 0-1",
    "text": "8.9 Probabilidades y pérdida 0-1\nOtra medida común para medir el error de un clasificador es el error de clasificación, que también llamamos probabilidad de clasificación incorrecta, o error bajo pérdida 0-1.\n\n\n\n\n\n\nProbabilidades de clase y pérdida 0-1\n\n\n\nSean \\(\\hat{p}_g(x)\\) probabilidades de clase estimadas. El clasificador bajo pérdida 0-1 asociado está dado por \\[\\hat{g} (x) = \\arg\\max_g \\hat{p}_g(x)\\] Podemos estimar su error de clasificación \\(P(\\hat{g}(x) \\neq g)\\) con una muestra de prueba \\[{\\mathcal T}=\\{ (\\mathbf{x}^{(1)},\\mathbf{g}^{(1)}),(\\mathbf{x}^{(2)},\\mathbf{g}^{(2)}), \\ldots, (\\mathbf{x}^{(m)}, \\mathbf{g}^{(m)})\\] mediante \\[\\hat{Err} = \\frac{1}{m} \\sum_{j=i}^m I(\\hat{g}(\\mathbf{x}^{(i)}) \\neq \\mathbf{g}^{(i)}),\\] es decir, la proporción de casos de prueba que son clasificados incorrectamente.\n\n\nObservación: Muy generalmente, esta manera de construir un clasificador es deficiente:\n\nRara vez queremos clasificar simplemente a la clase con mayor probabilidad. Por ejemplo, podría ser mucho más razonable que basta investigar una operación si su probabilidad de ser fraude está por arriba de 10%, y no necesariamente por arriba de 50%. Esto se debe a que los costos de los distintos errores no son simétricos.\nLa tasa de clasificación incorrecta por lo tanto es un resumen poco relevante para muchos problemas.\nPara la mayoría de problemas de clasificación, es un error ignorar las probabilidades de clase estimadas. No es lo mismo que un cliente tenga 99% de probabilidad de mantenerse al corriente que otro que tiene 55%. Ambos son clasificados de la misma manera por el clasificador de máxima probabilidad.\nPuede haber dos predictores con tasas similares de clasificación incorrecta, pero distintos en cuanto a score de Brier o pérdida logarítmica, y mejor score de Brier y pérdida logarítmica indican muchas veces mejor separación de clases.\n\nMás adelante veremos cómo construir reglas de clasificación a partir de probabilidades, pero por el momento notamos que tomar decisiones de cómo clasificar en el proceso de construcción de predictores es mala idea, pues confundimos el desempeño predictivo con los costos de tomar cada decisión de clasificación. Esos costos muchas veces no están perfectamente planteados, de forma que es mejor usar probabilidades para presentar a tomadores de decisiones o calcular simulaciones de costo-beneficio.\n\nEjemplo\nVeamos cómo se comporta en términos de error de clasificación nuestro último modelo:\n\ndat_log_loss |&gt; \n  bind_cols(predict(ajuste_vmc, dat_ent)) |&gt; \n  mutate(correcto = .pred_class == g)  |&gt;  \n  ungroup() |&gt;  summarise(p_correctos = mean(correcto))  |&gt; \n  mutate(error_clasif = 1 - p_correctos)\n\n# A tibble: 1 × 2\n  p_correctos error_clasif\n        &lt;dbl&gt;        &lt;dbl&gt;\n1       0.794        0.206\n\n\nY calculamos el error de clasificación de prueba:\n\ndat_log_loss_prueba |&gt; \n  bind_cols(predict(ajuste_vmc, dat_prueba)) |&gt; \n  mutate(correcto = .pred_class == g)  |&gt;  \n  ungroup() |&gt;  summarise(p_correctos = mean(correcto))  |&gt; \n  mutate(error_clasif = 1 - p_correctos)\n\n# A tibble: 1 × 2\n  p_correctos error_clasif\n        &lt;dbl&gt;        &lt;dbl&gt;\n1       0.802        0.198"
  },
  {
    "objectID": "08-clasificacion-1.html#regresión-logística-multinomial",
    "href": "08-clasificacion-1.html#regresión-logística-multinomial",
    "title": "8  Clasificación",
    "section": "8.10 Regresión logística multinomial",
    "text": "8.10 Regresión logística multinomial\nPara estimar \\(K\\) probabilidades de clase, consideramos \\(k\\) predictores lineales individuales\n\\[f_k(x) = \\beta_{0, k} + \\beta_{1,k} x_1 + \\cdots + \\beta_{p,k} x_p\\]\ny la probabilidad de clase la calculamos haciendo softmax sobre estas:\n\\[p_k(x) = \\frac{e^{f_k(x)}}{\\sum_i e^{f_i(x)}}\\]\nque necesariamente suman uno. Nótese si embargo que este modelo está sobreparametrizado, pues solamente es necesario escribir \\(K-1\\) de estas probabilidades, y la última tiene que ser el complemento para que sumen uno. Podemos ver esto, por ejemplo, si sumamos \\(h(x) = \\gamma_0 + \\gamma_1x_1 + \\cdots \\gamma_p x_p\\) a todas las funciones:\n\\[p_k(x) = \\frac{e^{f_k(x) + h(x)}}{\\sum_i e^{f_i(x) + h(x)}} = \\frac{e^{f_k(x)}}{\\sum_i e^{f_i(x)}}\\]\nEn regresión logística, por ejemplo, si tenemos \\(f_1(x)\\) y \\(f_0(x)\\) podemos tomar \\(f_0(x) = 0\\), de forma que \\[p_1(x) = \\frac{e^{f_1(x)}}{1+ e^{f_1(x)}}\\] que es justamente el modelo de regresión logística como lo escribimos arriba. Siempre es posible entonces crear una clase de referencia, con coeficientes igual a 0, aunque esto no es necesario si usamos regularización, que generalmente es el caso."
  },
  {
    "objectID": "08-clasificacion-1.html#ejemplo-clasificación-de-ropa",
    "href": "08-clasificacion-1.html#ejemplo-clasificación-de-ropa",
    "title": "8  Clasificación",
    "section": "8.11 Ejemplo: clasificación de ropa",
    "text": "8.11 Ejemplo: clasificación de ropa\nPara el siguiente problema tenemos imágenes en blanco y negro de artículos de ropa\n\nlibrary(imager)\nropa_datos &lt;- dataset_fashion_mnist()\nropa_entrena &lt;- ropa_datos$train \nropa_prueba &lt;- ropa_datos$test\n# estas son las categorias:\narticulos &lt;- c(\"playera/top\", \"pantalón\", \"suéter\", \"vestido\", \"abrigo\", \"sandalia\", \n                 \"camisa\", \"tenis\", \"bolsa\", \"bota\")\netiquetas_tbl &lt;- tibble(\n  codigo = 0:9, \n  articulo = c(\"playera\", \"pantalón\", \"suéter\", \"vestido\", \"abrigo\", \"sandalia\", \n                 \"camisa\", \"tenis\", \"bolsa\", \"bota\"))\n\n\nx &lt;- ropa_entrena$x\ny &lt;- ropa_entrena$y\n\nPor ejemplo:\n\npar(mfrow = c(4, 4), mar = c(1,1,1,1))\nfor(i in 2:17) plot(as.cimg(t(x[2 + i, ,])), axes = FALSE, main = articulos[y[2 + i] + 1])\n\n\n\n\nUtilizaremos regresión logistica multinomial con keras y regularización L2:\n\nnum_classes &lt;- 10\ninput_shape &lt;- c(28, 28, 1)\n\n# normalizar\nx_entrena &lt;- ropa_entrena$x / 255\nx_prueba &lt;- ropa_prueba$x / 255\ny_entrena &lt;- to_categorical(ropa_entrena$y, num_classes)\ny_prueba &lt;- to_categorical(ropa_prueba$y, num_classes)\nif(FALSE){\n#' Model definition\n#' (architecture taken from \n#' https://keras.rstudio.com/articles/examples/mnist_cnn.html )\nmodelo_ropa &lt;- keras_model_sequential()\nmodelo_ropa |&gt; \n  layer_flatten() |&gt; \n  layer_dense(units = 10,\n              activity_regularizer = regularizer_l2(l = 0.0005), \n              activation = 'softmax') \n# compile model\nmodelo_ropa |&gt;  compile(\n  loss = \"categorical_crossentropy\",\n  optimizer = optimizer_adam(learning_rate = 0.0005),\n  metrics = c(\"accuracy\")\n)\n\n# train and evaluate\nmodelo_ropa |&gt; fit(\n  x_entrena, y_entrena,\n  batch_size = 128,\n  epochs = 40,\n  verbose = 1,\n  validation_data = list(x_prueba, y_prueba)\n  )\nsave_model_tf(modelo_ropa, \"cache/red_ropa_1\")\n}\n\nmodelo_ropa &lt;- load_model_tf(\"cache/red_ropa_1\")\nscores &lt;- modelo_ropa |&gt; evaluate(\n  x_prueba, y_prueba, verbose = 0\n)\ncat('Test pérdida:', scores[[1]], '\\n')\n\nTest pérdida: 0.4358351 \n\ncat('Test clasificación correcta:', scores[[2]], '\\n')\n\nTest clasificación correcta: 0.8478 \n\n\nAhora podemos hacer predicciones:\n\npreds_mat &lt;- predict(modelo_ropa, x_prueba)\ndim(preds_mat)\n\n[1] 10000    10\n\nprobs &lt;- round(preds_mat[1,], 3)\ntibble(articulo = articulos, prob = probs) |&gt; \n  arrange(probs)\n\n# A tibble: 10 × 2\n   articulo     prob\n   &lt;chr&gt;       &lt;dbl&gt;\n 1 playera/top 0    \n 2 pantalón    0    \n 3 suéter      0    \n 4 vestido     0    \n 5 abrigo      0    \n 6 camisa      0    \n 7 bolsa       0.005\n 8 tenis       0.051\n 9 sandalia    0.117\n10 bota        0.827\n\n\n\nplot(as.cimg(t(ropa_prueba$x[1,,])), axes = FALSE, main = articulos[ropa_prueba$y[1] + 1])"
  },
  {
    "objectID": "81-apendice-descenso.html#cálculo-del-gradiente",
    "href": "81-apendice-descenso.html#cálculo-del-gradiente",
    "title": "Apéndice A — Apéndice 1: descenso en gradiente",
    "section": "A.1 Cálculo del gradiente",
    "text": "A.1 Cálculo del gradiente\nVamos a escribir ahora el algoritmo de descenso en gradiente para regresión lineal. Igual que en los ejemplos anteriores, tenemos que precalcular el gradiente. Una vez que esto esté terminado, escribir la iteración es fácil.\nRecordamos que queremos minimizar (dividiendo entre dos para simplificar más adelante) \\[L(\\beta) = \\frac{1}{2N}\\sum_{i=1}^N (y^{(i)} - f_\\beta(x^{(i)}))^2\\]\nLa derivada de la suma es la suma de las derivadas, así nos concentramos en derivar uno de los términos\n\\[  u^{(i)}=\\frac{1}{2}(y^{(i)} - f_\\beta(x^{(i)}))^2 \\] Usamos la regla de la cadena para obtener \\[ \\frac{1}{2}\\frac{\\partial}{\\partial \\beta_j} (y^{(i)} - f_\\beta(x^{(i)}))^2 =\n-(y^{(i)} - f_\\beta(x^{(i)})) \\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_j}\\]\nAhora recordamos que \\[f_{\\beta} (x) = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_p x_p\\]\nY vemos que tenemos dos casos. Si \\(j=0\\),\n\\[\\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_0} = 1\\] y si \\(j=1,2,\\ldots, p\\) entonces\n\\[\\frac{\\partial f_\\beta(x^{(i)})}{\\partial \\beta_j} = x_j^{(i)}\\]\nEntonces, si ponemos \\(u^{(i)}=\\frac{1}{2}(y^{(i)} - f_\\beta(x^{(i)}))^2\\):\n\\[\\frac{\\partial u^{(i)}}{\\partial \\beta_0} = -(y^{(i)} - f_\\beta(x^{(i)}))\\] y\n\\[\\frac{\\partial u^{(i)}}{\\partial \\beta_j} = - x_j^{(i)}(y^{(i)} - f_\\beta(x^{(i)}))\\]\nY sumando todos los términos (uno para cada caso de entrenamiento):\n\n\n\n\n\n\nGradiente para regresión lineal\n\n\n\nSea \\(e^{(i)} = y_{(i)} - f_{\\beta} (x^{(i)})\\). Entonces \\[\\begin{equation}\n  \\frac{\\partial L(\\beta)}{\\partial \\beta_0} = - \\frac{1}{N}\\sum_{i=1}^N e^{(i)}\n  (\\#eq:grad1)\n\\end{equation}\\] \\[\\begin{equation}\n  \\frac{\\partial L(\\beta)}{\\partial \\beta_j} = - \\frac{1}{N}\\sum_{i=1}^N x_j^{(i)}e^{(i)}\n  (\\#eq:grad2)\n\\end{equation}\\] para \\(j=1,2,\\ldots, p\\).\n\n\nNótese que cada punto de entrenamiento contribuye al cálculo del gradiente - la contribución es la dirección de descenso de error para ese punto particular de entrenamiento. Nos movemos entonces en una dirección promedio, para intentar hacer el error total lo más chico posible."
  },
  {
    "objectID": "81-apendice-descenso.html#implementación",
    "href": "81-apendice-descenso.html#implementación",
    "title": "Apéndice A — Apéndice 1: descenso en gradiente",
    "section": "A.2 Implementación",
    "text": "A.2 Implementación\nEn este punto, podemos intentar una implementación simple basada en el código anterior para hacer descenso en gradiente para nuestro problema de regresión (es un buen ejercicio). En lugar de eso, mostraremos cómo usar librerías ahora estándar para hacer esto. En particular usamos keras (con tensorflow), que tienen la ventaja:\n\nEn tensorflow y keras no es necesario calcular las derivadas a mano. Utiliza diferenciación automática, que no es diferenciación numérica ni simbólica: se basa en la regla de la cadena y la codificación explícita de las derivadas de funciones elementales.\n\n\nlibrary(tidymodels)\nlibrary(keras)\nsource(\"../R/casas_traducir_geo.R\")\nset.seed(68821)\n# dividir muestra\ncasas_split &lt;- initial_split(casas |&gt;\n                      select(precio_m2_miles, area_hab_m2, calidad_gral, num_coches), \n                             prop = 0.75)\n# obtener muestra de entrenamiento\ncasas_entrena &lt;- training(casas_split)\ncasas_receta &lt;- recipe(precio_m2_miles ~ ., casas_entrena) \n\n\n# definición de estructura del modelo (regresión lineal)\nx_ent &lt;- casas_receta |&gt; prep() |&gt; juice()  |&gt; select(-precio_m2_miles) |&gt; as.matrix()\ny_ent &lt;- casas_receta |&gt; prep() |&gt; juice() |&gt; pull(precio_m2_miles)\nn_entrena &lt;- nrow(x_ent)\ncrear_modelo &lt;- function(lr = 0.01){\n    modelo_casas &lt;- \n        keras_model_sequential() |&gt;\n        layer_dense(units = 1,        #una sola respuesta,\n            activation = \"linear\",    # combinar variables linealmente\n            kernel_initializer = initializer_constant(0), #inicializamos coeficientes en 0\n            bias_initializer = initializer_constant(0))   #inicializamos ordenada en 0\n    # compilar seleccionando cantidad a minimizar, optimizador y métricas\n    modelo_casas |&gt; compile(\n        loss = \"mean_squared_error\",  # pérdida cuadrática\n        optimizer = optimizer_sgd(learning_rate = lr), # descenso en gradiente\n        metrics = list(\"mean_squared_error\"))\n    modelo_casas\n}\n# tasa de aprendizaje es lr, tenemos que poner una tasa chica (prueba)\nmodelo_casas &lt;- crear_modelo(lr = 0.00001)\n# Ahora iteramos\n# Primero probamos con un número bajo de iteraciones\nhistoria &lt;- modelo_casas |&gt; fit(\n  x_ent,    # x entradas\n  y_ent,    # y salida o target\n  batch_size = nrow(x_ent), # para descenso en gradiente\n  epochs = 20, # número de iteraciones\n  verbose = 0\n)\n\n\nplot(historia, metrics = \"mean_squared_error\", smooth = FALSE) +\n  geom_line()\n\n\n\nhistoria$metrics$mean_squared_error |&gt; round(4)\n\n [1] 1.7903 0.7636 0.4549 0.3621 0.3342 0.3258 0.3232 0.3224 0.3222 0.3221\n[11] 0.3220 0.3220 0.3220 0.3219 0.3219 0.3219 0.3218 0.3218 0.3218 0.3217\n\n\nProbamos con más corridas para checar convergencia:\n\n# Agregamos iteraciones: esta historia comienza en los últimos valores de\n# la corrida anterior\nhistoria &lt;- modelo_casas |&gt; fit(\n  as.matrix(x_ent), # x entradas\n  y_ent,            # y salida o target\n  batch_size = nrow(x_ent), # para descenso en gradiente\n  epochs = 1000, # número de iteraciones\n  verbose = 0\n)\n\n\nplot(historia, metrics = \"mean_squared_error\", smooth = FALSE) \n\n\n\n\nEl modelo parece todavía ir mejorando. Veamos de todas formas los coeficientes estimados hasta ahora:\n\nkeras::get_weights(modelo_casas)\n\n[[1]]\n            [,1]\n[1,] 0.007331368\n[2,] 0.016437238\n[3,] 0.004633875\n\n[[2]]\n[1] 0.003028649\n\n\nLa implementación oficial de R es lm, que en general tiene buen desempeño para datos que caben en memoria:\n\nlm(precio_m2_miles ~ area_hab_m2 + calidad_gral + num_coches, \n   data = casas_entrena) |&gt; \n  coef()\n\n (Intercept)  area_hab_m2 calidad_gral   num_coches \n  0.66869194  -0.00449751   0.16807663   0.13115749 \n\n\nDe modo que todavía requerimos más iteraciones para alcanzar convergencia. ¿Por qué la convergencia es tan lenta? En parte, la razón es que las escalas de las variables de entrada son muy diferentes, de modo que es difícil ajustar una tasa de aprendizaje constante que funcione bien. Podemos remediar esto poniendo todas las entradas en la misma escala (normalizando)"
  },
  {
    "objectID": "81-apendice-descenso.html#normalización-de-entradas",
    "href": "81-apendice-descenso.html#normalización-de-entradas",
    "title": "Apéndice A — Apéndice 1: descenso en gradiente",
    "section": "A.3 Normalización de entradas",
    "text": "A.3 Normalización de entradas\nLa convergencia de descenso en gradiente (y también el desempeño numérico para otros algoritmos) puede dificultarse cuando las variables tienen escalas muy diferentes. Esto produce curvaturas altas en la función que queremos minimizar.\nEn este ejemplo simple, una variable tiene desviación estándar 10 y otra 1:\n\nx1 &lt;- rnorm(100, 0, 5) \nx2 &lt;- rnorm(100, 0, 1) +  0.1*x1\ny &lt;- 0*x1 + 0*x2 + rnorm(100, 0, 0.1) \ndat &lt;- tibble(x1, x2,  y)\nrss &lt;- function(beta)  mean((as.matrix(dat[, 1:2]) %*% beta - y)^2) \ngrid_beta &lt;- expand.grid(beta1 = seq(-1, 1, length.out = 50), \n                         beta2 = seq(-1, 1, length.out = 50))\nrss_1 &lt;- apply(grid_beta, 1, rss) \ndat_x &lt;- data.frame(grid_beta, rss_1)\nggplot(dat_x, aes(x = beta1, y = beta2, z = rss_1)) + \n    geom_contour(binwidth = 0.5) +\n    coord_equal() \n\n\n\n\nEn algunas direcciones el gradiente es muy grande, y en otras chico. Esto implica que la convergencia puede ser muy lenta en algunas direcciones, puede diverger en otras, y que hay que ajustar el paso \\(\\eta &gt; 0\\) con cuidado, dependiendo de dónde comiencen las iteraciones.\nPor ejemplo, con un tamaño de paso relativamente chico, damos unos saltos grandes al principio y luego avanzamos muy lentamente:\n\ngrad_calc &lt;- function(x_ent, y_ent){\n  # calculamos directamente el gradiente\n  salida_grad &lt;- function(beta){\n    n &lt;- length(y_ent)\n    f_beta &lt;- as.matrix(cbind(1, x_ent)) %*% beta\n    e &lt;- y_ent - f_beta\n    grad_out &lt;- - as.numeric(t(cbind(1, x_ent)) %*% e) / n\n    names(grad_out) &lt;- c('Intercept', colnames(x_ent))\n    grad_out\n  }\n  salida_grad\n}\ngrad_sin_norm &lt;- grad_calc(dat[, 1:2, drop = FALSE], dat$y)\niteraciones &lt;- descenso(10, c(0, -0.25, -0.75), 0.02, grad_sin_norm)\nggplot(dat_x) + \n    geom_contour(aes(x = beta1, y = beta2, z = rss_1), binwidth = 0.5) +\n    coord_equal() +\n  geom_path(data = data.frame(iteraciones[, 2:3]), aes(x=X1, y=X2), colour = 'red') +\n  geom_point(data = data.frame(iteraciones[, 2:3]), aes(x=X1, y=X2), colour = 'red')\n\n\n\n\nSi incrementamos el tamaño de paso observamos también convergencia lenta. En este caso particular, subir más el tamaño de paso puede producir divergencia:\n\niteraciones &lt;- descenso(10, c(0, -0.25, -0.75), 0.07, grad_sin_norm)\nggplot(dat_x) + \n    geom_contour(aes(x = beta1, y = beta2, z = rss_1), binwidth = 0.5) +\n    coord_equal() +\n  geom_path(data = data.frame(iteraciones[, 2:3]), aes(x=X1, y=X2), colour = 'red') +\n  geom_point(data = data.frame(iteraciones[, 2:3]), aes(x=X1, y=X2), colour = 'red')\n\n\n\n\nUna normalización usual es con la media y desviación estándar, donde hacemos, para cada variable de entrada \\(j=1,2,\\ldots, p\\) \\[ x_j^{(i)} = \\frac{ x_j^{(i)} - \\bar{x}_j}{s_j}\\] donde \\[\\bar{x}_j = \\frac{1}{N} \\sum_{i=1}^N x_j^{(i)}\\] \\[s_j = \\sqrt{\\frac{1}{N-1}\\sum_{i=1}^N (x_j^{(i)}- \\bar{x}_j )^2}\\] es decir, centramos y normalizamos por columna. Otra opción común es restar el mínimo y dividir entre la diferencia del máximo y el mínimo, de modo que las variables resultantes toman valores en \\([0,1]\\).\nEntonces escalamos antes de ajustar:\n\nx1_s = (x1 - mean(x1))/sd(x1)\nx2_s = (x2 - mean(x2))/sd(x2)\ndat &lt;- tibble(x1_s = x1_s, x2_s = x2_s,  y = y)\nrss &lt;- function(beta)  mean((as.matrix(dat[, 1:2]) %*% beta - y)^2) \ngrid_beta &lt;- expand.grid(beta1 = seq(-1, 1, length.out = 50), \n                         beta2 = seq(-1, 1, length.out = 50))\nrss_1 &lt;- apply(grid_beta, 1, rss) \ndat_x &lt;- data.frame(grid_beta, rss_1)\nggplot(dat_x, aes(x = beta1, y = beta2, z = rss_1)) + \n    geom_contour(binwidth = 0.5) +\n    coord_equal() \n\n\n\n\nNótese que los coeficientes ajustados serán diferentes a los del caso no normalizado.\nSi normalizamos, obtenemos convergencia más rápida\n\ngrad_sin_norm &lt;- grad_calc(dat[, 1:2, drop = FALSE], dat$y)\niteraciones &lt;- descenso(10, c(0, -0.25, -0.75), 0.5, grad_sin_norm)\nggplot(dat_x) + \n    geom_contour(aes(x = beta1, y = beta2, z = rss_1), binwidth = 0.5) +\n    coord_equal() +\n  geom_path(data = data.frame(iteraciones[, 2:3]), aes(x=X1, y=X2), colour = 'red') +\n  geom_point(data = data.frame(iteraciones[, 2:3]), aes(x=X1, y=X2), colour = 'red')\n\n\n\n\n\n\n\nCuando normalizamos antes de ajustar el modelo, las predicciones deben hacerse con entradas normalizadas. La normalización se hace con los mismos valores que se usaron en el entrenamiento (y no recalculando medias y desviaciones estándar con el conjunto de prueba). En cuanto a la forma funcional del predictor (f), el problema con entradas normalizadas es equivalente al de las entradas no normalizadas. Asegúrate de esto escribiendo cómo correponden los coeficientes de cada modelo normalizado con los coeficientes del modelo no normalizado.\n\n\n\nSupongamos que el modelo en las variables originales es \\[{f}_\\beta (X) = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_p X_p,\\] Consideramos el modelo con variables estandarizadas \\[{g}_{\\beta^s} (X) = \\beta_0^s + \\beta_1^s Z_1 + \\beta_2^s Z_2 + \\cdots + \\beta_p^s Z_p,\\]\nSustituyendo \\(Z_j = (X_j - \\mu_j)/s_j,\\)\n\\[{g}_{\\beta^s} (X) = (\\beta_0^s - \\sum_{j=1}^p \\beta_j^s \\mu_j/s_j) + \\frac{\\beta_1^s}{s_j} X_1 + \\frac{\\beta_2^s}{s_2} X_2 + \\cdots + \\frac{\\beta_p^s}{s_p} X_p,\\] Y vemos que tiene la misma forma funcional de \\(f_\\beta(X)\\). Si la solución de mínimos cuadrados es única, entonces una vez que ajustemos tenemos que tener \\(\\hat{f}_\\beta(X) = \\hat{g}_{\\beta^s} (X)\\), lo que implica que \\[\\hat{\\beta}_0 = \\hat{\\beta}_0^s -  \\sum_{j=1}^p \\hat{\\beta}_j^s\\mu_j/s_j\\] y \\[\\hat{\\beta}_j = \\hat{\\beta}_j^s/s_j.\\]\nNótese que para pasar del problema estandarizado al no estandarizado simplemente se requiere escalar los coeficientes por la \\(s_j\\) correspondiente.\n\nEjemplo\nRepetimos nuestro modelo, pero normalizando las entradas:\n\n# usamos recipes para este ejemplo, no necesitas usarlo\ncasas_receta &lt;- recipe(precio_m2_miles ~ ., casas_entrena) |&gt;\n  step_normalize(all_predictors()) \ncasas_receta |&gt; summary()\n\n# A tibble: 4 × 4\n  variable        type      role      source  \n  &lt;chr&gt;           &lt;list&gt;    &lt;chr&gt;     &lt;chr&gt;   \n1 area_hab_m2     &lt;chr [2]&gt; predictor original\n2 calidad_gral    &lt;chr [2]&gt; predictor original\n3 num_coches      &lt;chr [2]&gt; predictor original\n4 precio_m2_miles &lt;chr [2]&gt; outcome   original\n\n\n\nmodelo_lineal &lt;- linear_reg() |&gt;\n  set_engine(\"lm\")\ncasas_flujo &lt;- workflow() |&gt;\n  add_recipe(casas_receta) |&gt; \n  add_model(modelo_lineal)\n\n\nlibrary(keras)\n# definición de estructura del modelo (regresión lineal)\nx_ent_s &lt;-  prep(casas_receta) |&gt; juice() |&gt; select(-precio_m2_miles) |&gt; \n  as.matrix()\najustar_casas &lt;- function(modelo, x, y, n_epochs = 100){\n  ajuste &lt;- modelo |&gt; fit(\n    as.matrix(x), y,\n    batch_size = nrow(x_ent), # para descenso en gradiente\n    epochs = n_epochs, # número de iteraciones\n    verbose = 0) |&gt; as_tibble()\n  ajuste\n}\nmodelo_casas_ns &lt;- crear_modelo(0.00001)\nmodelo_casas_s &lt;- crear_modelo(0.2)\nhistoria_s &lt;- ajustar_casas(modelo_casas_s, x_ent_s, y_ent) |&gt;\n  mutate(tipo = \"Estandarizar\")\nhistoria_ns &lt;- ajustar_casas(modelo_casas_ns, x_ent, y_ent) |&gt; \n  mutate(tipo = \"Sin estandarizar\")\nhistoria &lt;- bind_rows(historia_ns, historia_s) |&gt;  filter(metric == \"mean_squared_error\")\nggplot(historia, aes(x = epoch, y = value, colour = tipo)) +\n     geom_line() + geom_point() +scale_x_log10() + scale_y_log10()\n\n\n\n\nObservamos que el modelo con datos estandarizados convergió:\n\nkeras::get_weights(modelo_casas_s)\n\n[[1]]\n            [,1]\n[1,] -0.22045916\n[2,]  0.23149671\n[3,]  0.09673478\n\n[[2]]\n[1] 1.295027\n\ncoef(lm.fit(cbind(1,x_ent_s), y_ent))\n\n              area_hab_m2 calidad_gral   num_coches \n  1.29502679  -0.22045919   0.23149675   0.09673476 \n\n\nMientras que el modelo no estandarizado todavía requiere iteraciones:\n\nkeras::get_weights(modelo_casas_ns)\n\n[[1]]\n             [,1]\n[1,] 0.0079817399\n[2,] 0.0019486140\n[3,] 0.0005532746\n\n[[2]]\n[1] 0.0003491882\n\ncoef(lm.fit(cbind(1, x_ent), y_ent))\n\n              area_hab_m2 calidad_gral   num_coches \n  0.66869194  -0.00449751   0.16807663   0.13115749"
  },
  {
    "objectID": "82-apendice-descenso-estocastico.html#algoritmo-de-descenso-estocástico",
    "href": "82-apendice-descenso-estocastico.html#algoritmo-de-descenso-estocástico",
    "title": "Apéndice B — Apéndice 2: Descenso estocástico",
    "section": "B.1 Algoritmo de descenso estocástico",
    "text": "B.1 Algoritmo de descenso estocástico\n\n\n\n\n\n\nDescenso estocástico\n\n\n\nSeparamos al azar los datos de entrenamiento en \\(n\\) minilotes de tamaño \\(m\\).\n\nPara épocas \\(e =1,2,\\ldots, n_e\\)\n\nCalcular el gradiente sobre el minilote y hacer actualización, sucesivamente para cada uno de los minilotes \\(k=1,2,\\ldots, n/m\\): \\[\\beta_{i+1} = \\beta_{i} - \\eta\\frac{1}{m}\\sum_{j=1}^m \\nabla D^{(k)}_j (\\beta_i)\\] donde \\(D^{(k)}_j (\\beta_i)\\) es la devianza para el \\(j\\)-ésimo caso del minilote \\(k\\).\n\nRepetir para la siguiente época (opcional: reordenar antes al azar los minilotes, para evitar ciclos)."
  },
  {
    "objectID": "82-apendice-descenso-estocastico.html#por-qué-usar-descenso-estocástico-por-minilotes",
    "href": "82-apendice-descenso-estocastico.html#por-qué-usar-descenso-estocástico-por-minilotes",
    "title": "Apéndice B — Apéndice 2: Descenso estocástico",
    "section": "B.2 ¿Por qué usar descenso estocástico por minilotes?",
    "text": "B.2 ¿Por qué usar descenso estocástico por minilotes?\nLas propiedades importantes de descenso estocástico son:\n\nMuchas veces no es necesario usar todos los datos para encontrar una buena dirección de descenso. Podemos ver la dirección de descenso en gradiente como un valor esperado sobre la muestra de entrenamiento (pues la pérdida es un promedio sobre el conjunto de entrenamiento). Una submuestra (minilote) puede ser suficiente para estimar ese valor esperado, con costo menor de cómputo. Adicionalmente, quizá no es tan buena idea intentar estimar el gradiente con la mejor precisión pues es solamente una dirección de descenso local (así que quizá no da la mejor decisión de a dónde moverse en cada punto). Es mejor hacer iteraciones más rápidas con direcciones estimadas.\nDesde este punto de vista, calcular el gradiente completo para descenso en gradiente es computacionalmente ineficiente. Si el conjunto de entrenamiento es masivo, descenso en gradiente puede no ser factible.\nDesde el punto de vista de sobreajuste, el uso de distintos datos para cada paso evita mínimos sobreajustados o de bajo desempeño que están presentes en la pérdida calculada con todos los datos.\n¿Cuál es el mejor tamaño de minilote? Por un lado, minilotes más grandes nos dan mejores eficiencias en paralelización (multiplicación de matrices), especialmente en GPUs. Por otro lado, con minilotes más grandes puede ser que hagamos trabajo de más, por las razones expuestas en los incisos anteriores, y tengamos menos iteraciones en el mismo tiempo. El mejor punto está entre minilotes demasiado chicos (donde no aprovechamos paralelismo) o demasiado grande (donde hacemos demasiado trabajo por iteración).\n\n4.Una propiedad importante de descenso estocástico en minilotes es que su convergencia no depende del tamaño del conjunto de entrenamiento, es decir, el tiempo de iteración para descenso estocástico no crece con el número de casos totales. Podemos tener obtener buenos ajustes incluso con tamaños muy grandes de conjuntos de entrenamiento (por ejemplo, antes de procesar todos los datos de entrenamiento). Descenso estocástico escala bien en este sentido: el factor limitante es el tamaño de minilote y el número de iteraciones.\n\nEs importante permutar al azar los datos antes de hacer los minibatches, pues órdenes “naturales” en los datos pueden afectar la convergencia. Se ha observado también que permutar los minibatches en cada iteración típicamente acelera la convergencia (si se pueden tener los datos en memoria).\n\n\nEjemplo\nEn el ejemplo anterior nota que las direcciones de descenso de descenso estocástico son muy razonables (punto 1). Nota también que obtenemos una buena aproximación a la solución con menos cómputo (punto 2 - mismo número de iteraciones, pero cada iteración con un minilote).\n\nggplot(filter(dat_dev, iteracion &gt;= 1), \n       aes(x=iteracion, y=dev_ent, colour=algoritmo)) + geom_line() +\n  facet_wrap(~tipo, ncol=1)"
  },
  {
    "objectID": "82-apendice-descenso-estocastico.html#escogiendo-la-tasa-de-aprendizaje",
    "href": "82-apendice-descenso-estocastico.html#escogiendo-la-tasa-de-aprendizaje",
    "title": "Apéndice B — Apéndice 2: Descenso estocástico",
    "section": "B.3 Escogiendo la tasa de aprendizaje",
    "text": "B.3 Escogiendo la tasa de aprendizaje\nPara escoger la tasa, monitoreamos las curvas de error de entrenamiento y de validación. Si la tasa es muy grande, habrá oscilaciones grandes y muchas veces incrementos grandes en la función objectivo (error de entrenamiento). Algunas oscilaciones suaves no tienen problema -es la naturaleza estocástica del algoritmo. Si la tasa es muy baja, el aprendizaje es lento y podemos quedarnos en un valor demasiado alto.\nConviene monitorear las primeras iteraciones y escoger una tasa más alta que la mejor que tengamos acutalmente, pero no tan alta que cause inestabilidad. Una gráfica como la siguiente es útil. En este ejemplo, incluso podríamos detenernos antes para evitar el sobreajuste de la última parte de las iteraciones:\n\nggplot(filter(dat_dev, algoritmo=='descenso_estocastico'), \n       aes(x=iteracion, y=dev_ent, colour=tipo)) + geom_line() \n\n\n\n\nPor ejemplo: tasa demasiado alta:\n\niter_estocastico &lt;- descenso_estocastico(20, z_0, 0.5, minilotes) |&gt;\n  as_tibble() \ndev_ent &lt;- perdida_calc(x = as.matrix(dat_ent[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_ent$y)\ndev_valid &lt;- perdida_calc(x = as.matrix(dat_valid[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_valid$y)\ndat_dev &lt;- data_frame(iteracion = 1:nrow(iter_estocastico)) |&gt;\n   mutate(entrena = apply(iter_estocastico, 1, dev_ent), \n  validacion = apply(iter_estocastico, 1, dev_valid)) |&gt;\n  gather(tipo, devianza, entrena:validacion)\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\nℹ Please use `tibble()` instead.\n\nggplot(dat_dev, \n       aes(x=iteracion, y=devianza, colour=tipo)) + geom_line() \n\n\n\n\nTasa demasiado chica ( o hacer más iteraciones):\n\niter_estocastico &lt;- descenso_estocastico(20, z_0, 0.001, minilotes) |&gt;\n  as_tibble() \ndev_ent &lt;- perdida_calc(x = as.matrix(dat_ent[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_ent$y)\ndev_valid &lt;- perdida_calc(x = as.matrix(dat_valid[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_valid$y)\ndat_dev &lt;- tibble(iteracion = 1:nrow(iter_estocastico)) |&gt;\n   mutate(entrena = apply(iter_estocastico, 1, dev_ent), \n  validacion = apply(iter_estocastico, 1, dev_valid)) |&gt;\n  gather(tipo, devianza, entrena:validacion)\nggplot(dat_dev, \n       aes(x=iteracion, y=devianza, colour=tipo)) + geom_line() \n\n\n\n\n\nPara redes neuronales, es importante explorar distintas tasas de aprendizaje, aún cuando no parezca haber oscilaciones grandes o convergencia muy lenta. En algunos casos, si la tasa es demasiado grande, puede ser que el algoritmo llegue a lugares con gradientes cercanos a cero (por ejemplo, por activaciones demasiado grandes) y tenga dificultad para moverse."
  },
  {
    "objectID": "82-apendice-descenso-estocastico.html#mejoras-al-algoritmo-de-descenso-estocástico.",
    "href": "82-apendice-descenso-estocastico.html#mejoras-al-algoritmo-de-descenso-estocástico.",
    "title": "Apéndice B — Apéndice 2: Descenso estocástico",
    "section": "B.4 Mejoras al algoritmo de descenso estocástico.",
    "text": "B.4 Mejoras al algoritmo de descenso estocástico.\n\nB.4.1 Decaimiento de tasa de aprendizaje\nHay muchos algoritmos derivados de descenso estocástico. La primera mejora consiste en reducir gradualmente la tasa de aprendizaje para aprender rápido al principio, pero filtrar el ruido de la estimación de minilotes más adelante en las iteraciones y permitir que el algoritmo se asiente en un mínimo.\n\ndescenso_estocastico &lt;- function(n_epocas, z_0, eta, minilotes, decaimiento = 0.0){\n  #minilotes es una lista\n  m &lt;- length(minilotes)\n  z &lt;- matrix(0, m*n_epocas, length(z_0))\n  z[1, ] &lt;- z_0\n  for(i in 1:(m*n_epocas-1)){\n    k &lt;- i %% m + 1\n    if(i %% m == 0){\n      #comenzar nueva época y reordenar minilotes al azar\n      minilotes &lt;- minilotes[sample(1:m, m)]\n    }\n    h_deriv &lt;- grad_calc(minilotes[[k]]$x, minilotes[[k]]$y)\n    z[i+1, ] &lt;- z[i, ] - eta * h_deriv(z[i, ])\n    eta &lt;- eta*(1/(1+decaimiento*i))\n  }\n  colnames(z) &lt;- names(z_0)\n  z\n}\n\nY ahora vemos qué pasa con decaimiento:\n\niter_estocastico &lt;- descenso_estocastico(10, z_0, 0.1, \n                                         minilotes, decaimiento = 1e-3) |&gt;\n  as_tibble() |&gt; rename(beta_0 = Intercept, beta_1 = x_1, beta_2 = x_2, beta_3 = x_3)\ndev_ent &lt;- perdida_calc(x = as.matrix(dat_ent[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_ent$y)\ndev_valid &lt;- perdida_calc(x = as.matrix(dat_valid[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_valid$y)\ndat_dev &lt;- data_frame(iteracion = 1:nrow(iter_estocastico)) |&gt;\n   mutate(entrena = apply(iter_estocastico, 1, dev_ent), \n  validacion = apply(iter_estocastico, 1, dev_valid)) |&gt;\n  gather(tipo, devianza, entrena:validacion)\nggplot(filter(dat_dev, iteracion&gt;1), \n       aes(x=iteracion, y=devianza, colour=tipo)) + geom_line() \n\n\n\n\nPara los primeros dos parámetros, las iteraciones se ven:\n\nggplot(iteraciones_descenso, aes(x=beta_1, y=beta_2)) + geom_path() +\n  geom_point() +\n  geom_path(data = iter_estocastico, colour ='red', alpha=0.2) +\n  geom_point(data = iter_estocastico, colour ='red', alpha=0.2)\n\n\n\n\n\n\n\n\n\n\nTasa de aprendizaje\n\n\n\nLa tasa de aprendizaje es uno de los parámetros en redes neuronales más importantes de afinar. Generalmente se empieza con una tasa de aprendizaje con un valor bajo (0.01, o 0.1), pero es necesario experimentar.\n\nUn valor muy alto puede provocar oscilaciones muy fuertes en la pérdida\nUn valor alto también puede provocar que el algoritmo se detenga en lugar con función pérdida alta (sobreajusta rápidamente).\nUn valor demasiado bajo produce convergencia lenta.\n\n\n\n\n\nB.4.2 Momento\nTambién es posible utilizar una idea adicional que acelera la convergencia. La idea es que muchas veces la aleatoriedad del algoritmo puede producir iteraciones en direcciones que no son tan buenas (pues la estimación del gradiente es mala). Esto es parte del algoritmo. Sin embargo, si en varias iteraciones hemos observado movimientos en direcciones consistentes, quizá deberíamos movernos en esas direcciones consistentes, y reducir el peso de la dirección del minilote (que nos puede llevar en una dirección mala). El resultado es un suavizamiento de las curvas de aprendizaje.\nEsto es similar al movimiento de una canica en una superficie: la dirección de su movimiento está dada en parte por la dirección de descenso (el gradiente) y en parte la velocidad actual de la canica. La canica se mueve en un promedio de estas dos direcciones\n\n\n\n\n\n\nDescenso estocástico con momento\n\n\n\nSeparamos al azar los datos de entrenamiento en \\(n\\) minilotes de tamaño \\(m\\).\n\nPara épocas \\(e =1,2,\\ldots, n_e\\)\n\nCalcular el gradiente sobre el minilote y hacer actualización, sucesivamente para cada uno de los minilotes \\(k=1,2,\\ldots, n/m\\): \\[\\beta_{i+1} = \\beta_{i} + v,\\] \\[v= \\alpha v - \\eta\\frac{1}{m}\\sum_{j=1}^m \\nabla D^{(k)}_j\\] donde \\(D^{(k)}_j (\\beta_i)\\) es la devianza para el \\(j\\)-ésimo caso del minilote \\(k\\). A \\(v\\) se llama la velocidad\n\nRepetir para la siguiente época\n\n\n\n\ndescenso_estocastico &lt;- function(n_epocas, z_0, eta, minilotes, \n                                 momento = 0.0, decaimiento = 0.0){\n  #minilotes es una lista\n  m &lt;- length(minilotes)\n  z &lt;- matrix(0, m*n_epocas, length(z_0))\n  z[1, ] &lt;- z_0\n  v &lt;- 0\n  for(i in 1:(m*n_epocas-1)){\n    k &lt;- i %% m + 1\n    if(i %% m == 0){\n      #comenzar nueva época y reordenar minilotes al azar\n      minilotes &lt;- minilotes[sample(1:m, m)]\n      v &lt;- 0\n    }\n    h_deriv &lt;- grad_calc(minilotes[[k]]$x, minilotes[[k]]$y)\n    z[i+1, ] &lt;- z[i, ] + v\n    v &lt;- momento*v - eta * h_deriv(z[i, ])\n    eta &lt;- eta*(1/(1+decaimiento*i))\n  }\n  colnames(z) &lt;- names(z_0)\n  z\n}\n\nY ahora vemos que usando momento el algoritmo es más parecido a descenso en gradiente usual (pues tenemos cierta memoria de direcciones anteriores de descenso):\n\nset.seed(232)\niter_estocastico &lt;- descenso_estocastico(10, z_0, 0.005, minilotes, momento = 0.9, decaimiento = 0.00001) |&gt;\n  as_tibble() |&gt; rename(beta_0 = Intercept, beta_1 = x_1, beta_2 = x_2, beta_3 = x_3)\ndev_ent &lt;- perdida_calc(x = as.matrix(dat_ent[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_ent$y)\ndev_valid &lt;- perdida_calc(x = as.matrix(dat_valid[,c('x_1','x_2','x_3'), drop =FALSE]), \n                             y=dat_valid$y)\ndat_dev &lt;- data_frame(iteracion = 1:nrow(iter_estocastico)) |&gt;\n   mutate(entrena = apply(iter_estocastico, 1, dev_ent), \n  validacion = apply(iter_estocastico, 1, dev_valid)) |&gt;\n  gather(tipo, devianza, entrena:validacion)\nggplot(filter(dat_dev, iteracion &gt; 1), \n       aes(x=iteracion, y=devianza, colour=tipo)) + geom_line() + geom_point()\n\n\n\n\n\nggplot(iteraciones_descenso, aes(x=beta_1, y=beta_2)) + geom_path() +\n  geom_point() +\n  geom_path(data = iter_estocastico, colour ='red', alpha=0.5) +\n  geom_point(data = iter_estocastico, colour ='red', alpha=0.5)\n\n\n\n\nNótese cómo llegamos más rápido a una buena solución (comparado con el ejemplo sin momento). Adicionalmente, error de entrenamiento y validación lucen más suaves, producto de promediar velocidades a lo largo de iteraciones.\nValores típicos para momento son 0,0.5,0.9 o 0.99.\n\n\nB.4.3 Otras variaciones\nOtras variaciones incluyen usar una tasa adaptativa de aprendizaje por cada parámetro (algoritmos adagrad, rmsprop, adam y adamax), o actualizaciones de momento un poco diferentes (Nesterov).\nLos más comunes son descenso estocástico, descenso estocástico con momento (a veces con la modificación de Nesterov), rmsprop y adam (Capítulo 8 del Deep Learning Book, (Goodfellow, Bengio, y Courville 2016))."
  },
  {
    "objectID": "82-apendice-descenso-estocastico.html#ajuste-de-redes-con-descenso-estocástico",
    "href": "82-apendice-descenso-estocastico.html#ajuste-de-redes-con-descenso-estocástico",
    "title": "Apéndice B — Apéndice 2: Descenso estocástico",
    "section": "B.5 Ajuste de redes con descenso estocástico",
    "text": "B.5 Ajuste de redes con descenso estocástico\n\nlibrary(keras)\n\n\nset.seed(21321)\nx_ent &lt;- as.matrix(dat_ent[,c('x_1','x_2','x_3')])\nx_valid &lt;-  as.matrix(dat_valid[,c('x_1','x_2','x_3')])\ny_ent &lt;- dat_ent$y\ny_valid &lt;- dat_valid$y\n\nEmpezamos con regresión (sin capas ocultas), que se escribe y ajusta como sigue:\n\nmodelo &lt;- keras_model_sequential() \nmodelo |&gt;\n  layer_dense(units = 1, \n              activation = \"linear\",\n              input_shape = c(3))\n\nmodelo |&gt; compile(loss = 'mse',\n                   optimizer = optimizer_sgd(learning_rate = 0.1, momentum = 0,\n                                             decay = 0))\n\nhistory &lt;- modelo |&gt; \n  fit(x_ent, y_ent, \n      epochs = 50, batch_size = 10, \n      verbose = 0,\n      validation_data = list(x_valid, y_valid))\n\nPodemos ver el progreso del algoritmo por época\n\naprendizaje &lt;- as_tibble(history)\nggplot(aprendizaje, \n       aes(x=epoch, y=value, colour=data, group=data)) +\n  facet_wrap(~metric, ncol = 1) + geom_line() + geom_point(size = 0.5)\n\n\n\n\nVer los pesos:\n\nget_weights(modelo)\n\n[[1]]\n           [,1]\n[1,] -2.5870194\n[2,] -0.1679591\n[3,]  0.1543436\n\n[[2]]\n[1] -0.4388565\n\n\nY verificamos que concuerda con la salida de lm:\n\nmod_lineal &lt;- lm(y ~ x_1 + x_2+ x_3, data = dat_ent) \ncoef(mod_lineal)\n\n(Intercept)         x_1         x_2         x_3 \n-0.36904266 -2.46877687 -0.07368414  0.06632769 \n\n\n\n\n\n\nGoodfellow, Ian, Yoshua Bengio, y Aaron Courville. 2016. Deep Learning. MIT Press."
  },
  {
    "objectID": "99-referencias.html",
    "href": "99-referencias.html",
    "title": "Referencias",
    "section": "",
    "text": "Bishop, Christopher M. 2006. Pattern Recognition and Machine\nLearning (Information Science and Statistics). Secaucus, NJ, USA:\nSpringer-Verlag New York, Inc.\n\n\nChambers, J. M., W. S. Cleveland, B. Kleiner, and P. A. Tukey. 1983.\nGraphical Methods for Data Analysis. Chapman & Hall\nStatistics Series. Wadsworth International Group. https://books.google.com.mx/books?id=I-tQAAAAMAAJ.\n\n\nGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. Deep\nLearning. MIT Press.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2017. The\nElements of Statistical Learning. Springer Series in Statistics.\nSpringer New York Inc. http://web.stanford.edu/~hastie/ElemStatLearn/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2014. An Introduction to Statistical Learning: With Applications in\nr. Springer Publishing Company, Incorporated. http://www-bcf.usc.edu/~gareth/ISL/.\n\n\nKuhn, M., and J. Silge. 2022. Tidy Modeling with r. O’Reilly\nMedia. https://books.google.com.mx/books?id=9cJ6EAAAQBAJ."
  }
]